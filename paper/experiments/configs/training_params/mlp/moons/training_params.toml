name = "training_params"
dim_reduction = []
generator_type = ["ecco", "generic", "omni", "revise"]
data = "moons"
model_type = "mlp"
save_dir = "paper/experiments/output/training_params/mlp/moons"

[data_params]
datadir = []
mutability = []
domain = []
n_validation = []
train_test_ratio = []
train_test_seed = []
n_train = []
batchsize = []

[model_params]
nlayers = []
activation = []
nhidden = []

[generator_params]
opt = []
lambda_cost = []
lr = []
maxiter = []
lambda_energy = []
type = []

[training_params]
opt = ["adam"]
lr = []
objective = ["full", "vanilla"]
lambda_class_loss = [1.0]
lambda_energy_diff = [0.01, 0.1, 1.0]
burnin = [0.0, 0.5]
nepochs = []
lambda_adversarial = []
parallelizer = []
nce = [100, 300, 500]
threaded = []
class_loss = []
lambda_energy_reg = [0.0, 0.01, 0.1]
verbose = []
generator_params = []
conv = []
nneighbours = []
