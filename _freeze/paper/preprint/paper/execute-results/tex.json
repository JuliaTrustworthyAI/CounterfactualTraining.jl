{
  "hash": "79d0e56a32d48d6e8ff1cd8e20dd4f56",
  "result": {
    "engine": "julia",
    "markdown": "---\nengine: julia\njulia: \n  exeflags: [\"--project=../experiments/\"]\nformat:\n  arxiv-pdf:\n    keep-tex: true  \n    linenumbers: false\n    doublespacing: false\n    runninghead: \"Counterfactual Training\"\n    authorcols: true\n    include-in-header:\n      text: |\n        \\usepackage[title]{appendix}\n        \\usepackage{placeins}\n        \\usepackage{amsthm}\n        \\theoremstyle{plain}\n        \\newtheorem{proposition}{Proposition}[section]\n        \\theoremstyle{definition}\n        \\newtheorem{definition}{Definition}[section]\n        \\theoremstyle{definition}\n        \\newtheorem{example}{Example}[section]\n        \\theoremstyle{plain}\n        \\usepackage{algorithm}\n        \\usepackage{algorithmic}\n        \\usepackage{amsfonts}\n        \\usepackage{amsmath}\n        \\usepackage{siunitx}\n        \\sisetup{uncertainty-mode = separate}\n        \\DeclareMathSizes{10}{9}{7}{6.5}\n        \\usepackage{enumitem}\n---\n\n# Abstract\n\nWe propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-word decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and exhibit greatly improved adversarial robustness.\n\n\n\n# Introduction\n\nTodayâ€™s prominence of artificial intelligence (AI) has largely been driven by the success of representation learning with high degrees of freedom: instead of relying on features and rules hand-crafted by humans, modern machine learning (ML) models are tasked with learning highly complex representations directly from the data, guided by narrow objectives such as predictive accuracy [@goodfellow2016deep]. These models tend to be so complex that humans cannot easily interpret their decision logic.\n\nCounterfactual explanations (CE) have become a key part of the broader explainable AI (XAI) toolkit [@molnar2022interpretable] that can be applied to make sense of this complexity. Originally proposed by @wachter2017counterfactual, CEs prescribe minimal changes for factual inputs that, if implemented, would prompt some fitted model to produce an alternative, more desirable output. This is useful and necessary to not only understand how opaque models make their predictions, but also to provide algorithmic recourse (AR) to individuals subjected to them: a retail bank, for example, could use CE to provide meaningful feedback to unsuccessful loan applicants that were rejected based on an opaque automated decision-making (ADM) system (@fig-poc).\n\nFor such feedback to be meaningful, counterfactual explanations need to fulfill certain desiderata [@verma2020counterfactual; @karimi2020survey]---they should be faithful to the model [@altmeyer2024faithful], plausible [@joshi2019realistic] and actionable [@ustun2019actionable]. Plausibility is typically understood as counterfactuals being *in-domain*: unsuccessful loan applicants that implement the provided recourse should end up with credit profiles that are genuinely similar to that of individuals who have successfully repaid their loans in the past. Actionable explanations comply with practical constraints: a young, unsuccessful loan applicant cannot increase their age in an instance.\n\nExisting state-of-the-art (SOTA) approaches in the field have largely focused on designing model-agnostic CE methods that identify subsets of counterfactuals, which comply with specific desiderata. This is problematic, because the narrow focus on any specific desideratum can adversely affect others: it is possible, for example, to generate plausible counterfactuals for models that are also highly vulnerable to implausible, possibly adversarial counterfactuals [@altmeyer2024faithful]. In this work, we therefore embrace the paradigm that models (as opposed to explanation methods) should be held accountable for explanations that are plausible and actionable. While previous work has shown that at least plausibility can be indirectly achieved through existing techniques aimed at models' generative capacity, generalization and robustness [@altmeyer2024faithful; @augustin2020adversarial; @schut2021generating], we directly incorporate both plausibility and actionability in the training objective of models to improve their overall explanatory capacity.\n\nSpecifically, we propose **counterfactual training (CT)**: a novel training regime that leverages counterfactual explanations on-the-fly to ensure that differentiable models learn plausible and actionable explanations for the underlying data, while at the same time also being more robust to adversarial examples (AE). @fig-poc illustrates the outcomes of CT compared to a conventionally trained model. First, in panel (a), faithful and valid counterfactuals end up near the decision boundary forming a clearly distinguishable cluster in the target class (orange). In panel (b), CT is applied to the same underlying linear classifier architecture resulting in much more plausible counterfactuals. In panel (c), the classifier is again trained conventionally and we have introduced a mutability constraint on the *age* feature at test time---counterfactuals are valid but the classifier is roughly equally sensitive to both features. By contrast, the decision boundary in panel (d) has titled, making the model trained with CT relatively less sensitive to the immutable *age* feature. To achieve these outcomes, CT draws inspiration from the literature on contrastive and robust learning: we contrast faithful CEs with ground-truth data while protecting immutable features, and capitalize on methodological links between CE and AE by penalizing the model's adversarial loss on interim (*nascent*) counterfactuals. To the best of our knowledge, CT represents the first venture in this direction with promising empirical and theoretical results.\n\nThe remainder of this manuscript is structured as follows. @sec-lit presents related work, focusing on the links to contrastive and robust learning. Then follow our two principal contributions. In @sec-method, we introduce our methodological framework and show theoretically that it can be employed to respect global actionability constraints. In our experiments (@sec-experiments), we find that thanks to counterfactual training, (1) the implausibility of CEs decreases by up to 90%; (2) the cost of reaching valid counterfactuals with protected features decreases by 19% on average; and (3) models' adversarial robustness improves across the board. Finally, we discuss open challenges in @sec-discussion and conclude in @sec-conclusion.\n\n![Counterfactual explanations (stars) for linear classifiers trained under different regimes on synthetic data: (a) conventional training, all mutable; (b) CT, all mutable; (c) conventional, *age* immutable; (d) CT, *age* immutable. The linear decision boundary is shown in green along with training data colored according to ground-truth labels: $y^-=\\text{\"loan withheld\"}$ (blue) and $y^+=\\text{\"loan provided\"}$ (orange). Class and feature annotations (*debt* and *age*) are for illustrative purposes.](/paper/figures/poc.svg){#fig-poc fig-env=\"figure*\"}\n\n\n\n# Related Literature {#sec-lit}\n\nTo make the desiderata for our framework more concrete, we follow previous work in tying the explanatory capacity of models to the quality of CEs that can be generated for them [@altmeyer2024faithful; @augustin2020adversarial]. For simplicity, we refer to \"explanatory capacity\" as \"explainability\" in the rest of this manuscript (see Def. \\ref{def-explainability}).\n\n## Explainability and Contrastive Learning\n\nIn a closely related work, @altmeyer2024faithful show that model averaging and, in particular, contrastive model objectives can produce more explainable and hence trustworthy models. The authors propose a way to generate counterfactuals that are maximally faithful in that they are consistent with what models have learned about the underlying data. Formally, they rely on tools from energy-based modelling [@teh2003energy] to minimize the contrastive divergence between the distribution of counterfactuals and the conditional posterior over inputs learned by a model. Their algorithm, *ECCCo*, yields plausible counterfactual explanations if and only if the underlying model has learned representations that align with them. The authors find that both deep ensembles [@lakshminarayanan2016simple] and joint energy-based models (JEMs) [@grathwohl2020your], a form of constrastive learning, tend to do well in this regard. \n\nIt helps to look at these findings through the lens of representation learning with high degrees of freedom. Deep ensembles are approximate Bayesian model averages, which are particularly effective when models are underspecified by the available data [@wilson2020case]. Averaging across solutions mitigates the risk of overrelying on a single locally optimal representation that corresponds to semantically meaningless explanations. Likewise, previous work of @schut2021generating found that generating plausible (\"interpretable\") CEs is almost trivial for deep ensembles that have undergone adversarial training. The case for JEMs is even clearer: they optimize a hybrid objective that induces both high predictive performance and strong generative capacity [@grathwohl2020your], which resembles the idea of aligning models with plausible explanations and has inspired CT.\n\n## Explainability and Robust Learning\n\n@augustin2020adversarial show that CEs tend to be more meaningful (\"explainable\") if the underlying model is more robust to adversarial examples. Once again, we can make intuitive sense of this finding if we look at adversarial training (AT) through the lens of representation learning with high degrees of freedom: highly complex and flexible models may learn representations that make them sensitive to implausible or even adversarial examples [@szegedy2013intriguing]. Thus, by inducing models to \"unlearn\" susceptibility to such examples, adversarial training can effectively remove implausible explanations from the solution space.\n\nThis interpretation of the link between explainability through counterfactuals on the one side, and robustness to adversarial examples on the other is backed by empirical evidence. @sauer2021counterfactual demonstrate that using counterfactual images during classifier training improves model robustness. Similarly, @abbasnejad2020counterfactual argue that counterfactuals represent potentially useful training data in machine learning, especially in supervised settings where inputs may be reasonably mapped to multiple outputs. They, too, show that augmenting the training data of (image) classifiers can improve generalization performance. Finally, @teney2020learning argue that counterfactual pairs tend to exist in training data. Hence, their approach aims to identify similar input samples with different annotations and ensure that the gradient of the classifier aligns with the vector between such pairs of counterfactual inputs using a cosine distance loss function. \n\nCEs have also been used to improve models in the natural language processing domain. For example, @wu2021polyjuice propose *Polyjuice*, a general-purpose CE generator for language models and demonstrate that the augmentation of training data with *Polyjuice* improves robustness in a number of tasks, while @luu2023counterfactual introduce the *Counterfactual Adversarial Training* (CAT) framework that aims to improve generalization and robustness of language models by generating counterfactuals for training samples that are subject to high predictive uncertainty. \n\nThere have also been several attempts at formalizing the relationship between counterfactual explanations and adversarial examples. Pointing to clear similarities in how CEs and AEs are generated, @freiesleben2022intriguing makes the case for jointly studying the opaqueness and robustness problems in representation learning. Formally, AEs can be seen as the subset of CEs for which misclassification is achieved [@freiesleben2022intriguing]. Similarly, @pawelczyk2022exploring show that CEs and AEs are equivalent under certain conditions. \n\nTwo other works are closely related to ours in that they use counterfactuals during training with the explicit goal of affecting certain properties of the post-hoc counterfactual explanations. Firstly, @ross2021learning propose a way to train models that guarantee recourse to a positive target class with high probability. Their approach builds on adversarial training by explicitly inducing susceptibility to targeted AEs for the positive class. Additionally, the method allows for imposing a set of actionability constraints ex-ante. For example, users can specify that certain features are immutable. Secondly, @guo2023counternet are the first to propose an end-to-end training pipeline that includes CEs as part of the training procedure. Their *CounterNet* network architecture includes a predictor and a CE generator, where the parameters of the CE generator are learnable. Counterfactuals are generated during each training iteration and fed back to the predictor. In contrast, we impose no restrictions on the ANN architecture at all. \n\n\n\n# Counterfactual Training {#sec-method}\n\nThis section introduces the counterfactual training framework, applying ideas from contrastive and robust learning to counterfactual explanations. CT produces models whose learned representations align with plausible explanations that comply with user-defined actionability constraints. \n\nCounterfactual explanations are typically generated by solving variations of the following optimization problem,\n$$\n\\begin{aligned}\n\\min_{\\mathbf{X}^\\prime \\in \\mathcal{X}^D} \\left\\{  {\\text{yloss}(\\mathbf{M}_\\theta(\\mathbf{x}^{\\prime}),\\mathbf{y}^+)}+ \\lambda {\\text{reg}(\\mathbf{x}^{\\prime}) }  \\right\\} \n\\end{aligned}\n$$ {#eq-general}\nwhere $\\mathbf{M}_\\theta: \\mathcal{X} \\mapsto \\mathcal{Y}$ denotes a classifier, $\\mathbf{x}^{\\prime}$ denotes the counterfactual with $D$ features and $\\mathbf{y}^+\\in\\mathcal{Y}$ denotes some target class. The $\\text{yloss}(\\cdot)$ function quantifies the discrepancy between current model predictions for $\\mathbf{x}^{\\prime}$ and the target class (a conventional choice is cross-entropy). Finally, we use $\\text{reg}(\\cdot)$ to denote any form of regularization used to induce certain properties on the counterfactual. In their seminal paper, @wachter2017counterfactual propose regularizing the distance between counterfactuals and their original factual values to ensure that individuals seeking recourse through CE face minimal costs in terms of feature changes. Different variations of @eq-general have been proposed in the literature to address many desiderata including the ones discussed above (faithfulness, plausibility and actionability). Like @wachter2017counterfactual, most of these approaches rely on gradient descent to optimize @eq-general. For more details on the approaches tested in this work, we refer the reader to the supplementary appendix. In the following, we describe in detail how counterfactuals are generated and used in counterfactual training.\n\n## Proposed Training Objective\n\nThe goal of CT is to improve model explainability by aligning models with faithful explanations that are plausible and actionable. Formally, we define explainability as follows:\n\n\\begin{definition}[Model Explainability]\n\\label{def-explainability}\nLet $\\mathbf{M}_\\theta: \\mathcal{X} \\mapsto \\mathcal{Y}$ denote a supervised classification model that maps from the $D$-dimensional input space $\\mathcal{X}$ to representations $\\phi(\\mathbf{x};\\theta)$ and finally to the $K$-dimensional output space $\\mathcal{Y}$. Assume that for any given input-output pair $\\{\\mathbf{x},\\mathbf{y}\\}_i$ there exists a counterfactual $\\mathbf{x}^{\\prime} = \\mathbf{x} + \\Delta: \\mathbf{M}_\\theta(\\mathbf{x}^{\\prime}) = \\mathbf{y}^{+} \\neq \\mathbf{y} = \\mathbf{M}_\\theta(\\mathbf{x})$, where $\\arg\\max_y{\\mathbf{y}^{+}}=y^+$ is the index of the target class. \n\nWe say that $\\mathbf{M}_\\theta$ has an \\textbf{explanatory capacity} to the extent that faithfully generated, valid counterfactuals are also plausible and actionable. We define these properties as:\n\n\\begin{itemize}\n    \\item (Faithfulness) $\\int^{A} p_\\theta(\\mathbf{x}^\\prime|\\mathbf{y}^{+})d\\mathbf{x} \\rightarrow 1$; $A$ is an arbitrarily small region around $\\mathbf{x}^{\\prime}$.\n    \\item (Plausibility) $\\int^{A} p(\\mathbf{x}^\\prime|\\mathbf{y}^{+})d\\mathbf{x} \\rightarrow 1$; $A$ as specified above.\n    \\item (Actionability) Perturbations $\\Delta$ may be subject to some actionability constraints.\n\\end{itemize}\nHere, $p_\\theta(\\mathbf{x}|\\mathbf{y}^{+})$ denotes the conditional posterior distribution over inputs. For simplicity, we refer to a model with high explanatory capacity as \\textbf{explainable} in this manuscript. \n\\end{definition}\n\nThe characterization of faithfulness and plausibility in Def. \\ref{def-explainability} follows @altmeyer2024faithful, with adapted notation. Intuitively, plausible counterfactuals are consistent with the data and faithful counterfactuals are consistent with what the model has learned about the input data. Ac tionability constraints in Def. \\ref{def-explainability} vary and depend on the context in which $\\mathbf{M}_\\theta$ is deployed. In this work, we choose to only consider domain and mutability constraints for individual features $x_d$ for $d=1,...,D$. We also limit ourselves to classification tasks for reasons discussed in @sec-discussion.\n\nLet $\\mathbf{x}_t^\\prime$ for $t=0,...,T$ denote a counterfactual generated through gradient descent over $T$ iterations as originally proposed by @wachter2017counterfactual. CT adopts gradient-based CE search in training to generate on-the-fly model explanations $\\mathbf{x}^\\prime$ for the training samples. We use the term *nascent* to denote interim counterfactuals $\\mathbf{x}_{t\\leq T}^\\prime$ that have not yet converged. As we explain below, these nascent counterfactuals can be stored and repurposed as adversarial examples. Conversely, we consider counterfactuals $\\mathbf{x}_T^\\prime$ as *mature* explanations if they have either exhausted all $T$ iterations or converged by reaching a pre-specified threshold, $\\tau$, for the predicted probability of the target class: $\\mathcal{S}(\\mathbf{M}_\\theta(\\mathbf{x}^\\prime))[y^+] \\geq \\tau$, where $\\mathcal{S}$ is the softmax function.\n\nFormally, we propose the following counterfactual training objective to train explainable (as in Def. \\ref{def-explainability}) models,\n$$\n\\begin{aligned}\n&\\min_\\theta \\text{yloss}(\\mathbf{M}_\\theta(\\mathbf{x}),\\mathbf{y}) + \\lambda_{\\text{div}} \\text{div}(\\mathbf{x}^+,\\mathbf{x}_T^\\prime,y;\\theta) \\\\+ &\\lambda_{\\text{adv}} \\text{advloss}(\\mathbf{M}_\\theta(\\mathbf{x}_{t\\leq T}^\\prime),\\mathbf{y}) + \\lambda_{\\text{reg}}\\text{ridge}(\\mathbf{x}^+,\\mathbf{x}_T^\\prime,y;\\theta)\n\\end{aligned}\n$$ {#eq-obj}\nwhere $\\text{yloss}(\\cdot)$ is any classification loss that induces discriminative performance (e.g., cross-entropy). The second and third terms are explained in detail below. For now, they can be summarized as inducing explainability directly and indirectly by penalizing (1) the contrastive divergence, $\\text{div}(\\cdot)$, between mature counterfactuals $\\mathbf{x}_T^\\prime$ and observed samples $\\mathbf{x}^+\\in\\mathcal{X}^+=\\{\\mathbf{x}:y=y^+\\}$ in the target class $y^+$, and (2) the adversarial loss, $\\text{advloss}(.)$, wrt. nascent counterfactuals $\\mathbf{x}_{t\\leq T}^\\prime$. Finally, $\\text{ridge}(\\cdot)$ denotes a Ridge penalty ($\\ell_2$-norm) that regularizes the magnitude of the energy terms involved in $\\text{div}(\\cdot)$ [@du2019implicit]. The trade-offs between these components are adjusted through $\\lambda_{\\text{div}}$, $\\lambda_{\\text{adv}}$ and $\\lambda_{\\text{reg}}$. The full training regime is sketched out in Algorithm \\ref{alg-experiment}.\n\n\\begin{algorithm}[h]\n  \\caption{Counterfactual Training}\n    \\label{alg-experiment}\n    \\begin{algorithmic}[1]\n    \\REQUIRE Training dataset $\\mathcal{D}$, initialize model $\\mathbf{M}_{\\theta}$\n    \\WHILE{not converged}\n        \\STATE Sample $\\mathbf{x}$ and $\\mathbf{y}$ from dataset $\\mathcal{D}$.\n        \\STATE Sample $\\mathbf{x}^{\\prime}_0$, $\\mathbf{y}^+$ and $\\mathbf{x}^+$.\n        \\FOR{$t = 1$ to $T$}\n            \\STATE Backpropagate $\\nabla_{\\mathbf{x}^\\prime}$ through Equation \\ref{eq-general}. Store $\\mathbf{x}_t^\\prime$.\n        \\ENDFOR\n        \\STATE Backpropagate $\\nabla_{\\theta}$ through Equation \\ref{eq-obj}.\n    \\ENDWHILE\n    \\RETURN $\\mathbf{M}_\\theta$\n    \\end{algorithmic}\n\\end{algorithm}\n\n## Directly Inducing Explainability with Contrastive Divergence\n\n@grathwohl2020your observe that any classifier can be re-interpreted as a joint energy-based model that learns to discriminate output classes conditional on the observed (training) samples from $p(\\mathbf{x})$ and the generated samples from $p_\\theta(\\mathbf{x})$. The authors show that JEMs can be trained to perform well at both tasks by directly maximizing the joint log-likelihood: $\\log p_\\theta(\\mathbf{x},\\mathbf{y})=\\log p_\\theta(\\mathbf{y}|\\mathbf{x}) + \\log p_\\theta(\\mathbf{x})$, where the first term can be optimized using cross-entropy as in @eq-obj. To optimize $\\log p_\\theta(\\mathbf{x})$, they minimize the contrastive divergence between the observed samples from $p(\\mathbf{x})$ and samples generated from $p_\\theta(\\mathbf{x})$. \n\nTo generate samples, @grathwohl2020your use Stochastic Gradient Langevin Dynamics (SGLD) with an uninformative prior for initialization but we depart from their methodology: we propose to leverage counterfactual explainers to generate counterfactuals of observed training samples. Specifically, we have:\n$$\n\\text{div}(\\mathbf{x}^+,\\mathbf{x}_T^\\prime,y;\\theta) = \\mathcal{E}_\\theta(\\mathbf{x}^+,y) - \\mathcal{E}_\\theta(\\mathbf{x}_T^\\prime,y)\n$$ {#eq-div}\nwhere $\\mathcal{E}_\\theta(\\cdot)$ denotes the energy function defined as $\\mathcal{E}_\\theta(\\mathbf{x},y)=-\\mathbf{M}_\\theta(\\mathbf{x})[y^+]$, with $y^+$ denoting the index of the randomly drawn target class, $y^+ \\sim p(y)$. Conditional on the target class $y^+$, $\\mathbf{x}_T^\\prime$ denotes a mature counterfactual for a randomly sampled factual from a non-target class generated with a gradient-based CE generator for up to $T$ iterations. Intuitively, the gradient of @eq-div decreases the energy of observed training samples (positive samples) while increasing the energy of counterfactuals (negative samples) [@du2019implicit]. As the counterfactuals get more plausible (Def. \\ref{def-explainability}) during training, these opposing effects gradually balance each other out [@lippe2024uvadlc].\n\nSince maturity of counterfactuals in terms of a probability threshold is often reached before $T$, this form of sampling is not only more closely aligned with Def. \\ref{def-explainability}., but can also speed up training times compared to SGLD. The departure from SGLD also allows us to tap into the vast repertoire of explainers that have been proposed in the literature to meet different desiderata. For example, many methods support domain and mutability constraints. In principle, any existing approach for generating CEs is viable, so long as it does not violate the faithfulness condition. Like JEMs [@murphy2022probabilistic], counterfactual training can be considered a form of contrastive representation learning.\n\n## Indirectly Inducing Explainability with Adversarial Robustness\n\nBased on our analysis in @sec-lit, counterfactuals $\\mathbf{x}^\\prime$ can be repurposed as additional training samples [@balashankar2023improving;@luu2023counterfactual] or adversarial examples [@freiesleben2022intriguing;@pawelczyk2022exploring]. This leaves some flexibility with regards to the choice for the $\\text{advloss}(\\cdot)$ term in @eq-obj. An intuitive functional form, but likely not the only sensible choice, is inspired by adversarial training:\n$$\n\\begin{aligned}\n\\text{advloss}(\\mathbf{M}_\\theta(\\mathbf{x}_{t\\leq T}^\\prime),\\mathbf{y};\\varepsilon)&=\\text{yloss}(\\mathbf{M}_\\theta(\\mathbf{x}_{t_\\varepsilon}^\\prime),\\mathbf{y}) \\\\\nt_\\varepsilon &= \\max_t \\{t: ||\\Delta_t||_\\infty < \\varepsilon\\}\n\\end{aligned}\n$$ {#eq-adv}\nUnder this choice, we consider nascent counterfactuals $\\mathbf{x}_{t\\leq T}^\\prime$ as AEs as long as the magnitude of the perturbation to any single feature is at most $\\varepsilon$. This is closely aligned with @szegedy2013intriguing who define an adversarial attack as an \"imperceptible non-random perturbation\". Thus, we work with a different distinction between CE and AE than @freiesleben2022intriguing who considers misclassification as the distinguishing feature of adversarial examples. One of the key observations of this work is that we can leverage CEs during training and get AEs essentially for free to reap the aforementioned benefits of adversarial training.\n\n## Encoding Actionability Constraints {#sec-constraints}\n\nMany existing counterfactual explainers support domain and mutability constraints. In fact, both types of constraints can be implemented for any explainer that relies on gradient descent in the feature space for optimization [@altmeyer2023explaining]. In this context, domain constraints can be imposed by simply projecting counterfactuals back to the specified domain, if the previous gradient step resulted in updated feature values that were out-of-domain. Similarly, mutability constraints can be enforced by setting partial derivatives to zero to ensure that features are only perturbed in the allowed direction, if at all. \n\nSince actionability constraints are binding at test time, we also impose them when generating $\\mathbf{x}^\\prime$ during each training iteration to inform model representations. Through their effect on $\\mathbf{x}^\\prime$, both types of constraints influence model outcomes via @eq-div. Here it is crucial that we avoid penalizing implausibility that arises due to mutability constraints. For any mutability-constrained feature $d$ this can be achieved by enforcing $\\mathbf{x}^+[d] - \\mathbf{x}^\\prime[d]:=0$ whenever perturbing $\\mathbf{x}^\\prime[d]$ in the direction of $\\mathbf{x}^+[d]$ would violate mutability constraints. Specifically, we set $\\mathbf{x}^+[d] := \\mathbf{x}^\\prime[d]$ if:\n\n1. Feature $d$ is strictly immutable in practice.\n2. $\\mathbf{x}^+[d]>\\mathbf{x}^\\prime[d]$, but $d$ can only be decreased in practice.\n3. $\\mathbf{x}^+[d]<\\mathbf{x}^\\prime[d]$, but $d$ can only be increased in practice.\n\n`\\noindent`{=latex} From a Bayesian perspective, setting $\\mathbf{x}^+[d] := \\mathbf{x}^\\prime[d]$ can be understood as assuming a point mass prior for $p(\\mathbf{x}^+)$ wrt. feature $d$. Intuitively, we think of this as ignoring implausibility costs of immutable features, which effectively forces the model to instead seek plausibility through the remaining features. This can be expected to result in relatively lower sensitivity to immutable features; and higher relative sensitivity to mutable features should make mutability-constrained recourse less costly (@sec-experiments). Under certain conditions, this result holds theoretically; for the proof, see the supplementary appendix:\n\n\\begin{proposition}[Protecting Immutable Features]\n\\label{prp-mtblty}\nLet $f_\\theta(\\mathbf{x})=\\mathcal{S}(\\mathbf{M}_\\theta(\\mathbf{x}))=\\mathcal{S}(\\Theta\\mathbf{x})$ denote a linear classifier with softmax activation $\\mathcal{S}$ where $y\\in\\{1,...,K\\}=\\mathcal{K}$ and $\\mathbf{x} \\in \\mathbb{R}^D$. Assume multivariate Gaussian class densities with common diagonal covariance matrix $\\Sigma_k=\\Sigma$ for all $k \\in \\mathcal{K}$, then protecting an immutable feature from the contrastive divergence penalty will result in lower classifier sensitivity to that feature relative to the remaining features, provided that at least one of those is discriminative and mutable.\n\\end{proposition}\n\n\n\n# Experiments {#sec-experiments}\n\nWe seek to answer the following four research questions:\n\n\\begin{enumerate}[label={(\\makebox[2em][c]{RQ\\arabic*})}, leftmargin=3.5em]\n    \\item To what extent does the CT objective in Equation 1 induce models to learn plausible explanations?\n    \\item To what extent does CT result in more favorable algorithmic recourse outcomes in the presence of actionability constraints?\n    \\item To what extent does CT influence the adversarial robustness of trained models?\n    \\item What are the effects of hyperparameter selection on counterfactual training?\n\\end{enumerate}\n\n## Experimental Setup\n\nOur focus is the improvement in explainability (Def. \\ref{def-explainability}). Thus, we primarily look at the plausibility and cost of faithfully generated counterfactuals at test time. Other metrics, such as validity and redundancy, are reported in the supplementary appendix. To measure the cost, we follow the standard proxy of distances ($\\ell_1$-norm) between factuals and counterfactuals. For plausibility, we assess how similar CEs are to observed samples in the target domain, $\\mathbf{X}^+\\subset\\mathcal{X}^+$. We rely on the metric used by @altmeyer2024faithful,\n$$\n\\text{IP}(\\mathbf{x}^\\prime,\\mathbf{X}^+) = \\frac{1}{\\lvert\\mathbf{X}^+\\rvert}\\sum_{\\mathbf{x} \\in \\mathbf{X}^+} \\text{dist}(\\mathbf{x}^{\\prime},\\mathbf{x})\n$$ {#eq-impl-dist}\nand introduce a novel divergence-based adaptation,\n$$\n\\text{IP}^*(\\mathbf{X}^\\prime,\\mathbf{X}^+) = \\text{MMD}(\\mathbf{X}^\\prime,\\mathbf{X}^+)\n$$ {#eq-impl-div}\nwhere $\\mathbf{X}^\\prime$ denotes a collection of counterfactuals and $\\text{MMD}(\\cdot)$ is the unbiased estimate of the squared population maximum mean discrepancy, proposed by @gretton2012kernel. The metric in @eq-impl-div is equal to zero if and only if the two distributions are exactly the same, $\\mathbf{X}^\\prime=\\mathbf{X}^+$.\n\nTo assess outcomes with respect to actionability for non-linear models, we look at the average costs of valid counterfactuals in terms of their distances from factual starting points. While this an imperfect proxy of sensitivity, we hypothesize that CT can reduce these costs by teaching models to seek plausibility with respect to mutable features, much like we observe in @fig-poc in panel (d) compared to (c). We supplement this analysis with qualitative findings for integrated gradients [@sundararajan2017ig]. Finally, for predictive performance, we use standard metrics, such as robust accuracy estimated on adversarially perturbed data using FGSM [@goodfellow2014explaining].\n\nWe run experiments with three gradient-based generators: *Generic* of @wachter2017counterfactual as a simple baseline approach, *REVISE* [@joshi2019realistic] that aims to generate plausible counterfactuals using a surrogate Variational Autoencoder (VAE), and *ECCCo* [@altmeyer2024faithful], which targets faithfulness.\n\nWe make use of nine classification datasets common in the CE/AR literature. Four of them are synthetic with two classes and different characteristics: linearly separable clusters (*LS*), overlapping clusters (*OL*), concentric circles (*Circ*), and interlocking moons (*Moon*). Next, we have four real-world binary tabular datasets: *Adult* (Census data) of @becker1996adult2, California housing (*CH*) of @pace1997sparse, Default of Credit Card Clients (*Cred*) of @yeh2016default, and Give Me Some Credit (*GMSC*) from @kaggle2011give. Finally, for the convenience of illustration, we use the 10-class *MNIST* [@lecun1998mnist].\n\nTo assess CT, we investigate the improvements in performance metrics when using it on top of a weak baseline (BL): a multilayer perceptron (*MLP*). This is the best way to get a clear picture of the effectiveness of CT, and it is consistent with evaluation practices in the related literature [@goodfellow2014explaining;@ross2021learning;@teney2020learning].\n\n## Experimental Results\n\nOur main results for plausibility and actionability for *MLP* models are summarised in @tbl-main that presents counterfactual outcomes grouped by dataset along with standard errors averaged across bootstrap samples. Asterisks ($^*$) are used when the bootstrapped 99%-confidence interval of differences in mean outcomes does *not* include zero, so the observed effects are statistically significant at the 0.01 level.\n\nThe first two columns ($\\text{IP}$ and $\\text{IP}^*$) show the percentage reduction in implausibility for our two metrics when using CT on top of the weak baseline. As an example, consider the first row for *LS* data: the observed positive values indicate that faithful counterfactuals are around 30-55% more plausible for models trained with CT, in line with our observations in panel (b) of @fig-poc compared to panel (a).\n\nThe third column shows the results for a scenario when mutability constraints are imposed on the selected features. Again, we are comparing CT to the baseline, so reductions in the positive direction imply that valid counterfactuals are \"cheaper\" (more actionable) when using CT with feature protection. Relating this back to @fig-poc, the third column represents the reduction in distances travelled by counterfactuals in panel (d) compared to panel (c). In the following paragraphs, we summarize the results for all datasets.\n\n::: {#tbl-main}\n```{=latex}\n\\begin{table}[h]\n\\small\n\\centering\n\\begin{tabular}{\n  l\n  S[table-format=2.2(1.2)]\n  S[table-format=3.2(3.2)]\n  S[table-format=3.2(1.2)]\n}\n  \\toprule\n  \\textbf{Data} & \\textbf{$ \\text{IP} $ $(-\\%)$} & \\textbf{$ \\text{IP}^* $ $(-\\%)$} & \\textbf{Cost $(-\\%)$} \\\\\\midrule\n  LS & 29.05\\pm0.67 $^{*}$ & 55.33\\pm2.03 $^{*}$ & 14.07\\pm0.6 $^{*}$ \\\\\n  Circ & 56.29\\pm0.44 $^{*}$ & 89.38\\pm9.3 $^{*}$ & 45.55\\pm0.76 $^{*}$ \\\\\n  Moon & 20.62\\pm0.69 $^{*}$ & 19.26\\pm8.12 $^{*}$ & 2.86\\pm1.03 $^{*}$ \\\\\n  OL & -1.13\\pm0.88 $^{}$ & -24.52\\pm14.52 $^{}$ & 38.39\\pm2.21 $^{*}$ \\\\\\midrule\n  Adult & 0.77\\pm1.34 $^{}$ & 32.29\\pm6.87 $^{*}$ & -2.82\\pm4.88 $^{}$ \\\\\n  CH & 12.05\\pm1.41 $^{*}$ & 70.27\\pm3.72 $^{*}$ & 40.71\\pm1.55 $^{*}$ \\\\\n  Cred & 12.31\\pm1.84 $^{*}$ & 54.89\\pm11.21 $^{*}$ & -17.43\\pm5.17 $^{*}$ \\\\\n  GMSC & 23.44\\pm1.99 $^{*}$ & 73.31\\pm4.83 $^{*}$ & 62.64\\pm2.04 $^{*}$ \\\\\n  MNIST & 7.05\\pm1.8 $^{*}$ & -25.09\\pm109.05 $^{}$ & -12.34\\pm6.52 $^{}$ \\\\\\midrule\n  Avg. & 17.83 & 38.35 & 19.07 \\\\\\bottomrule\n\\end{tabular}\n\\end{table}\n```\n\nKey evaluation metrics for valid counterfactual along with bootstrapped standard errors for all datasets. **Plausibility** (columns 1-2): percentage reduction in implausibility for $\\text{IP}$ and $\\text{IP}^*$, respectively; **Cost** / **Actionability** (column 3): percentage reduction in costs when selected features are protected. Outcomes are aggregated across bootstrap samples (100 rounds) and varying degrees of the energy penalty $\\lambda_{\\text{egy}}$ used for *ECCCo* at test time. Asterisks ($^*$) indicate that the bootstrapped 99%-confidence interval of differences in mean outcomes does *not* include zero.\n:::\n\n### Plausibility (RQ1). {#sec-plaus}\n*CT generally produces substantial and statistically significant improvements in plausibility.*\n\nAverage reductions in $\\text{IP}$ range from around 7% for *MNIST* to almost 60% for *Circ*. For the real-world tabular datasets they are around 12% for *CH* and *Cred* and almost 25% for *GMSC*; for *Adult* and *OL* we find no significant impact of CT on $\\text{IP}$. Reductions in $\\text{IP}^*$ are even more substantial and generally statistically significant, although the average degree of uncertainty is higher than for $\\text{IP}$: reductions range from around 20% (*Moons*) to almost 90% (*Circ*). The only negative findings are for OL and MNIST, but they are not statistically significant. A qualitative inspection of the counterfactuals in @fig-mnist (columns 2-5) suggests recognizable digits 1-4 for the model trained with CT (bottom row), unlike the baseline (top row).\n\n![Visual explanations for *MNIST* for BL (top) and CT (bottom). **Plausibility**: col. 1 is a random factual 0 (blue); cols. 2-5 are corresponding *ECCCo* counterfactuals in target classes 1 to 4. **Actionability**: cols. 6-10 show integrated gradients averaged over test images in classes 5 to 9.](/paper/figures/mnist_body.png){#fig-mnist}\n\n### Actionability (RQ2). {#sec-act}\n*CT tends to improve actionability in the presence of immutable features, but this is not guaranteed if the assumptions in Proposition \\ref{prp-mtblty} are violated.*\n\nFor synthetic datasets, we always protect the first feature; for all real-world tabular datasets we could identify and protect an *age* variable; for *MNIST*, we protect the five upper and lower pixel rows of the full image. Statistically significant reductions in costs overwhelmingly point in the expected positive direction reaching up to around 60% for *GMSC*. Only in the case of *Cred*, average costs increase, likely because any potential benefits from protecting the *age* are outweighed by the increase in costs required for greater plausibility. The findings for *Adult* and *MNIST* are not significant. A qualitative inspection of the class-conditional integrated gradients in @fig-mnist (columns 6-10) suggests that CT still has the expected effect: the model (bottom) is insensitive (blue) to the protected rows of pixels; details of this experiment are reported in the supplementary appendix.\n\n![Test accuracies on adversarially perturbed data with varying perturbation sizes for all non-synthetic datasets.](/paper/figures/acc.png){#fig-acc fig-env=\"figure*\"}\n\n### Predictive Performance (RQ3). {#sec-pred}\n*Models trained with CT are substantially more robust to gradient-based adversarial attacks than conventionally-trained baselines.*\n\nTest accuracies on adversarially perturbed data are shown in @fig-acc. The perturbations size, $\\varepsilon\\in[0,0.1]$, increases along the horizontal axis and includes zero, corresponding to standard test accuracy for non-perturbed data. For all synthetic datasets, predictive performance of CT is virtually identical to the baseline and unaffected by perturbations. For all real-world datasets, we find that CT substantially improves robustness: while in some cases baseline accuracies drop to essentially zero for large enough perturbation sizes, accuracies of CT models remain remarkably robust.\n\n### Hyperparameter settings (RQ4). {#sec-hyperparameters}\n*CT is highly sensitive to the choice of a CE generator and its hyperparameters but (1) we observe manageable patterns, and (2) we can usually identify settings that improve either plausibility or actionability, and typically both of them at the same time.*\n\nWe evaluate the impacts of three types of hyperparameters on CT. In this section we focus on the highlights and make the full results available in the supplementary appendix.\n\nFirstly, we find that optimal results are generally obtained when using *ECCCo* to generate counterfactuals. Conversely, using a generator that may inhibit faithfulness (*REVISE*), tends to yield poor results. Concerning hyperparameters that guide the gradient-based counterfactual search, we find that increasing $T$, the maximum number of steps, generally yields better outcomes because more CEs can mature. Relatedly, we also find that the effectiveness and stability of CT is positively associated with the total number of counterfactuals generated during each training epoch. The impact of $\\tau$, the decision threshold, is more difficult to predict. On \"harder\" datasets it may be difficult to satisfy high $\\tau$ for any given sample (i.e., also factuals) and so increasing this threshold does not seem to correlate with better outcomes. In fact, $\\tau=0.5$ generally leads to optimal results as it is associated with high proportions of mature counterfactuals.\n\nSecondly, the strength of the energy regularization, $\\lambda_{\\text{reg}}$ is highly impactful and should be set sufficiently high to avoid common problems associated with exploding gradients. The sensitivity with respect to $\\lambda_{\\text{div}}$ and $\\lambda_{\\text{adv}}$ is much less evident. While high values of $\\lambda_{\\text{reg}}$ may increase the variability in outcomes when combined with high values of $\\lambda_{\\text{div}}$ or $\\lambda_{\\text{adv}}$, this effect is not particularly pronounced.\n\nFinally, we also observe desired improvements when CT was combined with conventional training and applied only for the final 50% of epochs of the complete training process. Put differently, CT can improve the explainability of models in a post-hoc, fine-tuning manner.\n\n\n\n# Discussion {#sec-discussion}\n\nAs our results indicate, counterfactual training produces models that are more explainable. Nonetheless, these advantages come at the cost of two important limitations.  \n\n*Interventions on features have implications for fairness.* We provide a method to modify the sensitivity of a model to certain features, which can be misused by enforcing explanations based on features that are more difficult to modify by a (group of) decision subjects. Such abuse could result in an unfairly assigned burden of recourse [@sharma2020certifai], threatening the equality of opportunity [@bell2024fairness]. Also, even if all immutable features are protected, there may exist proxies that are theoretically mutable, but preserve sufficient information about the principals to hinder these protections. Indeed, deciding on the actionability of features remains a major open challenge in the AR literature [@venkatasubramanian2020philosophical].\n\n*Plausibility is costly.* As noted by @altmeyer2024faithful, more plausible counterfactuals are inevitably more costly. CT improves plausibility and robustness, but it can impact average costs and validity when cheap, implausible and adversarial explanations are removed from the solution space.\n\n*CT increases the training times.* Just like contrastive and robust learning, CT is more resource-intensive than conventional regimes. Three factors mitigate this effect: (1) CT yields itself to parallel execution; (2) it amortizes the cost of CEs for the training samples; and (3) it can be used to fine-tune conventionally-trained models.  \n\nWe also highlight three key directions for future research. Firstly, it is an interesting challenge to extend CT beyond classification settings. Our formulation relies on the distinction between non-target class(es) and target class(es), requiring the output space to be discrete. Thus, it does not apply to ML tasks where the change in outcome cannot be readily discretized. Focus on classification is a common choice in research on CEs and AR; other settings have attracted some interest, e.g., regression [@spooner2021counterfactual], but there is little consensus how to robustly extend the notion of CEs.\n\nSecondly, our analysis covers CE generators with different characteristics, but it is interesting to extend it to more algorithms, including ones that do not rely on computationally costly gradient-based optimization. This should reduce training costs while possibly preserving the benefits of CT.\n\nFinally, we believe that it is possible to considerably improve hyperparameter selection procedures, and thus performance. We have relied exclusively on grid searches, but future work could benefit from more sophisticated approaches.\n\n\n\n# Conclusion {#sec-conclusion}\n\nState-of-the-art machine learning models are prone to learning complex representations that cannot be interpreted by humans. Existing explainability solutions cannot guarantee that explanations agree with these learned representation. As a step towards addressing this challenge, we introduce counterfactual training, a novel training regime that integrates recent advances in contrastive learning, adversarial robustness, and counterfactual explanations to incentivize highly-explainable models. Through extensive experiments, we demonstrate that CT satisfies this goal while preserving the predictive performance and promoting robustness of models. Explanations generated from CT-based models are both more plausible (compliant with the underlying data-generating process) and more actionable (compliant with user-specified mutability constraints), and thus meaningful to their recipients. In turn, our work highlights the value of simultaneously improving models and their explanations.\n\n\n\n\n# References {-}\n\n::: {#refs}\n:::\n\n{{< pagebreak >}}\n\n```{=latex}\n\\begin{appendices}\n```\n\n# Notation {.appendix}\n\nBelow we provide an overview of some notation used frequently throughout the paper:\n\n- $y^+$: The target class and also the index of the target class.\n- $y^-$: The non-target class and also the index of non-the target class.\n- $\\mathbf{x}$: a single training sample.\n- $\\mathbf{x}^\\prime$: a counterfactual. \n- $\\mathbf{x}^+$: a training sample in the target class (ground-truth).\n- $\\mathbf{y}^+$: The one-hot encoded output vector for the target class. \n- $\\theta$: Model parameters (unspecified).\n- $\\Theta$: Matrix of parameters. \n- $\\mathbf{M}(\\cdot)$: linear predictions (logits) of the classifier.\n\n## Other Technical Details\n\nMaximum mean discrepancy is defined as follows,\n\n$$\n\\begin{aligned}\n\\text{MMD}({X}^\\prime,\\tilde{X}^\\prime) &= \\frac{1}{m(m-1)}\\sum_{i=1}^m\\sum_{j\\neq i}^m k(x_i,x_j) \\\\ &+ \\frac{1}{n(n-1)}\\sum_{i=1}^n\\sum_{j\\neq i}^n k(\\tilde{x}_i,\\tilde{x}_j) \\\\ &- \\frac{2}{mn}\\sum_{i=1}^m\\sum_{j=1}^n k(x_i,\\tilde{x}_j)\n\\end{aligned}\n$$ {#eq-mmd}\n\nwhere $k(\\cdot,\\cdot)$ is a kernel function [@gretton2012kernel]. We make use of a Gaussian kernel with a constant length-scale parameter of $0.5$. In our implementation, @eq-mmd is by default applied to the entire subset of the training data for which $y=y^+$.\n\n\n\n# Technical Details of Our Approach {.appendix} \n\n## Generating Counterfactuals through Gradient Descent {#sec-app-ce}\n\nIn this section, we provide some background on gradient-based counterfactual generators (@sec-app-ce-background) and discuss how we define convergence in this context (@sec-app-conv).\n\n### Background {#sec-app-ce-background}\n\nGradient-based counterfactual search was originally proposed by @wachter2017counterfactual. It generally solves the following unconstrained objective,\n\n$$\n\\begin{aligned}\n\\min_{\\mathbf{z}^\\prime \\in \\mathcal{Z}^L} \\left\\{  {\\text{yloss}(\\mathbf{M}_{\\theta}(g(\\mathbf{z}^\\prime)),\\mathbf{y}^+)}+ \\lambda {\\text{cost}(g(\\mathbf{z}^\\prime)) }  \\right\\} \n\\end{aligned} \n$$\n\nwhere $g: \\mathcal{Z} \\mapsto \\mathcal{X}$ is an invertible function that maps from the $L$-dimensional counterfactual state space to the feature space and $\\text{cost}(\\cdot)$ denotes one or more penalties that are used to induce certain properties of the counterfactual outcome. As above, $\\mathbf{y}^+$ denotes the target output and $\\mathbf{M}_{\\theta}(\\mathbf{x})$ returns the logit predictions of the underlying classifier for $\\mathbf{x}=g(\\mathbf{z})$.\n\nFor all generators used in this work we use standard logit crossentropy loss for $\\text{yloss}(\\cdot)$. All generators also penalize the distance ($\\ell_1$-norm) of counterfactuals from their original factual state. For *Generic* and *ECCo*, we have $\\mathcal{Z}:=\\mathcal{X}$ and $g(\\mathbf{z})=g(\\mathbf{z})^{-1}=\\mathbf{z}$, that is counterfactual are searched directly in the feature space. Conversely, *REVISE* traverses the latent space of a variational autoencoder (VAE) fitted to the training data, where $g(\\cdot)$ corresponds to the decoder [@joshi2019realistic]. In addition to the distance penalty, *ECCo* uses an additional penalty component that regularizes the energy associated with the counterfactual, $\\mathbf{x}^\\prime$ [@altmeyer2024faithful]. \n\n<!-- TODO: Add note on why we omit the conformal prediction component. -->\n\n### Convergence {#sec-app-conv}\n\nAn important consideration when generating counterfactual explanations using gradient-based methods is how to define convergence. Two common choices are to 1) perform gradient descent over a fixed number of iterations $T$, or 2) conclude the search as soon as the predicted probability for the target class has reached a pre-determined threshold, $\\tau$: $\\mathcal{S}(\\mathbf{M}_\\theta(\\mathbf{x}^\\prime))[y^+] \\geq \\tau$. We prefer the latter for our purposes, because it explicitly defines convergence in terms of the black-box model, $\\mathbf{M}(\\mathbf{x})$.\n\nDefining convergence in this way allows for a more intuitive interpretation of the resulting counterfactual outcomes than with fixed $T$. Specifically, it allows us to think of counterfactuals as explaining 'high-confidence' predictions by the model for the target class $y^+$. Depending on the context and application, different choices of $\\tau$ can be considered as representing 'high-confidence' predictions.\n\n\n\n\n\n\n## Protecting Mutability Constraints with Linear Classifiers {#sec-app-constraints}\n\nIn @sec-constraints we explain that to avoid penalizing implausibility that arises due to mutability constraints, we impose a point mass prior on $p(\\mathbf{x})$ for the corresponding feature. We argue in @sec-constraints that this approach induces models to be less sensitive to immutable features and demonstrate this empirically in @sec-experiments. Below we derive the analytical results in Prp.~\\ref{prp-mtblty}.\n\n::: {.proof}\n\nLet $d_{\\text{mtbl}}$ and $d_{\\text{immtbl}}$ denote some mutable and immutable feature, respectively. Suppose that $\\mu_{y^-,d_{\\text{immtbl}}} < \\mu_{y^+,d_{\\text{immtbl}}}$ and $\\mu_{y^-,d_{\\text{mtbl}}} > \\mu_{y^+,d_{\\text{mtbl}}}$, where $\\mu_{k,d}$ denotes the conditional sample mean of feature $d$ in class $k$. In words, we assume that the immutable feature tends to take lower values for samples in the non-target class $y^-$ than in the target class $y^+$. We assume the opposite to hold for the mutable feature.\n\nAssuming multivariate Gaussian class densities with common diagonal covariance matrix $\\Sigma_k=\\Sigma$ for all $k \\in \\mathcal{K}$, we have for the log likelihood ratio between any two classes $k,m \\in \\mathcal{K}$ [@hastie2009elements]:\n\n$$\n\\log \\frac{p(k|\\mathbf{x})}{p(m|\\mathbf{x})}=\\mathbf{x}^\\intercal \\Sigma^{-1}(\\mu_{k}-\\mu_{m})  + \\text{const}\n$$ {#eq-loglike}\n\nBy independence of $x_1,...,x_D$, the full log-likelihood ratio decomposes into:\n\n$$\n\\log \\frac{p(k|\\mathbf{x})}{p(m|\\mathbf{x})} = \\sum_{d=1}^D \\frac{\\mu_{k,d}-\\mu_{m,d}}{\\sigma_{d}^2} x_{d} + \\text{const}\n$$ {#eq-loglike-decomp}\n\nBy the properties of our classifier (*multinomial logistic regression*), we have:\n\n$$\n\\log \\frac{p(k|\\mathbf{x})}{p(m|\\mathbf{x})} = \\sum_{d=1}^D \\left( \\theta_{k,d} - \\theta_{m,d} \\right)x_d + \\text{const}\n$$ {#eq-multi}\n\nwhere $\\theta_{k,d}=\\Theta[k,d]$ denotes the coefficient on feature $d$ for class $k$. \n\nBased on @eq-loglike-decomp and @eq-multi we can identify that $(\\mu_{k,d}-\\mu_{m,d}) \\propto (\\theta_{k,d} - \\theta_{m,d})$ under the assumptions we made above. Hence, we have that $(\\theta_{y^-,d_{\\text{immtbl}}} - \\theta_{y^+,d_{\\text{immtbl}}}) < 0$ and $(\\theta_{y^-,d_{\\text{mtbl}}} - \\theta_{y^+,d_{\\text{mtbl}}}) > 0$\n\nLet $\\mathbf{x}^\\prime$ denote some randomly chosen individual from class $y^-$ and let $y^+ \\sim p(y)$ denote the randomly chosen target class. Then the partial derivative of the contrastive divergence penalty [@eq-div] with respect to coefficient $\\theta_{y^+,d}$ is equal to \n\n$$\n\\frac{\\partial}{\\partial\\theta_{y^+,d}} \\left(\\text{div}(\\mathbf{x}^+,\\mathbf{x^\\prime},\\mathbf{y};\\theta)\\right) = \\frac{\\partial}{\\partial\\theta_{y^+,d}} \\left( \\left(-\\mathbf{M}_\\theta(\\mathbf{x}^+)[y^+]\\right) - \\left(-\\mathbf{M}_\\theta(\\mathbf{x}^\\prime)[y^+]\\right) \\right) = x_{d}^\\prime - x^+_{d}\n$$ {#eq-grad}\n\nand equal to zero everywhere else.\n\nSince $(\\mu_{y^-,d_{\\text{immtbl}}} < \\mu_{y^+,d_{\\text{immtbl}}})$ we are more likely to have $(x_{d_{\\text{immtbl}}}^\\prime - x^+_{d_{\\text{immtbl}}}) < 0$ than vice versa at initialization. Similarly, we are more likely to have $(x_{d_{\\text{mtbl}}}^\\prime - x^+_{d_{\\text{mtbl}}}) > 0$ since $(\\mu_{y^-,d_{\\text{mtbl}}} > \\mu_{y^+,d_{\\text{mtbl}}})$.\n\nThis implies that if we do not protect feature $d_{\\text{immtbl}}$, the contrastive divergence penalty will decrease $\\theta_{y^-,d_{\\text{immtbl}}}$ thereby exacerbating the existing effect $(\\theta_{y^-,d_{\\text{immtbl}}} - \\theta_{y^+,d_{\\text{immtbl}}}) < 0$. In words, not protecting the immutable feature would have the undesirable effect of making the classifier more sensitive to this feature, in that it would be more likely to predict class $y^-$ as opposed to $y^+$ for lower values of $d_{\\text{immtbl}}$. \n\nBy the same rationale, the contrastive divergence penalty can generally be expected to increase $\\theta_{y^-,d_{\\text{mtbl}}}$ exacerbating $(\\theta_{y^-,d_{\\text{mtbl}}} - \\theta_{y^+,d_{\\text{mtbl}}}) > 0$. In words, this has the effect of making the classifier more sensitive to the mutable feature, in that it would be more likely to predict class $y^-$ as opposed to $y^+$ for higher values of $d_{\\text{mtbl}}$.\n\nThus, our proposed approach of protecting feature $d_{\\text{immtbl}}$ has the net affect of decreasing the classifier's sensitivity to the immutable feature relative to the mutable feature (i.e. no change in sensitivity for $d_{\\text{immtbl}}$ relative to increased sensitivity for $d_{\\text{mtbl}}$).\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Domain Constraints\n\nWe apply domain constraints on counterfactuals during training and evaluation. There are at least two good reasons for doing so. Firstly, within the context of explainability and algorithmic recourse, real-world attributes are often domain constrained: the *age* feature, for example, is lower bounded by zero and upper bounded by the maximum human lifespan. Secondly, domain constraints help mitigate training instabilities commonly associated with energy-based modelling [@grathwohl2020your;@altmeyer2024faithful].\n\nFor our image datasets, features are pixel values and hence the domain is constrained by the lower and upper bound of values that pixels can take depending on how they are scaled (in our case $[-1,1]$). For all other features $d$ in our synthetic and tabular datasets, we automatically infer domain constraints $[x_d^{\\text{LB}},x_d^{\\text{UB}}]$  as follows,\n\n$$\n\\begin{aligned}\nx_d^{\\text{LB}} &= \\arg\\min_{x_d} \\{\\mu_d - n_{\\sigma_d}\\sigma_d, \\arg \\min_{x_d} x_d\\} \\\\\nx_d^{\\text{UB}} &= \\arg\\max_{x_d} \\{\\mu_d + n_{\\sigma_d}\\sigma_d, \\arg \\max_{x_d} x_d\\} \n\\end{aligned}\n$$ {#eq-domain}\n\nwhere $\\mu_d$ and $\\sigma_d$ denote the sample mean and standard deviation of feature $d$. We set $n_{\\sigma_d}=3$ across the board but higher values and hence wider bounds may be appropriate depending on the application.\n\n\n\n\n\n\n## Training Hyperparameters {#sec-app-training}\n\n@nte-train-default presents the default hyperparameters used during training. \n\n::: {#nte-train-default .callout-note}\n\n## Training Phase\n\n- Meta Parameters:\n    - Generator: `ecco`\n    - Model: `mlp`\n- Model:\n    - Activation: `relu`\n    - No. Hidden: `32`\n    - No. Layers: `1`\n- Training Parameters:\n    - Burnin: `0.0`\n    - Class Loss: `logitcrossentropy`\n    - Convergence: `threshold`\n    - Generator Parameters:\n        - Decision Threshold: `0.75`\n        - $\\lambda_{\\text{cst}}$: `0.001`\n        - $\\lambda_{\\text{egy}}$: `5.0`\n        - Learning Rate: `0.25`\n        - Maximum Iterations: `30`\n        - Optimizer: `sgd`\n        - Type: `ECCo`\n    - $\\lambda_{\\text{adv}}$: `0.25`\n    - $\\lambda_{\\text{clf}}$: `1.0`\n    - $\\lambda_{\\text{div}}$: `0.5`\n    - $\\lambda_{\\text{reg}}$: `0.1`\n    - Learning Rate: `0.001`\n    - No. Counterfactuals: `1000`\n    - No. Epochs: `100`\n    - Objective: `full`\n    - Optimizer: `adam`\n\n\n\n\n:::\n\n## Evaluation Details {#sec-app-eval}\n\nFor all of our evaluations, we proceed as follows: for each experiment setting we generate multiple counterfactuals (\"No. Counterfactuals\"), randomly choosing the factual and target class each time (@nte-eval-default). We do this across multiple rounds (\"No. Runs\") with different random seeds to account for stochasticity (@nte-eval-default). This is in line with standard practice in the related literature on CE. @nte-eval-default presents the default hyperparameters used during evaluation. For our final results presented in the main paper, we rely on held out test sets to sample factuals (and outputs for our performance metrics). For tuning purposes we rely on training or validation sets. \n\n### Robust Accuracy\n\nTo evaluate robust accuracy (Acc.$^*$), we use the Fast Gradient Sign Method (FGSM) to perturb test samples [@goodfellow2014explaining]. For the main results, we have set the perturbation size to $\\epsilon=0.03$. We have also tested other perturbation sizes, as well as randomly perturbed data. Although not reported here, we have consistently found strong outperformance of CT compared to the weak baseline. \n\n::: {#nte-eval-default .callout-note}\n\n## Evaluation Phase\n\n- Counterfactual Parameters:\n    - Convergence: `threshold`\n    - Decision Threshold: `0.95`\n    - Generator Parameters:\n        - Decision Threshold: `0.75`\n        - $\\lambda_{\\text{cst}}$: `0.001`\n        - $\\lambda_{\\text{egy}}$: `5.0`\n        - Learning Rate: `0.25`\n        - Maximum Iterations: `30`\n        - Optimizer: `sgd`\n        - Type: `ECCo`\n    - Maximum Iterations: `50`\n    - No. Individuals: `100`\n    - No. Runs: `5`\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\\FloatBarrier\n\n# Details on Main Experiments {#sec-app-main .appendix}\n\n## Final Hyperparameters\n\nAs discussed @sec-experiments, CT is sensitive to certain hyperparameter choices. We study the effect of many hyperparameters extensively in @sec-app-grid. For the main results, we tune a small set of key hyperparameters (@sec-app-tune). The final choices for the main results are presented for each data set in @tbl-final-params along with training, test and batch sizes.\n\n::: {#tbl-final-params}\n\n::: {.content-hidden unless-format=\"pdf\"}\n\n\\begin{tabular}{cccccccc}\n  \\toprule\n  \\textbf{Data} & \\textbf{No. Train} & \\textbf{No. Test} & \\textbf{Batchsize} & \\textbf{Domain} & \\textbf{Decision Threshold} & \\textbf{No. Counterfactuals} & \\textbf{$\\lambda_{\\text{reg}}$} \\\\\\midrule\n  LS & 3600 & 600 & 30 & none & 0.5 & 1000 & 0.01 \\\\\n  Circ & 3600 & 600 & 30 & none & 0.5 & 1000 & 0.5 \\\\\n  Moon & 3600 & 600 & 30 & none & 0.9 & 1000 & 0.25 \\\\\n  OL & 3600 & 600 & 30 & none & 0.5 & 1000 & 0.25 \\\\\\midrule\n  Adult & 26049 & 5010 & 1000 & none & 0.75 & 5000 & 0.25 \\\\\n  CH & 16504 & 3101 & 1000 & none & 0.5 & 5000 & 0.25 \\\\\n  Cred & 10617 & 1923 & 1000 & none & 0.5 & 5000 & 0.25 \\\\\n  GMSC & 13371 & 2474 & 1000 & none & 0.5 & 5000 & 0.5 \\\\\n  MNIST & 11000 & 2000 & 1000 & (-1.0, 1.0) & 0.5 & 5000 & 0.01 \\\\\n\\end{tabular}\n\n\n\n:::\n\nFinal hyperparameters used for the main results presented in @sec-experiments. Any hyperparameter not shown here is set to its default value (@nte-train-default).\n\n:::\n\n## Final Results {#sec-app-final-results}\n\nPlus/minus two standard deviations of bootstrap estimates. \n\n<!-- Standard deviation of bootstrap is the standard error. -->\n\n\n\n\n\n\n\n\n### Robust Performance Plots\n\n\n\n\n### Confidence Intervals\n\n\n\n\n::: {#tbl-ci}\n\n\\begin{tabular}{lccccc}\n  \\toprule\n  \\textbf{Variable} & \\textbf{Data} & \\textbf{CT} & \\textbf{BL} & \\textbf{LB} & \\textbf{UB} \\\\\\midrule\n  Cost & Adult & 2.26 & 2.2 & -0.22 & 0.28 \\\\\n  Cost & CH & 1.46 & 2.46 & -1.1 & -0.89 \\\\\n  Cost & Circ & 0.67 & 1.23 & -0.58 & -0.53 \\\\\n  Cost & Cred & 2.68 & 2.29 & 0.16 & 0.63 \\\\\n  Cost & GMSC & 1.14 & 3.05 & -2.45 & -1.77 \\\\\n  Cost & LS & 3.82 & 4.44 & -0.7 & -0.56 \\\\\n  Cost & MNIST & 77.04 & 68.67 & -3.47 & 18.34 \\\\\n  Cost & Moon & 1.55 & 1.6 & -0.08 & -0.01 \\\\\n  Cost & OL & 1.62 & 2.63 & -1.15 & -0.81 \\\\\n  $ \\text{IP}^* $ & Adult & 0.07 & 0.11 & -0.06 & -0.01 \\\\\n  $ \\text{IP}^* $ & CH & 0.02 & 0.06 & -0.06 & -0.04 \\\\\n  $ \\text{IP}^* $ & Circ & 0.0 & 0.0 & -0.01 & -0.0 \\\\\n  $ \\text{IP}^* $ & Cred & 0.03 & 0.06 & -0.05 & -0.01 \\\\\n  $ \\text{IP}^* $ & GMSC & 0.02 & 0.07 & -0.06 & -0.04 \\\\\n  $ \\text{IP}^* $ & LS & 0.1 & 0.23 & -0.14 & -0.12 \\\\\n  $ \\text{IP}^* $ & MNIST & 0.04 & 0.04 & -0.1 & 0.09 \\\\\n  $ \\text{IP}^* $ & Moon & 0.02 & 0.02 & -0.01 & -0.0 \\\\\n  $ \\text{IP}^* $ & OL & 0.12 & 0.09 & -0.01 & 0.05 \\\\\n  $ \\text{IP} $ & Adult & 15.03 & 15.15 & -0.68 & 0.26 \\\\\n  $ \\text{IP} $ & CH & 6.61 & 7.52 & -1.17 & -0.63 \\\\\n  $ \\text{IP} $ & Circ & 1.03 & 2.36 & -1.37 & -1.29 \\\\\n  $ \\text{IP} $ & Cred & 19.31 & 22.03 & -3.69 & -1.74 \\\\\n  $ \\text{IP} $ & GMSC & 6.19 & 8.09 & -2.4 & -1.49 \\\\\n  $ \\text{IP} $ & LS & 2.41 & 3.4 & -1.04 & -0.94 \\\\\n  $ \\text{IP} $ & MNIST & 258.83 & 278.54 & -30.49 & -7.64 \\\\\n  $ \\text{IP} $ & Moon & 1.36 & 1.71 & -0.38 & -0.32 \\\\\n  $ \\text{IP} $ & OL & 4.49 & 4.44 & -0.03 & 0.13 \\\\\\bottomrule\n\\end{tabular}\n\n\n\nMean outcomes for **CT** and **BL** along with bootstrapped confidence intervals (99%) for difference in mean outcomes grouped by dataset and evaluation metric. Column **LB** and **UB** show the lower and upper bound of the intervals, respectively, and computed using the percentile method. The underlying counterfactual evaluations are the same as the ones used to produce @tbl-main. \n\n:::\n\n### Qualitative Findings for Image Data\n\n\n\n\n\n\n@fig-mnist shows much more plausible (faithful) counterfactuals for a model with CT than the model with conventional training (@fig-mnist-vanilla).\n\n::: {layout=\"[10,-2,10]\" layout-valign=\"top\"}\n![Counterfactual images for *MLP* with counterfactual training. Factual images are shown on the diagonal, with the corresponding counterfactual for each target class (columns) in that same row. The underlying generator, *ECCo*, aims to generate counterfactuals that are faithful to the model [@altmeyer2024faithful].](/paper/figures/mnist_mlp.png){#fig-mnist}\n\n![The same setup, factuals, model architecture and generator as in @fig-mnist, but the model was trained conventionally.](/paper/figures/mnist_mlp_vanilla.png){#fig-mnist-vanilla}\n:::\n\n### Integrated Gradients\n\n:::{#tbl-ig}\n\n\\begin{tabular}{\nl\nS[table-format=2.2(3.2)]\nS[table-format=2.2(2.2)]\n}\n  \\toprule\n  \\textbf{Data} & \\textbf{CT} & \\textbf{BL} \\\\\\midrule\n  LS & 0.03 \\pm 0.02 & 275.23 \\pm 2389.26 \\\\\n  Circ & 9.58 \\pm 32.17 & 34.76 \\pm 154.26 \\\\\n  Moon & 15.05 \\pm 44.79 & 0.69 \\pm 0.5 \\\\\n  OL & 1.38 \\pm 2.24 & 7.9 \\pm 12.03 \\\\\\midrule\n  Adult & 0.43 \\pm 0.04 & 0.97 \\pm 0.05 \\\\\n  CH & 0.09 \\pm 0.03 & 0.22 \\pm 0.06 \\\\\n  Cred & 0.0 \\pm 0.01 & 0.43 \\pm 0.06 \\\\\n  GMSC & 1.0 \\pm 0.0 & 0.26 \\pm 0.13 \\\\\n  MNIST & 0.18 \\pm 0.02 & 0.43 \\pm 0.06 \\\\\n\\end{tabular}\n\n\n\nIntegrated gradients.\n\n:::\n\n### Costs\n\n\n\n\n\n::: {#tbl-costs}\n\n\\begin{tabular}{\nl\nS[table-format=2.2(1.2)]\n}\n  \\toprule\n  \\textbf{Data} & \\textbf{Cost $(-\\%)$} \\\\\\midrule\n  LS & -26.82\\pm0.86 $^{*}$ \\\\\n  Circ & 40.97\\pm0.82 $^{*}$ \\\\\n  Moon & 33.83\\pm0.98 $^{*}$ \\\\\n  OL & 10.35\\pm1.28 $^{*}$ \\\\\\midrule\n  Adult & 1.16\\pm3.53 $^{}$ \\\\\n  CH & -34.89\\pm2.31 $^{*}$ \\\\\n  Cred & 28.24\\pm1.08 $^{*}$ \\\\\n  GMSC & 3.54\\pm5.78 $^{}$ \\\\\n  MNIST & -31.67\\pm7.72 $^{*}$ \\\\\\midrule\n  Avg. & 2.75 \\\\\\bottomrule\n\\end{tabular}\n\n\n\nCosts\n\n:::\n\n### Validity\n\n\n\n\n::: {#tbl-val}\n\n\\begin{tabular}{lcc}\n  \\toprule\n  \\textbf{Data} & \\textbf{CT} & \\textbf{BL} \\\\\\midrule\n  LS & 1.0 & 1.0 \\\\\n  Circ & 0.97 & 0.52 \\\\\n  Moon & 1.0 & 1.0 \\\\\n  OL & 0.87 & 0.98 \\\\\\midrule\n  Adult & 0.61 & 0.99 \\\\\n  CH & 0.96 & 1.0 \\\\\n  Cred & 0.7 & 1.0 \\\\\n  GMSC & 0.63 & 1.0 \\\\\n  MNIST & 1.0 & 1.0 \\\\\n\\end{tabular}\n\n\n\nValidity\n\n:::\n\n::: {#tbl-val-mtbl}\n\n\\begin{tabular}{lcc}\n  \\toprule\n  \\textbf{Data} & \\textbf{CT} & \\textbf{BL} \\\\\\midrule\n  LS & 1.0 & 1.0 \\\\\n  Circ & 0.67 & 0.49 \\\\\n  Moon & 0.99 & 0.98 \\\\\n  OL & 0.37 & 0.57 \\\\\\midrule\n  Adult & 0.56 & 0.99 \\\\\n  CH & 0.96 & 1.0 \\\\\n  Cred & 0.67 & 1.0 \\\\\n  GMSC & 0.38 & 1.0 \\\\\n  MNIST & 1.0 & 1.0 \\\\\n\\end{tabular}\n\n\n\nValidity\n\n:::\n\n\n\n\\FloatBarrier\n\n# Grid Searches {#sec-app-grid}\n\n\n\n\n\n\n\nTo assess the hyperparameter sensitivity of our proposed training regime we ran multiple large grid searches for all of our synthetic datasets. We have grouped these grid searches into multiple categories: \n\n1. **Generator Parameters** (@sec-app-grid-gen): Investigates the effect of changing hyperparameters that affect the counterfactual outcomes during the training phase.\n2. **Penalty Strengths** (@sec-app-grid-pen): Investigates the effect of changing the penalty strengths in out proposed objective (@eq-obj).\n3. **Other Parameters** (@sec-app-grid-train): Investigates the effect of changing other training parameters, including the total number of generated counterfactuals in each epoch.\n\nWe begin by summarizing the high-level findings in @sec-app-grid-hl. For each of the categories, @sec-app-grid-gen to @sec-app-grid-train then present all details including the exact parameter grids, average predictive performance outcomes and key evaluation metrics for the generated counterfactuals. \n\n## Evaluation Details\n\nTo measure predictive performance, we compute the accuracy and F1-score for all models on test data (@tbl-acc-gen, @tbl-acc-pen, @tbl-acc-train). With respect to explanatory performance, we report here our findings for the (im)plausibility and cost of counterfactuals at test time. Since the computation of our proposed divergence metric (@eq-impl-div) is memory-intensive, we rely on the distance-based metric for the grid searches. For the counterfactual evaluation, we draw factual samples from the training data for the grid searches to avoid data leakage with respect to our final results reported in the body of the paper. Specifically, we want to avoid choosing our default hyperparameters based on results on the test data. Since we are optimizing for explainability, not predictive performance, we still present test accuracy and F1-scores. \n\n### Predictive Performance\n\nWe find that CT is associated with little to no decrease in average predictive performance for our synthetic datasets: test accuracy and F1-scores decrease by at most ~1 percentage point, but generally much less (@tbl-acc-gen, @tbl-acc-pen, @tbl-acc-train). Variation across hyperparameters is negligible as indicated by small standard deviations for these metrics across the board. \n\n### Counterfactual Outcomes {#sec-app-grid-hl}\n\nOverall, we find that counterfactual training achieves it key objectives consistently across all hyperparameter settings and also broadly across datasets: plausibility is improved by up to 60 percent (%) for the *Circles* data (e.g. @fig-grid-gen_params-plaus-circles), 25-30% for the *Moons* data (e.g. @fig-grid-gen_params-plaus-moons) and 10-20% for the *Linearly Separable* data (e.g. @fig-grid-gen_params-plaus-lin_sep). At the same time, the average costs of faithful counterfactuals are reduced in many cases by around 20-25% for  *Circles* (e.g. @fig-grid-gen_params-cost-circles) and up to 50% for *Moons* (e.g. @fig-grid-gen_params-cost-moons). For the *Linearly Separable* data, costs are generally increased although typically by less than 10% (e.g. @fig-grid-gen_params-cost-lin_sep), which reflects a common tradeoff between costs and plausibility [@altmeyer2024faithful]. \n\nWe do observe strong sensitivity to certain hyperparameters, with clear an manageable patterns. Concerning generator parameters, we firstly find that using *REVISE* to generate counterfactuals during training typically yields the worst outcomes out of all generators, often leading to a substantial decrease in plausibility. This finding can be attributed to the fact that *REVISE* effectively assigns the task of learning plausible explanations from the model itself to a surrogate VAE. In other words, counterfactuals generated by *REVISE* are less faithful to the model that *ECCo* and *Generic*, and hence we would expect them to be a less effective and, in fact, potentially detrimental role in our training regime. Secondly, we observe that allowing for a higher number of maximum steps $T$ for the counterfactual search generally yields better outcomes. This is intuitive, because it allows more counterfactuals to reach maturity in any given iteration. Looking in particular at the results for *Linearly Separable*, it seems that higher values for $T$ in combination with higher decision thresholds ($\\tau$) yields the best results when using *ECCo*. But depending on the degree of class separability of the underlying data, a high decision-threshold can also affect results adversely, as evident from the results for the *Overlapping* data (@fig-grid-gen_params-plaus-over): here we find that CT generally fails to achieve its objective because only a tiny proportion of counterfactuals ever reaches maturity.\n\nRegarding penalty strengths, we find that the strength of the energy regularization, $\\lambda_{\\text{reg}}$ is a key hyperparameter, while sensitivity with respect to $\\lambda_{\\text{div}}$ and $\\lambda_{\\text{adv}}$ is much less evident. In particular, we observe that not regularizing energy enough or at all typically leads to poor performance in terms of decreased plausibility and increased costs, in particular for *Circles* (@fig-grid-pen-plaus-circles), *Linearly Separable* (@fig-grid-pen-plaus-lin_sep) and *Overlapping* (@fig-grid-pen-plaus-over). High values of $\\lambda_{\\text{reg}}$ can increase the variability in outcomes, in particular when combined with high values for $\\lambda_{\\text{div}}$ and $\\lambda_{\\text{adv}}$, but this effect is less pronounced.\n\nFinally, concerning other hyperparameters we observe that the effectiveness and stability of CT is positively associated with the number of counterfactuals generated during each training epoch, in particular for *Circles* (@fig-grid-train-plaus-circles) and *Moons* (@fig-grid-train-plaus-moons). We further find that a higher number of training epochs is beneficial as expected, where we tested training models for 50 and 100 epochs. Interestingly, we find that it is not necessary to employ CT during the entire training phase to achieve the desired improvements in explainability: specifically, we have tested training models conventionally during the first half of training before switching to CT after this initial burn-in period. \n\n## Generator Parameters {#sec-app-grid-gen}\n\n\n\n\nThe hyperparameter grid with varying generator parameters during training is shown in @nte-gen-params-final-run-train. The corresponding evaluation grid used for these experiments is shown in @nte-gen-params-final-run-eval.\n\n::: {#nte-gen-params-final-run-train .callout-note}\n\n## Training Phase\n\n- Generator Parameters:\n    - Decision Threshold: `0.75, 0.9, 0.95`\n    - $\\lambda_{\\text{egy}}$: `0.1, 0.5, 5.0, 10.0, 20.0`\n    - Maximum Iterations: `5, 25, 50`\n- Generator: `ecco, generic, revise`\n- Model: `mlp`\n- Training Parameters:\n    - Objective: `full, vanilla`\n\n\n\n\n:::\n\n::: {#nte-gen-params-final-run-eval .callout-note}\n\n## Evaluation Phase\n\n- Generator Parameters:\n    - $\\lambda_{\\text{egy}}$: `0.1, 0.5, 1.0, 5.0, 10.0`\n\n\n\n\n:::\n\n### Predictive Performance\n\nPredictive performance measures for this grid search are shown in @tbl-acc-gen.\n\n::: {#tbl-acc-gen}\n\n::: {.content-hidden unless-format=\"pdf\"}\n\n\\begin{longtable}{ccccc}\n  \\toprule\n  \\textbf{Dataset} & \\textbf{Variable} & \\textbf{Objective} & \\textbf{Mean} & \\textbf{Se} \\\\\\midrule\n  \\endfirsthead\n  \\toprule\n  \\textbf{Dataset} & \\textbf{Variable} & \\textbf{Objective} & \\textbf{Mean} & \\textbf{Se} \\\\\\midrule\n  \\endhead\n  \\bottomrule\n  \\multicolumn{5}{r}{Continuing table below.}\\\\\n  \\bottomrule\n  \\endfoot\n  \\endlastfoot\n  Circ & Accuracy & Full & 1.0 & 0.0 \\\\\n  Circ & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  Circ & F1-score & Full & 1.0 & 0.0 \\\\\n  Circ & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  LS & Accuracy & Full & 1.0 & 0.0 \\\\\n  LS & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  LS & F1-score & Full & 1.0 & 0.0 \\\\\n  LS & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  Moon & Accuracy & Full & 1.0 & 0.0 \\\\\n  Moon & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  Moon & F1-score & Full & 1.0 & 0.0 \\\\\n  Moon & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  OL & Accuracy & Full & 0.91 & 0.0 \\\\\n  OL & Accuracy & Vanilla & 0.92 & 0.0 \\\\\n  OL & F1-score & Full & 0.91 & 0.0 \\\\\n  OL & F1-score & Vanilla & 0.92 & 0.0 \\\\\\bottomrule\n\\end{longtable}\n\n\n\n:::\n\nPredictive performance measures by dataset and objective averaged across training-phase parameters (@nte-gen-params-final-run-train) and evaluation-phase parameters (@nte-gen-params-final-run-eval).\n\n:::\n\n### Plausibility\n\nThe results with respect to the plausibility measure are shown in @fig-grid-gen_params-plaus-circles to @fig-grid-gen_params-plaus-over.\n\n\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/gen_params/mlp/circles/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png){#fig-grid-gen_params-plaus-circles width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/gen_params/mlp/lin_sep/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png){#fig-grid-gen_params-plaus-lin_sep width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/gen_params/mlp/moons/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png){#fig-grid-gen_params-plaus-moons width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/gen_params/mlp/over/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png){#fig-grid-gen_params-plaus-over width=80%}\n\n\n\n### Cost\n\nThe results with respect to the cost measure are shown in @fig-grid-gen_params-cost-circles to @fig-grid-gen_params-cost-over.\n\n\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/gen_params/mlp/circles/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png){#fig-grid-gen_params-cost-circles width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/gen_params/mlp/lin_sep/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png){#fig-grid-gen_params-cost-lin_sep width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/gen_params/mlp/moons/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png){#fig-grid-gen_params-cost-moons width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/gen_params/mlp/over/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png){#fig-grid-gen_params-cost-over width=80%}\n\n\n\n## Penalty Strengths {#sec-app-grid-pen}\n\n\n\n\nThe hyperparameter grid with varying penalty strengths during training is shown in @nte-pen-final-run-train. The corresponding evaluation grid used for these experiments is shown in @nte-pen-final-run-eval.\n\n::: {#nte-pen-final-run-train .callout-note}\n\n## Training Phase\n\n- Generator: `ecco, generic, revise`\n- Model: `mlp`\n- Training Parameters:\n    - $\\lambda_{\\text{adv}}$: `0.1, 0.25, 1.0`\n    - $\\lambda_{\\text{div}}$: `0.01, 0.1, 1.0`\n    - $\\lambda_{\\text{reg}}$: `0.0, 0.01, 0.1, 0.25, 0.5`\n    - Objective: `full, vanilla`\n\n\n\n\n:::\n\n::: {#nte-pen-final-run-eval .callout-note}\n\n## Evaluation Phase\n\n- Generator Parameters:\n    - $\\lambda_{\\text{egy}}$: `0.1, 0.5, 1.0, 5.0, 10.0`\n\n\n\n\n:::\n\n### Predictive Performance\n\nPredictive performance measures for this grid search are shown in @tbl-acc-pen.\n\n::: {#tbl-acc-pen}\n\n::: {.content-hidden unless-format=\"pdf\"}\n\n\\begin{longtable}{ccccc}\n  \\toprule\n  \\textbf{Dataset} & \\textbf{Variable} & \\textbf{Objective} & \\textbf{Mean} & \\textbf{Se} \\\\\\midrule\n  \\endfirsthead\n  \\toprule\n  \\textbf{Dataset} & \\textbf{Variable} & \\textbf{Objective} & \\textbf{Mean} & \\textbf{Se} \\\\\\midrule\n  \\endhead\n  \\bottomrule\n  \\multicolumn{5}{r}{Continuing table below.}\\\\\n  \\bottomrule\n  \\endfoot\n  \\endlastfoot\n  Circ & Accuracy & Full & 0.99 & 0.01 \\\\\n  Circ & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  Circ & F1-score & Full & 0.99 & 0.01 \\\\\n  Circ & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  LS & Accuracy & Full & 1.0 & 0.01 \\\\\n  LS & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  LS & F1-score & Full & 1.0 & 0.01 \\\\\n  LS & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  Moon & Accuracy & Full & 0.99 & 0.04 \\\\\n  Moon & Accuracy & Vanilla & 1.0 & 0.01 \\\\\n  Moon & F1-score & Full & 0.99 & 0.04 \\\\\n  Moon & F1-score & Vanilla & 1.0 & 0.01 \\\\\n  OL & Accuracy & Full & 0.91 & 0.02 \\\\\n  OL & Accuracy & Vanilla & 0.92 & 0.0 \\\\\n  OL & F1-score & Full & 0.91 & 0.02 \\\\\n  OL & F1-score & Vanilla & 0.92 & 0.0 \\\\\\bottomrule\n\\end{longtable}\n\n\n\n:::\n\nPredictive performance measures by dataset and objective averaged across training-phase parameters (@nte-pen-final-run-train) and evaluation-phase parameters (@nte-pen-final-run-eval).\n\n:::\n\n### Plausibility\n\nThe results with respect to the plausibility measure are shown in @fig-grid-pen-plaus-circles to @fig-grid-pen-plaus-over.\n\n\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/penalties/mlp/circles/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png){#fig-grid-pen-plaus-circles width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/penalties/mlp/lin_sep/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png){#fig-grid-pen-plaus-lin_sep width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/penalties/mlp/moons/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png){#fig-grid-pen-plaus-moons width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/penalties/mlp/over/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png){#fig-grid-pen-plaus-over width=80%}\n\n\n\n### Cost\n\nThe results with respect to the cost measure are shown in @fig-grid-pen-cost-circles to @fig-grid-pen-cost-over.\n\n\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/penalties/mlp/circles/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png){#fig-grid-pen-cost-circles width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/penalties/mlp/lin_sep/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png){#fig-grid-pen-cost-lin_sep width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/penalties/mlp/moons/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png){#fig-grid-pen-cost-moons width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/penalties/mlp/over/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png){#fig-grid-pen-cost-over width=80%}\n\n\n\n## Other Parameters {#sec-app-grid-train}\n\n\n\n\nThe hyperparameter grid with other varying training parameters is shown in @nte-train-final-run-train. The corresponding evaluation grid used for these experiments is shown in @nte-train-final-run-eval.\n\n::: {#nte-train-final-run-train .callout-note}\n\n## Training Phase\n\n- Generator: `ecco, generic, revise`\n- Model: `mlp`\n- Training Parameters:\n    - Burnin: `0.0, 0.5`\n    - No. Counterfactuals: `100, 1000`\n    - No. Epochs: `50, 100`\n    - Objective: `full, vanilla`\n\n\n\n\n:::\n\n::: {#nte-train-final-run-eval .callout-note}\n\n## Evaluation Phase\n\n- Generator Parameters:\n    - $\\lambda_{\\text{egy}}$: `0.1, 0.5, 1.0, 5.0, 10.0`\n\n\n\n\n:::\n\n### Predictive Performance\n\nPredictive performance measures for this grid search are shown in @tbl-acc-train.\n\n::: {#tbl-acc-train}\n\n::: {.content-hidden unless-format=\"pdf\"}\n\n\\begin{longtable}{ccccc}\n  \\toprule\n  \\textbf{Dataset} & \\textbf{Variable} & \\textbf{Objective} & \\textbf{Mean} & \\textbf{Se} \\\\\\midrule\n  \\endfirsthead\n  \\toprule\n  \\textbf{Dataset} & \\textbf{Variable} & \\textbf{Objective} & \\textbf{Mean} & \\textbf{Se} \\\\\\midrule\n  \\endhead\n  \\bottomrule\n  \\multicolumn{5}{r}{Continuing table below.}\\\\\n  \\bottomrule\n  \\endfoot\n  \\endlastfoot\n  Circ & Accuracy & Full & 0.99 & 0.0 \\\\\n  Circ & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  Circ & F1-score & Full & 0.99 & 0.0 \\\\\n  Circ & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  LS & Accuracy & Full & 1.0 & 0.0 \\\\\n  LS & Accuracy & Vanilla & 1.0 & 0.0 \\\\\n  LS & F1-score & Full & 1.0 & 0.0 \\\\\n  LS & F1-score & Vanilla & 1.0 & 0.0 \\\\\n  Moon & Accuracy & Full & 1.0 & 0.01 \\\\\n  Moon & Accuracy & Vanilla & 0.99 & 0.02 \\\\\n  Moon & F1-score & Full & 1.0 & 0.01 \\\\\n  Moon & F1-score & Vanilla & 0.99 & 0.02 \\\\\n  OL & Accuracy & Full & 0.91 & 0.01 \\\\\n  OL & Accuracy & Vanilla & 0.92 & 0.0 \\\\\n  OL & F1-score & Full & 0.91 & 0.01 \\\\\n  OL & F1-score & Vanilla & 0.92 & 0.0 \\\\\\bottomrule\n\\end{longtable}\n\n\n\n:::\n\nPredictive performance measures by dataset and objective averaged across training-phase parameters (@nte-train-final-run-train) and evaluation-phase parameters (@nte-train-final-run-eval).\n\n:::\n\n### Plausibility\n\nThe results with respect to the plausibility measure are shown in @fig-grid-train-plaus-circles to @fig-grid-train-plaus-over.\n\n\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/training_params/mlp/circles/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png){#fig-grid-train-plaus-circles width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/training_params/mlp/lin_sep/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png){#fig-grid-train-plaus-lin_sep width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/training_params/mlp/moons/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png){#fig-grid-train-plaus-moons width=80%}\n\n![Average outcomes for the plausibility measure across hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/training_params/mlp/over/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png){#fig-grid-train-plaus-over width=80%}\n\n\n\n### Cost\n\nThe results with respect to the cost measure are shown in @fig-grid-train-cost-circles to @fig-grid-train-cost-over.\n\n\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/training_params/mlp/circles/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png){#fig-grid-train-cost-circles width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/training_params/mlp/lin_sep/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png){#fig-grid-train-cost-lin_sep width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/training_params/mlp/moons/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png){#fig-grid-train-cost-moons width=80%}\n\n![Average outcomes for the cost measure across hyperparameters. This shows the % change from the baseline model for the distance-based cost metric [@wachter2017counterfactual]. Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/training_params/mlp/over/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png){#fig-grid-train-cost-over width=80%}\n\n\n\n\n\n\\FloatBarrier\n\n# Tuning Key Parameters {#sec-app-tune}\n\n\n\n\n\n\n\nBased on the findings from our initial large grid searches (@sec-app-grid), we tune selected hyperparameters for all datasets: namely, the decision threshold $\\tau$ and the strength of the energy regularization $\\lambda_{\\text{reg}}$. The final hyperparameter choices for each dataset are presented in @tbl-final-params in @sec-app-main. Detailed results for each data set are shown in @fig-tune-plaus-adult to @fig-tune-mat-over. From @tbl-final-params, we notice that the same decision threshold of $\\tau=0.5$ is optimal for all but on dataset. We attribute this to the fact that a low decision threshold results in a higher share of mature counterfactuals and hence more opportunities for the model to learn from examples (@fig-tune-mat-adult to @fig-tune-mat-over). This has played a role in particular for our real-world tabular datasets and MNIST, which suffered from low levels of maturity for higher decision thresholds. In cases where maturity is not an issue, as for *Moons*, higher decision thresholds lead to better outcomes, which may have to do with the fact that the resulting counterfactuals are more faithful to the model. Concerning the regularization strength, we find somewhat high variation across datasets. Most notably, we find that relatively low levels of regularization are optimal for MNIST. We hypothesize that this finding may be attributed to the uniform scaling of all input features (digits). \n\nFinally, to increase the proportion of mature counterfactuals for some datasets, we have also investigated the effect on the learning rate $\\eta$ for the counterfactual search and even smaller regularization strengths for a fixed decision threshold of 0.5 (@fig-tune_lr-plaus-adult to @fig-tune_lr-plaus-over). For the given low decision threshold, we find that the learning rate has no discernable impact on the proportion of mature counterfactuals (@fig-tune_lr-mat-adult to @fig-tune_lr-mat-over). We do notice, however, that the results for MNIST are much improved when using a low value $\\lambda_{\\text{reg}}$, the strength for the engery regularization: plausibility is increased by up to ~10% (@fig-tune_lr-plaus-mnist) and the proportion of mature counterfactuals reaches 100%. \n\nOne consideration worth exploring is to combine high decision thresholds with high learning rates, which we have not investigated here. \n\n<!-- ::: {.callout-warning}\n\n## Package Version (Reproducibility)\n\nTuning was run using `v1.1.3` of `TaijaData`. The follow-up version `v1.1.4` introduced an option to split real-world tabular datasets into train and test set, ensuring that pre-processing steps like standardization is fit on the training set only. If you are rerunning the tuning experiments with a version of `TaijaData` that is higher than `v1.1.3`, than for the default parameters specified in the configuration files, you may end up with slightly different results, although we would not expect any changes in terms of qualitative findings. For exact reproducibility, please use `v1.1.3`.\n\n::: -->\n\n## Key Parameters {#sec-app-tune-key}\n\n\n\n\nThe hyperparameter grid for tuning key parameters is shown in @nte-tune-train. The corresponding evaluation grid used for these experiments is shown in @nte-tune-eval.\n\n::: {#nte-tune-train .callout-note}\n\n## Training Phase\n\n- Generator Parameters:\n    - Decision Threshold: `0.5, 0.75, 0.9`\n- Model: `mlp`\n- Training Parameters:\n    - $\\lambda_{\\text{reg}}$: `0.1, 0.25, 0.5`\n    - Objective: `full, vanilla`\n\n\n\n\n:::\n\n::: {#nte-tune-eval .callout-note}\n\n## Evaluation Phase\n\n- Generator Parameters:\n    - $\\lambda_{\\text{egy}}$: `0.1, 0.5, 1.0, 5.0, 10.0`\n\n\n\n\n:::\n\n### Plausibility\n\nThe results with respect to the plausibility measure are shown in @fig-tune-plaus-adult to @fig-tune-plaus-over.\n\n\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Adult.](/paper/experiments/output/final_run/tune/mlp/adult/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-adult width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: California Housing.](/paper/experiments/output/final_run/tune/mlp/cali/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-cali width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/tune/mlp/circles/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-circles width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Credit.](/paper/experiments/output/final_run/tune/mlp/credit/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-credit width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: GMSC.](/paper/experiments/output/final_run/tune/mlp/gmsc/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-gmsc width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/tune/mlp/lin_sep/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-lin_sep width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: MNIST.](/paper/experiments/output/final_run/tune/mlp/mnist/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-mnist width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/tune/mlp/moons/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-moons width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/tune/mlp/over/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png){#fig-tune-plaus-over width=100%}\n\n\n\n### Proportion of Mature CE\n\nThe results with respect to the proportion of mature counterfactuals in each epoch are shown in @fig-tune-mat-adult to @fig-tune-mat-over.\n\n\n\n![Proportion of mature counterfactuals in each epoch. Data: Adult.](/paper/experiments/output/final_run/tune/mlp/adult/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-adult width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: California Housing.](/paper/experiments/output/final_run/tune/mlp/cali/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-cali width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Circles.](/paper/experiments/output/final_run/tune/mlp/circles/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-circles width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Credit.](/paper/experiments/output/final_run/tune/mlp/credit/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-credit width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: GMSC.](/paper/experiments/output/final_run/tune/mlp/gmsc/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-gmsc width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Linearly Separable.](/paper/experiments/output/final_run/tune/mlp/lin_sep/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-lin_sep width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: MNIST.](/paper/experiments/output/final_run/tune/mlp/mnist/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-mnist width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Moons.](/paper/experiments/output/final_run/tune/mlp/moons/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-moons width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Overlapping.](/paper/experiments/output/final_run/tune/mlp/over/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png){#fig-tune-mat-over width=100%}\n\n\n\n## Learning Rate {#sec-app-tune-lr}\n\n\n\n\nThe hyperparameter grid for tuning the learning rate is shown in @nte-tune_lr-train. The corresponding evaluation grid used for these experiments is shown in @nte-tune_lr-eval.\n\n::: {#nte-tune_lr-train .callout-note}\n\n## Training Phase\n\n- Generator Parameters:\n    - Learning Rate: `0.1, 0.5, 1.0`\n- Model: `mlp`\n- Training Parameters:\n    - $\\lambda_{\\text{reg}}$: `0.01, 0.1, 0.5`\n    - Objective: `full, vanilla`\n\n\n\n\n:::\n\n::: {#nte-tune_lr-eval .callout-note}\n\n## Evaluation Phase\n\n- Generator Parameters:\n    - $\\lambda_{\\text{egy}}$: `0.1, 0.5, 1.0, 5.0, 10.0`\n\n\n\n\n:::\n\n### Plausibility\n\nThe results with respect to the plausibility measure are shown in @fig-tune_lr-plaus-adult to @fig-tune_lr-plaus-over.\n\n\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Adult.](/paper/experiments/output/final_run/tune_lr/mlp/adult/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-adult width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: California Housing.](/paper/experiments/output/final_run/tune_lr/mlp/cali/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-cali width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Circles.](/paper/experiments/output/final_run/tune_lr/mlp/circles/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-circles width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Credit.](/paper/experiments/output/final_run/tune_lr/mlp/credit/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-credit width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: GMSC.](/paper/experiments/output/final_run/tune_lr/mlp/gmsc/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-gmsc width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Linearly Separable.](/paper/experiments/output/final_run/tune_lr/mlp/lin_sep/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-lin_sep width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: MNIST.](/paper/experiments/output/final_run/tune_lr/mlp/mnist/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-mnist width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Moons.](/paper/experiments/output/final_run/tune_lr/mlp/moons/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-moons width=100%}\n\n![Average outcomes for the plausibility measure across key hyperparameters. This shows the % change from the baseline model for the distance-based implausibility metric (@eq-impl-dist). Boxplots indicate the variation across evaluation runs and test settings (varying parameters for *ECCo*). Data: Overlapping.](/paper/experiments/output/final_run/tune_lr/mlp/over/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png){#fig-tune_lr-plaus-over width=100%}\n\n\n\n### Proportion of Mature CE\n\nThe results with respect to the proportion of mature counterfactuals in each epoch are shown in @fig-tune_lr-mat-adult to @fig-tune_lr-mat-over.\n\n\n\n![Proportion of mature counterfactuals in each epoch. Data: Adult.](/paper/experiments/output/final_run/tune_lr/mlp/adult/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-adult width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: California Housing.](/paper/experiments/output/final_run/tune_lr/mlp/cali/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-cali width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Circles.](/paper/experiments/output/final_run/tune_lr/mlp/circles/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-circles width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Credit.](/paper/experiments/output/final_run/tune_lr/mlp/credit/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-credit width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: GMSC.](/paper/experiments/output/final_run/tune_lr/mlp/gmsc/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-gmsc width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Linearly Separable.](/paper/experiments/output/final_run/tune_lr/mlp/lin_sep/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-lin_sep width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: MNIST.](/paper/experiments/output/final_run/tune_lr/mlp/mnist/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-mnist width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Moons.](/paper/experiments/output/final_run/tune_lr/mlp/moons/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-moons width=100%}\n\n![Proportion of mature counterfactuals in each epoch. Data: Overlapping.](/paper/experiments/output/final_run/tune_lr/mlp/over/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png){#fig-tune_lr-mat-over width=100%}\n\n\n\n\n\n\\FloatBarrier\n\n# Computation Details {.appendix}\n\n<!-- [@DHPC2022] -->\n## Hardware {#sec-app-hardware}\n\nWe performed our experiments on a high-performance cluster. Details about the cluster will be disclosed upon publication to avoid revealing information that might interfere with the double-blind review process. Since our experiments involve highly parallel tasks and rather small models by today's standard, we have relied on distributed computing across multiple central processing units (CPU). Graphical processing units (GPU) were not required. \n\n### Grid Searches\n\nModel training for the largest grid searches with 270 unique parameter combinations was parallelized across 34 CPUs with 2GB memory each. The time to completion varied by dataset for reasons discussed in @sec-discussion: 0h49m (*Moons*), 1h4m (*Linearly Separable*), 1h49m (*Circles*), 3h52m (*Overlapping*). Model evaluations for large grid searches were parallelized across 20 CPUs with 3GB memory each. Evaluations for all data sets took less than one hour (<1h) to complete. \n\n### Tuning\n\nFor tuning of selected hyperparameters, we distributed the task of generating counterfactuals during training across 40 CPUs with 2GB memory each for all tabular datasets. Except for the *Adult* dataset, all training runs were completed in less that half an hour (<0h30m). The *Adult* dataset took around 0h35m to complete. Evaluations across 20 CPUs with 3GB memory each generally took less than 0h30m to complete. For *MNIST*, we relied on 100 CPUs with 2GB memory each. For the *MLP*, training of all models could be completed in 1h30m, while the evaluation across 20 CPUs (6GB memory) took 4h12m. For the *CNN*, training of all models took ~8h, with conventionally trained models taking ~0h15m each and model with CT taking ~0h30m-0h45m each.\n\n## Software\n\nAll computations were performed in the Julia Programming Language [@bezanson2017julia]. We have developed a package for counterfactual training that leverages and extends the functionality provided by several existing packages, most notably [CounterfactualExplanations.jl](https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl) [@altmeyer2023explaining] and the [Flux.jl](https://fluxml.ai/Flux.jl/v0.16/) library for deep learning [@innes2018fashionable;@innes2018flux]. For data-wrangling and presentation-ready tables we relied on [DataFrames.jl](https://dataframes.juliadata.org/v1.7/) [@milan2023dataframes] and [PrettyTables.jl](https://ronisbr.github.io/PrettyTables.jl/v2.4/) [@chagas2024pretty], respectively. For plots and visualizations we used both [Plots.jl](https://docs.juliaplots.org/v1.40/) [@PlotsJL] and [Makie.jl](https://docs.makie.org/v0.22/) [@danisch2021makie], in particular [AlgebraOfGraphics.jl](https://aog.makie.org/v0.9.3/). To distribute computational tasks across multiple processors, we have relied on [MPI.jl](https://juliaparallel.org/MPI.jl/v0.20/) [@byrne2021mpi].\n\n\n\n\n\n```{=latex}\n\\end{appendices}\n```\n\n",
    "supporting": [
      "paper_files/figure-pdf"
    ],
    "filters": []
  }
}