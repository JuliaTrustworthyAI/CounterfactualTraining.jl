{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "projectdir = splitpath(pwd()) |>\n",
        "    ss -> joinpath(ss[1:findall([s == \"CounterfactualTraining.jl\" for s in ss])[1]]...) \n",
        "cd(projectdir)"
      ],
      "id": "c3dcbc72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using CTExperiments\n",
        "using CTExperiments.CSV\n",
        "using CTExperiments.DataFrames\n",
        "using CTExperiments.StatsBase\n",
        "\n",
        "using DotEnv\n",
        "DotEnv.load!()"
      ],
      "id": "764988e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\FloatBarrier\n",
        "\n",
        "\\setcounter{section}{0}\n",
        "\\renewcommand{\\thesection}{\\Alph{section}}\n",
        "\n",
        "\\setcounter{table}{0}\n",
        "\\renewcommand{\\thetable}{A\\arabic{table}}\n",
        "\n",
        "\\setcounter{figure}{0}\n",
        "\\renewcommand{\\thefigure}{A\\arabic{figure}}\n",
        "\n",
        "<!-- # Supplementary Material {.appendix} -->\n",
        "\n",
        "# Notation {.appendix}\n",
        "\n",
        "- $y^+$: The target class and also the index of the target class.\n",
        "- $y^-$: The non-target class and also the index of non-the target class.\n",
        "- $\\mathbf{y}^+$: The one-hot encoded output vector for the target class. \n",
        "- $\\theta$: Model parameters (unspecified).\n",
        "- $\\Theta$: Matrix of parameters. \n",
        "\n",
        "# Technical Details of Our Approach {.appendix} \n"
      ],
      "id": "3dbe9083"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "projectdir = splitpath(pwd()) |>\n",
        "    ss -> joinpath(ss[1:findall([s == \"CounterfactualTraining.jl\" for s in ss])[1]]...) \n",
        "cd(projectdir)\n",
        "\n",
        "using CTExperiments\n",
        "using CTExperiments.CounterfactualExplanations\n",
        "using CTExperiments.CounterfactualTraining\n",
        "using CTExperiments.Flux\n",
        "using CTExperiments.Plots\n",
        "using CTExperiments.TaijaPlotting\n",
        "using Plots.PlotMeasures"
      ],
      "id": "5a3b7fa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Protecting Mutability Constraints with Linear Classifiers {#sec-app-constraints}\n",
        "\n",
        "In @sec-constraints we explain that to avoid penalizing implausibility that arises due to mutability constraints, we impose a point mass prior on $p(\\mathbf{x})$ for the corresponding feature. We argue in @sec-constraints that this approach induces models to be less sensitive to immutable features and demonstrate this empirically in @sec-experiments. Below we derive the analytical results in @prp-mtblty.\n",
        "\n",
        "::: {.proof}\n",
        "\n",
        "Let $d_{\\text{mtbl}}$ and $d_{\\text{immtbl}}$ denote some mutable and immutable feature, respectively. Suppose that $\\mu_{y^-,d_{\\text{immtbl}}} < \\mu_{y^+,d_{\\text{immtbl}}}$ and $\\mu_{y^-,d_{\\text{mtbl}}} > \\mu_{y^+,d_{\\text{mtbl}}}$, where $\\mu_{k,d}$ denotes the conditional sample mean of feature $d$ in class $k$. In words, we assume that the immutable feature tends to take lower values for samples in the non-target class $y^-$ than in the target class $y^+$. We assume the opposite to hold for the mutable feature.\n",
        "\n",
        "Assuming multivariate Gaussian class densities with common diagonal covariance matrix $\\Sigma_k=\\Sigma$ for all $k \\in \\mathcal{K}$, we have for the log likelihood ratio between any two classes $k,m \\in \\mathcal{K}$ [@hastie2009elements]:\n",
        "\n",
        "$$\n",
        "\\log \\frac{p(k|\\mathbf{x})}{p(m|\\mathbf{x})}=\\mathbf{x}^\\intercal \\Sigma^{-1}(\\mu_{k}-\\mu_{m})  + \\text{const}\n",
        "$$ {#eq-loglike}\n",
        "\n",
        "By independence of $x_1,...,x_D$, the full log-likelihood ratio decomposes into:\n",
        "\n",
        "$$\n",
        "\\log \\frac{p(k|\\mathbf{x})}{p(m|\\mathbf{x})} = \\sum_{d=1}^D \\frac{\\mu_{k,d}-\\mu_{m,d}}{\\sigma_{d}^2} x_{d} + \\text{const}\n",
        "$$ {#eq-loglike-decomp}\n",
        "\n",
        "By the properties of our classifier (*multinomial logistic regression*), we have:\n",
        "\n",
        "$$\n",
        "\\log \\frac{p(k|\\mathbf{x})}{p(m|\\mathbf{x})} = \\sum_{d=1}^D \\left( \\theta_{k,d} - \\theta_{m,d} \\right)x_d + \\text{const}\n",
        "$$ {#eq-multi}\n",
        "\n",
        "where $\\theta_{k,d}=\\Theta[k,d]$ denotes the coefficient on feature $d$ for class $k$. \n",
        "\n",
        "Based on @eq-loglike-decomp and @eq-multi we can identify that $(\\mu_{k,d}-\\mu_{m,d}) \\propto (\\theta_{k,d} - \\theta_{m,d})$ under the assumptions we made above. Hence, we have that $(\\theta_{y^-,d_{\\text{immtbl}}} - \\theta_{y^+,d_{\\text{immtbl}}}) < 0$ and $(\\theta_{y^-,d_{\\text{mtbl}}} - \\theta_{y^+,d_{\\text{mtbl}}}) > 0$\n",
        "\n",
        "Let $\\mathbf{x}^\\prime$ denote some randomly chosen individual from class $y^-$ and let $y^+ \\sim p(y)$ denote the randomly chosen target class. Then the partial derivative of the contrastive divergence penalty [@eq-div] with respect to coefficient $\\theta_{y^+,d}$ is equal to \n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial\\theta_{y^+,d}} \\left(\\text{div}(\\mathbf{x},\\mathbf{x^\\prime},\\mathbf{y};\\theta)\\right) = \\frac{\\partial}{\\partial\\theta_{y^+,d}} \\left( \\left(-\\mathbf{M}_\\theta(\\mathbf{x})[y^+]\\right) - \\left(-\\mathbf{M}_\\theta(\\mathbf{x}^\\prime)[y^+]\\right) \\right) = x_{d}^\\prime - x_{d}\n",
        "$$ {#eq-grad}\n",
        "\n",
        "and equal to zero everywhere else.\n",
        "\n",
        "Since $(\\mu_{y^-,d_{\\text{immtbl}}} < \\mu_{y^+,d_{\\text{immtbl}}})$ we are more likely to have $(x_{d_{\\text{immtbl}}}^\\prime - x_{d_{\\text{immtbl}}}) < 0$ than vice versa at initialization. Similarly, we are more likely to have $(x_{d_{\\text{mtbl}}}^\\prime - x_{d_{\\text{mtbl}}}) > 0$ since $(\\mu_{y^-,d_{\\text{mtbl}}} > \\mu_{y^+,d_{\\text{mtbl}}})$.\n",
        "\n",
        "This implies that if we do not protect feature $d_{\\text{immtbl}}$, the contrastive divergence penalty will decrease $\\theta_{y^-,d_{\\text{immtbl}}}$ thereby exacerbating the existing effect $(\\theta_{y^-,d_{\\text{immtbl}}} - \\theta_{y^+,d_{\\text{immtbl}}}) < 0$. In words, not protecting the immutable feature would have the undesirable effect of making the classifier more sensitive to this feature, in that it would be more likely to predict class $y^-$ as opposed to $y^+$ for lower values of $d_{\\text{immtbl}}$. \n",
        "\n",
        "By the same rationale, the contrastive divergence penalty can generally be expected to increase $\\theta_{y^-,d_{\\text{mtbl}}}$ exacerbating $(\\theta_{y^-,d_{\\text{mtbl}}} - \\theta_{y^+,d_{\\text{mtbl}}}) > 0$. In words, this has the effect of making the classifier more sensitive to the mutable feature, in that it would be more likely to predict class $y^-$ as opposed to $y^+$ for higher values of $d_{\\text{mtbl}}$.\n",
        "\n",
        "Thus, our proposed approach of protecting feature $d_{\\text{immtbl}}$ has the net affect of decreasing the classifier's sensitivity to the immutable feature relative to the mutable feature (i.e. no change in sensitivity for $d_{\\text{immtbl}}$ relative to increased sensitivity for $d_{\\text{mtbl}}$).\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-warning}\n",
        "\n",
        "\\@Cynthia, \\@Arie, I have tentatively phrased the above in terms of a theorem and proof. This is something I've so far shied away from because I feel a bit out of my depth when it comes to mathematical proofs. The above makes intuitive sense to me, but I don't know for sure if it's correct. \n",
        "\n",
        ":::"
      ],
      "id": "c618e365"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "using CTExperiments: \n",
        "    get_ce_data, \n",
        "    train_val_split, \n",
        "    build_model, \n",
        "    LinearModel, \n",
        "    get_input_encoder\n",
        "\n",
        "# Callback:\n",
        "using CTExperiments: get_log_reg_params, get_decision_boundary\n",
        "\n",
        "function plot_db(model, ces; _xlab=\"Debt\", _ylab=\"Age\")\n",
        "\n",
        "    x = (ce -> ce.counterfactual).(ces) |> xs -> reduce(hcat, xs)\n",
        "    x0 = (ce -> ce.factual).(ces) |> xs -> reduce(hcat, xs)\n",
        "\n",
        "    xlab = _constraint[1] == \"both\" ? \"$(_xlab) (mutable)\" : \"$(_xlab) (immutable)\"\n",
        "    ylab = _constraint[2] == \"both\" ? \"$(_ylab) (mutable)\" : \"$(_ylab) (immutable)\"\n",
        "\n",
        "    # Data and decision boundary:\n",
        "    coeff = get_log_reg_params(model)\n",
        "    db = get_decision_boundary(coeff)\n",
        "    plt = Plots.scatter(\n",
        "        ce_data, \n",
        "        # label=[\"1=Default\" \"2=No Default\"], \n",
        "        # legend_position=:topright, \n",
        "        xlab=xlab, ylab=ylab,  \n",
        "        axis=nothing, \n",
        "        legend=false,\n",
        "        title=_title\n",
        "    )\n",
        "    Plots.abline!(plt, db.slope, db.intercept; lw=5, label=\"Dec. Boundary\")\n",
        "\n",
        "    # Counterfactuals:\n",
        "    target = 2\n",
        "    factual = 1\n",
        "    if !any(isnothing.(x))\n",
        "        yhat = [argmax(y) for y in eachcol(model(x))]\n",
        "        yhat0 = [argmax(y) for y in eachcol(model(x0))]\n",
        "        idx_plotted = yhat0.==factual\n",
        "        if any(idx_plotted)\n",
        "\n",
        "            # Paths:\n",
        "            u = []\n",
        "            v = []\n",
        "            for (i,ce) in enumerate(eachcol(x))\n",
        "                Δ = ce - x0[:,i]\n",
        "                push!(u, Δ[1])\n",
        "                push!(v, Δ[2])\n",
        "            end\n",
        "            Plots.quiver!(x0[1,idx_plotted], x0[2,idx_plotted], quiver=(u[idx_plotted], v[idx_plotted]), color=factual)\n",
        "            \n",
        "            # End points:\n",
        "            Plots.scatter!(x[1,idx_plotted], x[2,idx_plotted], label=[\"CE (y⁺=1)\" \"CE (y⁺=2)\"], ms=15, shape=:star, color=yhat[idx_plotted], group=yhat[idx_plotted], mscolor=yhat0[idx_plotted])\n",
        "\n",
        "        end\n",
        "    end\n",
        "    display(plt)\n",
        "end\n",
        "\n",
        "# Data:\n",
        "specs = [\n",
        "    (\"(a)\", VanillaObjective(needs_ce=true), [\"both\", \"both\"]),\n",
        "    (\"(b)\", FullObjective(lambda=[1.0,1.0,0.0,1.0]), [\"both\", \"both\"]),\n",
        "    (\"(c)\", VanillaObjective(needs_ce=true), [\"both\", \"none\"]),\n",
        "    (\"(d)\", FullObjective(lambda=[1.0,1.0,0.0,1.0]), [\"both\", \"none\"]),\n",
        "]"
      ],
      "id": "f44ccc2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "using CounterfactualExplanations.Convergence\n",
        "using Random\n",
        "Random.seed!(42)\n",
        "\n",
        "models = []\n",
        "plts = []\n",
        "\n",
        "for (title, obj, constraint) in specs\n",
        "\n",
        "    # Globals for the callback:\n",
        "    global _title = title\n",
        "    global _constraint = constraint\n",
        "\n",
        "    # Data:\n",
        "    data = LinearlySeparable(\n",
        "        n_train=500,\n",
        "        batchsize=50,\n",
        "        mutability=constraint\n",
        "    )\n",
        "    global ce_data = get_ce_data(data)\n",
        "    val_size = data.n_validation / (data.n_validation + data.n_train)\n",
        "    train_set, val_set, _ = train_val_split(data, ce_data, val_size)\n",
        "\n",
        "    # Model:\n",
        "    nin = size(first(train_set)[1], 1)\n",
        "    nout = size(first(train_set)[2], 1)\n",
        "    model = build_model(LinearModel(), nin, nout)\n",
        "\n",
        "    # Objective:\n",
        "    generator = GenericGenerator()\n",
        "    opt_state = Flux.setup(Descent(), model)\n",
        "    conv = MaxIterConvergence(25)\n",
        "\n",
        "    model, logs = counterfactual_training(\n",
        "        obj,\n",
        "        model,\n",
        "        generator,\n",
        "        train_set,\n",
        "        opt_state;\n",
        "        val_set = val_set,\n",
        "        nepochs = 100,\n",
        "        mutability = Symbol.(constraint),\n",
        "        callback = plot_db,\n",
        "        nce=50,\n",
        "        convergence=conv, \n",
        "        verbose=3\n",
        "    )\n",
        "\n",
        "    push!(models, model)\n",
        "    push!(plts, current())\n",
        "end"
      ],
      "id": "2084fbbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "plt = Plots.plot(\n",
        "    plts..., \n",
        "    layout=(1,4), \n",
        "    size=(1150,250),  \n",
        "    left_margin = 10mm, \n",
        "    bottom_margin = 5mm,\n",
        "    top_margin = 3mm,\n",
        "    right_margin = 10mm,\n",
        ")\n",
        "display(plt)\n",
        "Plots.savefig(plt, \"paper/figures/poc.svg\")"
      ],
      "id": "02ada4fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "plts = []\n",
        "titles = [\"(a)\", \"(b)\"]\n",
        "_xlab = \"Existing Debt\"\n",
        "_ylab = \"Age\"\n",
        "for (i,model) in enumerate(models)\n",
        "    coeff = get_log_reg_params(model)\n",
        "    db = get_decision_boundary(coeff)\n",
        "    xlab = constraints[i][1] == \"both\" ? \"$(_xlab) (mutable)\" : \"$(_xlab) (immutable)\"\n",
        "    ylab = constraints[i][2] == \"both\" ? \"$(_ylab) (mutable)\" : \"$(_ylab) (immutable)\"\n",
        "    plt = Plots.scatter(ce_data; xlab=xlab, ylab=ylab, bottom_margin = 5mm, left_margin = 5mm, label=[\"Default\" \"No Default\"], title=titles[i])\n",
        "    Plots.abline!(plt, db.slope, db.intercept; lw=5, label=\"Dec. Boundary\")\n",
        "\n",
        "    push!(plts, plt)\n",
        "end\n",
        "\n",
        "plt = Plots.plot(plts..., layout=(1,2), size=(600,300))\n",
        "Plots.savefig(plt, \"paper/figures/app_mtblty.svg\")"
      ],
      "id": "26c769a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Domain Constraints\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Detailed Results {.appendix}\n",
        "\n",
        "::: {.callout-warning}\n",
        "\n",
        "\\@Cynthia, \\@Arie, I'm including some preliminary results here but will rerun experiments in the coming days. You'll notice some odd outlier results (huge values) for the initial grid search (@sec-app-initial). My belief is that this is once again due to *ECCo* overshooting for some hyperparameter choices, that we have discussed before. A simple solution to this story is to actually impose domain constraints. Let's see what the final results show us (I also still plan to make slight changes to the implementation), but in any case I think it might even be worth to report results for the initial grid search in the final appendix (they do include good results for CT for certain hyperparameter ranges and highlight limitations inherited from energy-based modelling).\n",
        "\n",
        ":::\n",
        "\n",
        "## Qualitative Findings for Image Data\n",
        "\n",
        "::: {.callout-note}\n",
        "\n",
        "\\@Cynthia, \\@Arie, @fig-mnist shows much more plausible (faithful) counterfactuals for a model with CT than the model with conventional training (@fig-mnist-vanilla). In fact, this is not even using *ECCo+* and still showing better results than the best results we achieved in our AAAI paper for JEM ensembles.\n",
        "\n",
        ":::\n",
        "\n",
        "![Counterfactual images for *MLP* with counterfactual training. The underlying generator, *ECCo*, aims to generate counterfactuals that are faithful to the model [@altmeyer2024faithful].](/paper/figures/mnist_mlp.png){#fig-mnist}\n",
        "\n",
        "![Counterfactual images for *MLP* with conventional training. The underlying generator, *ECCo*, aims to generate counterfactuals that are faithful to the model [@altmeyer2024faithful].](/paper/figures/mnist_mlp_vanilla.png){#fig-mnist-vanilla}\n",
        "\n",
        "## Initial Grid Search {#sec-app-initial}\n"
      ],
      "id": "79cba2be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results_dir = ENV[\"INITIAL_RUN_RESULTS\"]\n",
        "config_dir = ENV[\"INITIAL_RUN_CONFIG\"]"
      ],
      "id": "2fc96d45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the initial round of experiments we \n",
        "\n",
        "### Generator Parameters\n",
        "\n",
        "The hyperparameter grids for the first investigation of the effect of generator parameters are shown in @exr-gen-params-first-run-train and @exr-gen-params-first-run-eval.\n",
        "\n",
        "::: {#exr-gen-params-first-run-train}\n",
        "\n",
        "## Training Phase\n"
      ],
      "id": "670fcb46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "dict = CTExperiments.from_toml(joinpath(config_dir,\"gen_params.toml\")) \n",
        "println(CTExperiments.dict_to_quarto_markdown(dict))"
      ],
      "id": "995994db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "::: {#exr-gen-params-first-run-eval}\n",
        "\n",
        "## Evaluation Phase\n"
      ],
      "id": "bd2da3ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "dict = CTExperiments.from_toml(joinpath(results_dir, \"gen_params/mlp/lin_sep/evaluation/evaluation_grid_config.toml\"))\n",
        "println(CTExperiments.dict_to_quarto_markdown(dict))"
      ],
      "id": "07a9b400",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n"
      ],
      "id": "d2fa2c7c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gen_params_dir = joinpath(results_dir, \"gen_params/mlp\")"
      ],
      "id": "659c16b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Linearly Separable \n",
        "\n",
        "- **Energy Penalty** (@tbl-lin_sep-lambda_energy_exper): *ECCo* generally does yield better results than *Vanilla* for higher choices of the energy penalty (10,15) during training. *Generic* performs poorly accross the board. *Omni* seems to have an anchoring effect, in that it never performs terribly but also never as good as the best *ECCo* results. *REVISE* performs poorly across the board.\n",
        "- **Cost** (@tbl-lin_sep-lambda_cost_exper): Results for all generators (except *Omni*) are quite bad, which can likely be attributed to extremely bad results for some choices of the **Energy Penalty** (results here are averaged). For *ECCo* and *Generic*, higher cost values generally lead to worse results.\n",
        "- **Maximum Iterations**: No clear patterns recognizable, so it seems that smaller choices are ok. \n",
        "- **Validity**: *ECCo* almost always valid except for very low values during training and high values at evaluation time. *Generic* often has poor validity.\n",
        "- **Accuracy**: Seems largely unaffected.\n"
      ],
      "id": "d5251847"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = CSV.read(\"$(gen_params_dir)/lin_sep/evaluation/results/ce/objective---lambda_energy_exper---lambda_energy_eval/plausibility_distance_from_target.csv\", DataFrame)\n",
        "df = groupby(df, Not(:run, :std, :mean, :lambda_energy_eval)) |> \n",
        "  gdf -> combine(gdf, :mean => (x -> [(mean(x),std(x))]) => [:value,:std]) |>\n",
        "  df -> sort(df, [:lambda_energy_exper, :objective, :generator_type])"
      ],
      "id": "d9935c12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tbl-lin_sep-lambda_energy_exper}\n",
        "\n",
        "::: {.content-hidden unless-format=\"pdf\"}\n"
      ],
      "id": "a3079570"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "get_table_inputs(df, \"value\"; alpha=0.9, byvars=\"lambda_energy_exper\", backend=Val(:latex)) |>\n",
        "    inputs -> tabulate_results(inputs; wrap_table=false)"
      ],
      "id": "10ea79c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Results for Linearly Separable data by energy penalty.\n",
        "\n",
        ":::\n",
        "\n",
        "<!-- Cost -->\n"
      ],
      "id": "a3e48cd7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = CSV.read(\"$(gen_params_dir)/lin_sep/evaluation/results/ce/objective---lambda_cost_exper---lambda_energy_eval/plausibility_distance_from_target.csv\", DataFrame)\n",
        "df = groupby(df, Not(:run, :std, :mean, :lambda_energy_eval)) |> \n",
        "  gdf -> combine(gdf, :mean => (x -> [(mean(x),std(x))]) => [:value,:std]) |>\n",
        "  df -> sort(df, [:lambda_cost_exper, :objective, :generator_type])"
      ],
      "id": "6e9f7d1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tbl-lin_sep-lambda_cost_exper}\n",
        "\n",
        "::: {.content-hidden unless-format=\"pdf\"}\n"
      ],
      "id": "b7338a20"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "get_table_inputs(df, \"value\"; alpha=0.9, byvars=\"lambda_cost_exper\", backend=Val(:latex)) |>\n",
        "    inputs -> tabulate_results(inputs; wrap_table=false)"
      ],
      "id": "c00dc0df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Results for Linearly Separable data by cost penalty.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "#### Moons\n",
        "\n",
        "- **Energy Penalty** (@tbl-moons-lambda_energy_exper): *ECCo* consistently yields better results than *Vanilla*, except for very low choices of the energy penalty during training for which it performs abismal. *Generic* performs quite badly across the board for high enough choices of the energy penalty at evaluation time. *Omni* has small positive effect. *REVISE* performs poorly across the board.\n",
        "- **Cost (distance penalty)**: *Generic* generally does better for higher values, while *ECCo* does better for lower values.\n",
        "- **Maximum Iterations**: No clear patterns recognizable, so it seems that smaller choices are ok. \n",
        "- **Validity**: *ECCo* generally achieves full validity except for very low choices the energy penalty during training and high choices at evaluation time. *Generic* performs poorly for high choices of the energy penalty during evaluation.\n",
        "- **Accuracy**: Largely unaffected although *ECCo* suffers a bit for very low choices the energy penalty during training. *REVISE* suffers a lot in general (around 10 percentage points).\n"
      ],
      "id": "6efac4aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = CSV.read(\"$(gen_params_dir)/moons/evaluation/results/ce/objective---lambda_energy_exper---lambda_energy_eval/plausibility_distance_from_target.csv\", DataFrame)\n",
        "df = groupby(df, Not(:run, :std, :mean, :lambda_energy_eval)) |> \n",
        "  gdf -> combine(gdf, :mean => (x -> [(mean(x),std(x))]) => [:value,:std]) |>\n",
        "  df -> sort(df, [:lambda_energy_exper, :objective, :generator_type]) "
      ],
      "id": "7b3ca798",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tbl-moons-lambda_energy_exper}\n",
        "\n",
        "::: {.content-hidden unless-format=\"pdf\"}\n"
      ],
      "id": "d568587c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "get_table_inputs(df, \"value\"; alpha=0.9, byvars=\"lambda_energy_exper\", backend=Val(:latex)) |>\n",
        "    inputs -> tabulate_results(inputs)"
      ],
      "id": "a3c66954",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Results for Moons data by energy penalty.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Circles\n",
        "\n",
        "- **Energy Penalty** (@tbl-circles-lambda_energy_exper): *ECCo* consistently yields better results than *Vanilla*, though primarily for low to medium choices of the energy penalty (<=5) during training. The same goes for *Generic*, which sometimes outperforms *ECCo* (for small energy penalty at evaluation time). *Omni* does alright for lower energy penalty at evaluation time, but loses out for higher choices. *REVISE* performs poorly across the board (except very low choices at evaluation time).\n",
        "- **Cost (distance penalty)**: *ECCo* and *Generic* generally achieve the best results when no cost penalty is used during training. Both *Omni* and *REVISE* are largely unaffected.\n",
        "- **Maximum Iterations**: *ECCo* consistently yields better results for higher numbers of iterations. *Generic* generally does best for a medium number (50). *Omni* is sometimes invalid (**???**).\n",
        "- **Validity**: *ECCo* tends to outperform its *Vanilla* counterpart, though primarily for low to medium choices of the energy penalty (<=5) during training and evaluation. *Vanilla* typically worse across the board.\n",
        "- **Accuracy**: Mostly unaffected, but *REVISE* again consistently some deterioration and *ECCo* deteriorates for high choices of energy penalty during training, reflecting other outcomes above.\n"
      ],
      "id": "886f06b2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = CSV.read(\"$(gen_params_dir)/circles/evaluation/results/ce/objective---lambda_energy_exper---lambda_energy_eval/plausibility_distance_from_target.csv\", DataFrame)\n",
        "df = groupby(df, Not(:run, :std, :mean, :lambda_energy_eval)) |> \n",
        "  gdf -> combine(gdf, :mean => (x -> [(mean(x),std(x))]) => [:value,:std]) |>\n",
        "  df -> sort(df, [:lambda_energy_exper, :objective, :generator_type]) "
      ],
      "id": "556f9408",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {#tbl-circles-lambda_energy_exper}\n",
        "\n",
        "::: {.content-hidden unless-format=\"pdf\"}\n"
      ],
      "id": "a40abf03"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: asis\n",
        "get_table_inputs(df, \"value\"; alpha=0.9, byvars=\"lambda_energy_exper\", backend=Val(:latex)) |>\n",
        "    inputs -> tabulate_results(inputs)"
      ],
      "id": "e4d86725",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Results for Circles data by energy penalty.\n",
        "\n",
        ":::"
      ],
      "id": "9f4315b3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.11",
      "language": "julia",
      "display_name": "Julia 1.11.1",
      "path": "/Users/paltmeyer/Library/Jupyter/kernels/julia-1.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}