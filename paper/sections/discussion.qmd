# Discussion {#sec-discussion}

As our results indicate, counterfactual training produces models that are more explainable. Nonetheless, these advantages come at the cost of two important limitations.  

*Interventions on features have implications for fairness.* We provide a method to modify the sensitivity of a model to certain features, which can be misused by enforcing explanations based on features that are more difficult to modify by a (group of) decision subjects. Such abuse could result in an unfairly assigned burden of recourse [@sharma2020certifai], threatening the equality of opportunity [@bell2024fairness]. Also, even if all immutable features are protected, there may exist proxies that are theoretically mutable, but preserve sufficient information about the principals to hinder these protections. Indeed, deciding on the actionability of features remains a major open challenge in the AR literature [@venkatasubramanian2020philosophical].

*CT increases the training times.* Like adversarial training, CT is more resource-intensive than conventional regimes. Higher numbers of CEs improve the quality of the learned representations but they also increase the number of computations. As our codebase is not performance optimized, grids of around 300 settings for the largest datasets in our experiments took up to four hours using 34 2GB CPUs (see supplementary appendix). Other than optimization, three factors mitigate this effect: (1) CT yields itself to parallel execution; (2) it amortizes the cost of CEs for the training samples; and (3) it can be used to fine-tune conventionally-trained models.  

We also highlight three key directions for future research. Firstly, it is an interesting challenge to extend CT beyond classification settings. Our formulation relies on the distinction between non-target class(es) and target class(es), requiring the output space to be discrete. Thus, it does not apply to ML tasks where the change in outcome cannot be readily discretized. Focus on classification is a common choice in research on CEs and AR; other settings have attracted some interest, e.g., regression [@spooner2021counterfactual], but there is little consensus how to robustly extend the notion of CEs.  

Secondly, CT is susceptible to training instabilities, as is also the case for the related JEMs [@grathwohl2020your]. CT is exposed to two sources of instabilities: (1) the energy-based contrastive divergence term, $\text{div}(\cdot)$, in @eq-div, and (2) the underlying explainers. We find several promising ways to mitigate this problem: regularizing energy ($\lambda_{\text{reg}}$), generating sufficiently many counterfactuals during each epoch, and including only mature counterfactuals in $\text{div}(\cdot)$.  

Finally, we believe that it is possible to considerably improve hyperparameter selection procedures, and thus performance. We have relied exclusively on grid searches, but future work could benefit from more sophisticated approaches.