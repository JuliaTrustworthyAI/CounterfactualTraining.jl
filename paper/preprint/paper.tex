% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
  \setmainfont[]{Latin Modern Roman}
  \setmathfont[]{Latin Modern Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\usepackage[title]{appendix}
\usepackage{placeins}
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\theoremstyle{plain}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{siunitx}
\sisetup{uncertainty-mode = separate}
\DeclareMathSizes{10}{9}{7}{6.5}
\usepackage{enumitem}
\usepackage{arxiv}
\usepackage{orcidlink}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{placeins}
\usepackage{siunitx}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[section]
\newtheorem{refsolution}{Solution}[section]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\newcounter{quartocalloutnteno}
\newcommand{\quartocalloutnte}[1]{\refstepcounter{quartocalloutnteno}\label{#1}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Counterfactual Training: Teaching Models Plausible and Actionable Explanations},
  pdfauthor={Patrick Altmeyer; Aleksander Buszydlik; Arie van Deursen; Cynthia C. S. Liem},
  pdfkeywords={Counterfactual Training, Counterfactual
Explanations, Algorithmic Recourse, Explainable AI, Representation
Learning},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\newcommand{\runninghead}{A Preprint }
\renewcommand{\runninghead}{Counterfactual Training }
\title{Counterfactual Training: Teaching Models Plausible and Actionable
Explanations}
\def\asep{\\\\\\ } % default: all authors on same column
\def\asep{\And }
\author{\textbf{Patrick
Altmeyer}~\orcidlink{0000-0003-4726-8613}\\Faculty of Electrical
Engineering, Mathematics and Computer Science\\Delft University of
Technology\\\\\href{mailto:p.altmeyer@tudelft.nl}{p.altmeyer@tudelft.nl}\asep\textbf{Aleksander
Buszydlik}\\Faculty of Electrical Engineering, Mathematics and Computer
Science\\Delft University of Technology\\\\\asep\textbf{Arie van
Deursen}\\Faculty of Electrical Engineering, Mathematics and Computer
Science\\Delft University of Technology\\\\\asep\textbf{Cynthia C. S.
Liem}\\Faculty of Electrical Engineering, Mathematics and Computer
Science\\Delft University of Technology\\\\}
\date{}
\begin{document}
\maketitle
\begin{abstract}
We propose a novel training regime termed counterfactual training that
leverages counterfactual explanations to increase the explanatory
capacity of models. Counterfactual explanations have emerged as a
popular post-hoc explanation method for opaque machine learning models:
they inform how factual inputs would need to change in order for a model
to produce some desired output. To be useful in real-word
decision-making systems, counterfactuals should be plausible with
respect to the underlying data and actionable with respect to the
feature mutability constraints. Much existing research has therefore
focused on developing post-hoc methods to generate counterfactuals that
meet these desiderata. In this work, we instead hold models directly
accountable for the desired end goal: counterfactual training employs
counterfactuals during the training phase to minimize the divergence
between learned representations and plausible, actionable explanations.
We demonstrate empirically and theoretically that our proposed method
facilitates training models that deliver inherently desirable
counterfactual explanations and exhibit greatly improved adversarial
robustness.
\end{abstract}
{\bfseries \emph Keywords}
\def\sep{\textbullet\ }
Counterfactual Training \sep Counterfactual
Explanations \sep Algorithmic Recourse \sep Explainable AI \sep 
Representation Learning



\section{Introduction}\label{introduction}

Today's prominence of artificial intelligence (AI) has largely been
driven by the success of representation learning with high degrees of
freedom: instead of relying on features and rules hand-crafted by
humans, modern machine learning (ML) models are tasked with learning
highly complex representations directly from the data, guided by narrow
objectives such as predictive accuracy
(\citeproc{ref-goodfellow2016deep}{Goodfellow, Bengio, and Courville
2016}). These models tend to be so complex that humans cannot easily
interpret their decision logic.

Counterfactual explanations (CE) have become a key part of the broader
explainable AI (XAI) toolkit
(\citeproc{ref-molnar2022interpretable}{Molnar 2022}) that can be
applied to make sense of this complexity. Originally proposed by
Wachter, Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}), CEs prescribe minimal
changes for factual inputs that, if implemented, would prompt some
fitted model to produce an alternative, more desirable output. This is
useful and necessary to not only understand how opaque models make their
predictions, but also to provide algorithmic recourse (AR) to
individuals subjected to them: a retail bank, for example, could use CE
to provide meaningful feedback to unsuccessful loan applicants that were
rejected based on an opaque automated decision-making (ADM) system
(Figure~\ref{fig-poc}).

For such feedback to be meaningful, counterfactual explanations need to
fulfill certain desiderata (\citeproc{ref-verma2020counterfactual}{Verma
et al. 2022}; \citeproc{ref-karimi2020survey}{Karimi et al.
2021})---they should be faithful to the model
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}), plausible
(\citeproc{ref-joshi2019realistic}{Joshi et al. 2019}) and actionable
(\citeproc{ref-ustun2019actionable}{Ustun, Spangher, and Liu 2019}).
Plausibility is typically understood as counterfactuals being
\emph{in-domain}: unsuccessful loan applicants that implement the
provided recourse should end up with credit profiles that are genuinely
similar to that of individuals who have successfully repaid their loans
in the past. Actionable explanations comply with practical constraints:
a young, unsuccessful loan applicant cannot increase their age in an
instance.

Existing state-of-the-art (SOTA) approaches in the field have largely
focused on designing model-agnostic CE methods that identify subsets of
counterfactuals, which comply with specific desiderata. This is
problematic, because the narrow focus on any specific desideratum can
adversely affect others: it is possible, for example, to generate
plausible counterfactuals for models that are also highly vulnerable to
implausible, possibly adversarial counterfactuals
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}). In this
work, we therefore embrace the paradigm that models (as opposed to
explanation methods) should be held accountable for explanations that
are plausible and actionable. While previous work has shown that at
least plausibility can be indirectly achieved through existing
techniques aimed at models' generative capacity, generalization and
robustness (\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024};
\citeproc{ref-augustin2020adversarial}{Augustin, Meinke, and Hein 2020};
\citeproc{ref-schut2021generating}{Schut et al. 2021}), we directly
incorporate both plausibility and actionability in the training
objective of models to improve their overall explanatory capacity.

Specifically, we propose \textbf{counterfactual training (CT)}: a novel
training regime that leverages counterfactual explanations on-the-fly to
ensure that differentiable models learn plausible and actionable
explanations for the underlying data, while at the same time also being
more robust to adversarial examples (AE). Figure~\ref{fig-poc}
illustrates the outcomes of CT compared to a conventionally trained
model. First, in panel (a), faithful and valid counterfactuals end up
near the decision boundary forming a clearly distinguishable cluster in
the target class (orange). In panel (b), CT is applied to the same
underlying linear classifier architecture resulting in much more
plausible counterfactuals. In panel (c), the classifier is again trained
conventionally and we have introduced a mutability constraint on the
\emph{age} feature at test time---counterfactuals are valid but the
classifier is roughly equally sensitive to both features. By contrast,
the decision boundary in panel (d) has titled, making the model trained
with CT relatively less sensitive to the immutable \emph{age} feature.
To achieve these outcomes, CT draws inspiration from the literature on
contrastive and robust learning: we contrast faithful CEs with
ground-truth data while protecting immutable features, and capitalize on
methodological links between CE and AE by penalizing the model's
adversarial loss on interim (\emph{nascent}) counterfactuals. To the
best of our knowledge, CT represents the first venture in this direction
with promising empirical and theoretical results.

The remainder of this manuscript is structured as follows.
Section~\ref{sec-lit} presents related work, focusing on the links to
contrastive and robust learning. Then follow our two principal
contributions. In Section~\ref{sec-method}, we introduce our
methodological framework and show theoretically that it can be employed
to respect global actionability constraints. In our experiments
(Section~\ref{sec-experiments}), we find that thanks to counterfactual
training, (1) the implausibility of CEs decreases by up to 90\%; (2) the
cost of reaching valid counterfactuals with protected features decreases
by 19\% on average; and (3) models' adversarial robustness improves
across the board. Finally, we discuss open challenges in
Section~\ref{sec-discussion} and conclude in
Section~\ref{sec-conclusion}.

\begin{figure*}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{paper_files/mediabag/../../paper/figures/poc.pdf}}

}

\caption{\label{fig-poc}Counterfactual explanations (stars) for linear
classifiers trained under different regimes on synthetic data: (a)
conventional training, all mutable; (b) CT, all mutable; (c)
conventional, \emph{age} immutable; (d) CT, \emph{age} immutable. The
linear decision boundary is shown in green along with training data
colored according to ground-truth labels: \(y^-=\text{"loan withheld"}\)
(blue) and \(y^+=\text{"loan provided"}\) (orange). Class and feature
annotations (\emph{debt} and \emph{age}) are for illustrative purposes.}

\end{figure*}%

\section{Related Literature}\label{sec-lit}

To make the desiderata for our framework more concrete, we follow
previous work in tying the explanatory capacity of models to the quality
of CEs that can be generated for them
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024};
\citeproc{ref-augustin2020adversarial}{Augustin, Meinke, and Hein
2020}). For simplicity, we refer to ``explanatory capacity'' as
``explainability'' in the rest of this manuscript (see Def.
\ref{def-explainability}).

\subsection{Explainability and Contrastive
Learning}\label{explainability-and-contrastive-learning}

In a closely related work, Altmeyer et al.
(\citeproc{ref-altmeyer2024faithful}{2024}) show that model averaging
and, in particular, contrastive model objectives can produce more
explainable and hence trustworthy models. The authors propose a way to
generate counterfactuals that are maximally faithful in that they are
consistent with what models have learned about the underlying data.
Formally, they rely on tools from energy-based modelling
(\citeproc{ref-teh2003energy}{Teh et al. 2003}) to minimize the
contrastive divergence between the distribution of counterfactuals and
the conditional posterior over inputs learned by a model. Their
algorithm, \emph{ECCCo}, yields plausible counterfactual explanations if
and only if the underlying model has learned representations that align
with them. The authors find that both deep ensembles
(\citeproc{ref-lakshminarayanan2016simple}{Lakshminarayanan, Pritzel,
and Blundell 2017}) and joint energy-based models (JEMs)
(\citeproc{ref-grathwohl2020your}{Grathwohl et al. 2020}), a form of
constrastive learning, tend to do well in this regard.

It helps to look at these findings through the lens of representation
learning with high degrees of freedom. Deep ensembles are approximate
Bayesian model averages, which are particularly effective when models
are underspecified by the available data
(\citeproc{ref-wilson2020case}{Wilson 2020}). Averaging across solutions
mitigates the risk of overrelying on a single locally optimal
representation that corresponds to semantically meaningless
explanations. Likewise, previous work of Schut et al.
(\citeproc{ref-schut2021generating}{2021}) found that generating
plausible (``interpretable'') CEs is almost trivial for deep ensembles
that have undergone adversarial training. The case for JEMs is even
clearer: they optimize a hybrid objective that induces both high
predictive performance and strong generative capacity
(\citeproc{ref-grathwohl2020your}{Grathwohl et al. 2020}), which
resembles the idea of aligning models with plausible explanations and
has inspired CT.

\subsection{Explainability and Robust
Learning}\label{explainability-and-robust-learning}

Augustin, Meinke, and Hein
(\citeproc{ref-augustin2020adversarial}{2020}) show that CEs tend to be
more meaningful (``explainable'') if the underlying model is more robust
to adversarial examples. Once again, we can make intuitive sense of this
finding if we look at adversarial training (AT) through the lens of
representation learning with high degrees of freedom: highly complex and
flexible models may learn representations that make them sensitive to
implausible or even adversarial examples
(\citeproc{ref-szegedy2013intriguing}{Szegedy et al. 2014}). Thus, by
inducing models to ``unlearn'' susceptibility to such examples,
adversarial training can effectively remove implausible explanations
from the solution space.

This interpretation of the link between explainability through
counterfactuals on the one side, and robustness to adversarial examples
on the other is backed by empirical evidence. Sauer and Geiger
(\citeproc{ref-sauer2021counterfactual}{2021}) demonstrate that using
counterfactual images during classifier training improves model
robustness. Similarly, Abbasnejad et al.
(\citeproc{ref-abbasnejad2020counterfactual}{2020}) argue that
counterfactuals represent potentially useful training data in machine
learning, especially in supervised settings where inputs may be
reasonably mapped to multiple outputs. They, too, show that augmenting
the training data of (image) classifiers can improve generalization
performance. Finally, Teney, Abbasnedjad, and Hengel
(\citeproc{ref-teney2020learning}{2020}) argue that counterfactual pairs
tend to exist in training data. Hence, their approach aims to identify
similar input samples with different annotations and ensure that the
gradient of the classifier aligns with the vector between such pairs of
counterfactual inputs using a cosine distance loss function.

CEs have also been used to improve models in the natural language
processing domain. For example, Wu et al.
(\citeproc{ref-wu2021polyjuice}{2021}) propose \emph{Polyjuice}, a
general-purpose CE generator for language models and demonstrate that
the augmentation of training data with \emph{Polyjuice} improves
robustness in a number of tasks, while Luu and Inoue
(\citeproc{ref-luu2023counterfactual}{2023}) introduce the
\emph{Counterfactual Adversarial Training} (CAT) framework that aims to
improve generalization and robustness of language models by generating
counterfactuals for training samples that are subject to high predictive
uncertainty.

There have also been several attempts at formalizing the relationship
between counterfactual explanations and adversarial examples. Pointing
to clear similarities in how CEs and AEs are generated, Freiesleben
(\citeproc{ref-freiesleben2022intriguing}{2022}) makes the case for
jointly studying the opaqueness and robustness problems in
representation learning. Formally, AEs can be seen as the subset of CEs
for which misclassification is achieved
(\citeproc{ref-freiesleben2022intriguing}{Freiesleben 2022}). Similarly,
Pawelczyk et al. (\citeproc{ref-pawelczyk2022exploring}{2022}) show that
CEs and AEs are equivalent under certain conditions.

Two other works are closely related to ours in that they use
counterfactuals during training with the explicit goal of affecting
certain properties of the post-hoc counterfactual explanations. Firstly,
Ross, Lakkaraju, and Bastani (\citeproc{ref-ross2021learning}{2024})
propose a way to train models that guarantee recourse to a positive
target class with high probability. Their approach builds on adversarial
training by explicitly inducing susceptibility to targeted AEs for the
positive class. Additionally, the method allows for imposing a set of
actionability constraints ex-ante. For example, users can specify that
certain features are immutable. Secondly, Guo, Nguyen, and Yadav
(\citeproc{ref-guo2023counternet}{2023}) are the first to propose an
end-to-end training pipeline that includes CEs as part of the training
procedure. Their \emph{CounterNet} network architecture includes a
predictor and a CE generator, where the parameters of the CE generator
are learnable. Counterfactuals are generated during each training
iteration and fed back to the predictor. In contrast, we impose no
restrictions on the ANN architecture at all.

\section{Counterfactual Training}\label{sec-method}

This section introduces the counterfactual training framework, applying
ideas from contrastive and robust learning to counterfactual
explanations. CT produces models whose learned representations align
with plausible explanations that comply with user-defined actionability
constraints.

Counterfactual explanations are typically generated by solving
variations of the following optimization problem,
\begin{equation}\phantomsection\label{eq-general}{
\begin{aligned}
\min_{\mathbf{X}^\prime \in \mathcal{X}^D} \left\{  {\text{yloss}(\mathbf{M}_\theta(\mathbf{x}^{\prime}),\mathbf{y}^+)}+ \lambda {\text{reg}(\mathbf{x}^{\prime}) }  \right\} 
\end{aligned}
}\end{equation} where
\(\mathbf{M}_\theta: \mathcal{X} \mapsto \mathcal{Y}\) denotes a
classifier, \(\mathbf{x}^{\prime}\) denotes the counterfactual with
\(D\) features and \(\mathbf{y}^+\in\mathcal{Y}\) denotes some target
class. The \(\text{yloss}(\cdot)\) function quantifies the discrepancy
between current model predictions for \(\mathbf{x}^{\prime}\) and the
target class (a conventional choice is cross-entropy). Finally, we use
\(\text{reg}(\cdot)\) to denote any form of regularization used to
induce certain properties on the counterfactual. In their seminal paper,
Wachter, Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}) propose regularizing
the distance between counterfactuals and their original factual values
to ensure that individuals seeking recourse through CE face minimal
costs in terms of feature changes. Different variations of
Equation~\ref{eq-general} have been proposed in the literature to
address many desiderata including the ones discussed above
(faithfulness, plausibility and actionability). Like Wachter,
Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}), most of these
approaches rely on gradient descent to optimize
Equation~\ref{eq-general}. For more details on the approaches tested in
this work, we refer the reader to the supplementary appendix. In the
following, we describe in detail how counterfactuals are generated and
used in counterfactual training.

\subsection{Proposed Training
Objective}\label{proposed-training-objective}

The goal of CT is to improve model explainability by aligning models
with faithful explanations that are plausible and actionable. Formally,
we define explainability as follows:

\begin{definition}[Model Explainability]
\label{def-explainability}
Let $\mathbf{M}_\theta: \mathcal{X} \mapsto \mathcal{Y}$ denote a supervised classification model that maps from the $D$-dimensional input space $\mathcal{X}$ to representations $\phi(\mathbf{x};\theta)$ and finally to the $K$-dimensional output space $\mathcal{Y}$. Assume that for any given input-output pair $\{\mathbf{x},\mathbf{y}\}_i$ there exists a counterfactual $\mathbf{x}^{\prime} = \mathbf{x} + \Delta: \mathbf{M}_\theta(\mathbf{x}^{\prime}) = \mathbf{y}^{+} \neq \mathbf{y} = \mathbf{M}_\theta(\mathbf{x})$, where $\arg\max_y{\mathbf{y}^{+}}=y^+$ is the index of the target class. 

We say that $\mathbf{M}_\theta$ has an \textbf{explanatory capacity} to the extent that faithfully generated, valid counterfactuals are also plausible and actionable. We define these properties as:

\begin{itemize}
    \item (Faithfulness) $\int^{A} p_\theta(\mathbf{x}^\prime|\mathbf{y}^{+})d\mathbf{x} \rightarrow 1$; $A$ is an arbitrarily small region around $\mathbf{x}^{\prime}$.
    \item (Plausibility) $\int^{A} p(\mathbf{x}^\prime|\mathbf{y}^{+})d\mathbf{x} \rightarrow 1$; $A$ as specified above.
    \item (Actionability) Perturbations $\Delta$ may be subject to some actionability constraints.
\end{itemize}
Here, $p_\theta(\mathbf{x}|\mathbf{y}^{+})$ denotes the conditional posterior distribution over inputs. For simplicity, we refer to a model with high explanatory capacity as \textbf{explainable} in this manuscript. 
\end{definition}

The characterization of faithfulness and plausibility in Def.
\ref{def-explainability} follows Altmeyer et al.
(\citeproc{ref-altmeyer2024faithful}{2024}), with adapted notation.
Intuitively, plausible counterfactuals are consistent with the data and
faithful counterfactuals are consistent with what the model has learned
about the input data. Ac tionability constraints in Def.
\ref{def-explainability} vary and depend on the context in which
\(\mathbf{M}_\theta\) is deployed. In this work, we choose to only
consider domain and mutability constraints for individual features
\(x_d\) for \(d=1,...,D\). We also limit ourselves to classification
tasks for reasons discussed in Section~\ref{sec-discussion}.

Let \(\mathbf{x}_t^\prime\) for \(t=0,...,T\) denote a counterfactual
generated through gradient descent over \(T\) iterations as originally
proposed by Wachter, Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}). CT adopts
gradient-based CE search in training to generate on-the-fly model
explanations \(\mathbf{x}^\prime\) for the training samples. We use the
term \emph{nascent} to denote interim counterfactuals
\(\mathbf{x}_{t\leq T}^\prime\) that have not yet converged. As we
explain below, these nascent counterfactuals can be stored and
repurposed as adversarial examples. Conversely, we consider
counterfactuals \(\mathbf{x}_T^\prime\) as \emph{mature} explanations if
they have either exhausted all \(T\) iterations or converged by reaching
a pre-specified threshold, \(\tau\), for the predicted probability of
the target class:
\(\mathcal{S}(\mathbf{M}_\theta(\mathbf{x}^\prime))[y^+] \geq \tau\),
where \(\mathcal{S}\) is the softmax function.

Formally, we propose the following counterfactual training objective to
train explainable (as in Def. \ref{def-explainability}) models,
\begin{equation}\phantomsection\label{eq-obj}{
\begin{aligned}
&\min_\theta \text{yloss}(\mathbf{M}_\theta(\mathbf{x}),\mathbf{y}) + \lambda_{\text{div}} \text{div}(\mathbf{x}^+,\mathbf{x}_T^\prime,y;\theta) \\+ &\lambda_{\text{adv}} \text{advloss}(\mathbf{M}_\theta(\mathbf{x}_{t\leq T}^\prime),\mathbf{y}) + \lambda_{\text{reg}}\text{ridge}(\mathbf{x}^+,\mathbf{x}_T^\prime,y;\theta)
\end{aligned}
}\end{equation} where \(\text{yloss}(\cdot)\) is any classification loss
that induces discriminative performance (e.g., cross-entropy). The
second and third terms are explained in detail below. For now, they can
be summarized as inducing explainability directly and indirectly by
penalizing (1) the contrastive divergence, \(\text{div}(\cdot)\),
between mature counterfactuals \(\mathbf{x}_T^\prime\) and observed
samples \(\mathbf{x}^+\in\mathcal{X}^+=\{\mathbf{x}:y=y^+\}\) in the
target class \(y^+\), and (2) the adversarial loss,
\(\text{advloss}(.)\), wrt. nascent counterfactuals
\(\mathbf{x}_{t\leq T}^\prime\). Finally, \(\text{ridge}(\cdot)\)
denotes a Ridge penalty (\(\ell_2\)-norm) that regularizes the magnitude
of the energy terms involved in \(\text{div}(\cdot)\)
(\citeproc{ref-du2019implicit}{Du and Mordatch 2020}). The trade-offs
between these components are adjusted through \(\lambda_{\text{div}}\),
\(\lambda_{\text{adv}}\) and \(\lambda_{\text{reg}}\). The full training
regime is sketched out in Algorithm \ref{alg-experiment}.

\begin{algorithm}[h]
  \caption{Counterfactual Training}
    \label{alg-experiment}
    \begin{algorithmic}[1]
    \REQUIRE Training dataset $\mathcal{D}$, initialize model $\mathbf{M}_{\theta}$
    \WHILE{not converged}
        \STATE Sample $\mathbf{x}$ and $\mathbf{y}$ from dataset $\mathcal{D}$.
        \STATE Sample $\mathbf{x}^{\prime}_0$, $\mathbf{y}^+$ and $\mathbf{x}^+$.
        \FOR{$t = 1$ to $T$}
            \STATE Backpropagate $\nabla_{\mathbf{x}^\prime}$ through Equation \ref{eq-general}. Store $\mathbf{x}_t^\prime$.
        \ENDFOR
        \STATE Backpropagate $\nabla_{\theta}$ through Equation \ref{eq-obj}.
    \ENDWHILE
    \RETURN $\mathbf{M}_\theta$
    \end{algorithmic}
\end{algorithm}

\subsection{Directly Inducing Explainability with Contrastive
Divergence}\label{directly-inducing-explainability-with-contrastive-divergence}

Grathwohl et al. (\citeproc{ref-grathwohl2020your}{2020}) observe that
any classifier can be re-interpreted as a joint energy-based model that
learns to discriminate output classes conditional on the observed
(training) samples from \(p(\mathbf{x})\) and the generated samples from
\(p_\theta(\mathbf{x})\). The authors show that JEMs can be trained to
perform well at both tasks by directly maximizing the joint
log-likelihood:
\(\log p_\theta(\mathbf{x},\mathbf{y})=\log p_\theta(\mathbf{y}|\mathbf{x}) + \log p_\theta(\mathbf{x})\),
where the first term can be optimized using cross-entropy as in
Equation~\ref{eq-obj}. To optimize \(\log p_\theta(\mathbf{x})\), they
minimize the contrastive divergence between the observed samples from
\(p(\mathbf{x})\) and samples generated from \(p_\theta(\mathbf{x})\).

To generate samples, Grathwohl et al.
(\citeproc{ref-grathwohl2020your}{2020}) use Stochastic Gradient
Langevin Dynamics (SGLD) with an uninformative prior for initialization
but we depart from their methodology: we propose to leverage
counterfactual explainers to generate counterfactuals of observed
training samples. Specifically, we have:
\begin{equation}\phantomsection\label{eq-div}{
\text{div}(\mathbf{x}^+,\mathbf{x}_T^\prime,y;\theta) = \mathcal{E}_\theta(\mathbf{x}^+,y) - \mathcal{E}_\theta(\mathbf{x}_T^\prime,y)
}\end{equation} where \(\mathcal{E}_\theta(\cdot)\) denotes the energy
function defined as
\(\mathcal{E}_\theta(\mathbf{x},y)=-\mathbf{M}_\theta(\mathbf{x})[y^+]\),
with \(y^+\) denoting the index of the randomly drawn target class,
\(y^+ \sim p(y)\). Conditional on the target class \(y^+\),
\(\mathbf{x}_T^\prime\) denotes a mature counterfactual for a randomly
sampled factual from a non-target class generated with a gradient-based
CE generator for up to \(T\) iterations. Intuitively, the gradient of
Equation~\ref{eq-div} decreases the energy of observed training samples
(positive samples) while increasing the energy of counterfactuals
(negative samples) (\citeproc{ref-du2019implicit}{Du and Mordatch
2020}). As the counterfactuals get more plausible (Def.
\ref{def-explainability}) during training, these opposing effects
gradually balance each other out (\citeproc{ref-lippe2024uvadlc}{Lippe
2024}).

Since maturity of counterfactuals in terms of a probability threshold is
often reached before \(T\), this form of sampling is not only more
closely aligned with Def. \ref{def-explainability}., but can also speed
up training times compared to SGLD. The departure from SGLD also allows
us to tap into the vast repertoire of explainers that have been proposed
in the literature to meet different desiderata. For example, many
methods support domain and mutability constraints. In principle, any
existing approach for generating CEs is viable, so long as it does not
violate the faithfulness condition. Like JEMs
(\citeproc{ref-murphy2022probabilistic}{Murphy 2022}), counterfactual
training can be considered a form of contrastive representation
learning.

\subsection{Indirectly Inducing Explainability with Adversarial
Robustness}\label{indirectly-inducing-explainability-with-adversarial-robustness}

Based on our analysis in Section~\ref{sec-lit}, counterfactuals
\(\mathbf{x}^\prime\) can be repurposed as additional training samples
(\citeproc{ref-balashankar2023improving}{Balashankar et al. 2023};
\citeproc{ref-luu2023counterfactual}{Luu and Inoue 2023}) or adversarial
examples (\citeproc{ref-freiesleben2022intriguing}{Freiesleben 2022};
\citeproc{ref-pawelczyk2022exploring}{Pawelczyk et al. 2022}). This
leaves some flexibility with regards to the choice for the
\(\text{advloss}(\cdot)\) term in Equation~\ref{eq-obj}. An intuitive
functional form, but likely not the only sensible choice, is inspired by
adversarial training: \begin{equation}\phantomsection\label{eq-adv}{
\begin{aligned}
\text{advloss}(\mathbf{M}_\theta(\mathbf{x}_{t\leq T}^\prime),\mathbf{y};\varepsilon)&=\text{yloss}(\mathbf{M}_\theta(\mathbf{x}_{t_\varepsilon}^\prime),\mathbf{y}) \\
t_\varepsilon &= \max_t \{t: ||\Delta_t||_\infty < \varepsilon\}
\end{aligned}
}\end{equation} Under this choice, we consider nascent counterfactuals
\(\mathbf{x}_{t\leq T}^\prime\) as AEs as long as the magnitude of the
perturbation to any single feature is at most \(\varepsilon\). This is
closely aligned with Szegedy et al.
(\citeproc{ref-szegedy2013intriguing}{2014}) who define an adversarial
attack as an ``imperceptible non-random perturbation''. Thus, we work
with a different distinction between CE and AE than Freiesleben
(\citeproc{ref-freiesleben2022intriguing}{2022}) who considers
misclassification as the distinguishing feature of adversarial examples.
One of the key observations of this work is that we can leverage CEs
during training and get AEs essentially for free to reap the
aforementioned benefits of adversarial training.

\subsection{Encoding Actionability Constraints}\label{sec-constraints}

Many existing counterfactual explainers support domain and mutability
constraints. In fact, both types of constraints can be implemented for
any explainer that relies on gradient descent in the feature space for
optimization (\citeproc{ref-altmeyer2023explaining}{Altmeyer, Deursen,
and Liem 2023}). In this context, domain constraints can be imposed by
simply projecting counterfactuals back to the specified domain, if the
previous gradient step resulted in updated feature values that were
out-of-domain. Similarly, mutability constraints can be enforced by
setting partial derivatives to zero to ensure that features are only
perturbed in the allowed direction, if at all.

Since actionability constraints are binding at test time, we also impose
them when generating \(\mathbf{x}^\prime\) during each training
iteration to inform model representations. Through their effect on
\(\mathbf{x}^\prime\), both types of constraints influence model
outcomes via Equation~\ref{eq-div}. Here it is crucial that we avoid
penalizing implausibility that arises due to mutability constraints. For
any mutability-constrained feature \(d\) this can be achieved by
enforcing \(\mathbf{x}^+[d] - \mathbf{x}^\prime[d]:=0\) whenever
perturbing \(\mathbf{x}^\prime[d]\) in the direction of
\(\mathbf{x}^+[d]\) would violate mutability constraints. Specifically,
we set \(\mathbf{x}^+[d] := \mathbf{x}^\prime[d]\) if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Feature \(d\) is strictly immutable in practice.
\item
  \(\mathbf{x}^+[d]>\mathbf{x}^\prime[d]\), but \(d\) can only be
  decreased in practice.
\item
  \(\mathbf{x}^+[d]<\mathbf{x}^\prime[d]\), but \(d\) can only be
  increased in practice.
\end{enumerate}

\noindent From a Bayesian perspective, setting
\(\mathbf{x}^+[d] := \mathbf{x}^\prime[d]\) can be understood as
assuming a point mass prior for \(p(\mathbf{x}^+)\) wrt. feature \(d\).
Intuitively, we think of this as ignoring implausibility costs of
immutable features, which effectively forces the model to instead seek
plausibility through the remaining features. This can be expected to
result in relatively lower sensitivity to immutable features; and higher
relative sensitivity to mutable features should make
mutability-constrained recourse less costly
(Section~\ref{sec-experiments}). Under certain conditions, this result
holds theoretically; for the proof, see the supplementary appendix:

\begin{proposition}[Protecting Immutable Features]
\label{prp-mtblty}
Let $f_\theta(\mathbf{x})=\mathcal{S}(\mathbf{M}_\theta(\mathbf{x}))=\mathcal{S}(\Theta\mathbf{x})$ denote a linear classifier with softmax activation $\mathcal{S}$ where $y\in\{1,...,K\}=\mathcal{K}$ and $\mathbf{x} \in \mathbb{R}^D$. Assume multivariate Gaussian class densities with common diagonal covariance matrix $\Sigma_k=\Sigma$ for all $k \in \mathcal{K}$, then protecting an immutable feature from the contrastive divergence penalty will result in lower classifier sensitivity to that feature relative to the remaining features, provided that at least one of those is discriminative and mutable.
\end{proposition}

\section{Experiments}\label{sec-experiments}

We seek to answer the following four research questions:

\begin{enumerate}[label={(\makebox[2em][c]{RQ\arabic*})}, leftmargin=3.5em]
    \item To what extent does the CT objective in Equation 1 induce models to learn plausible explanations?
    \item To what extent does CT result in more favorable algorithmic recourse outcomes in the presence of actionability constraints?
    \item To what extent does CT influence the adversarial robustness of trained models?
    \item What are the effects of hyperparameter selection on counterfactual training?
\end{enumerate}

\subsection{Experimental Setup}\label{experimental-setup}

Our focus is the improvement in explainability (Def.
\ref{def-explainability}). Thus, we primarily look at the plausibility
and cost of faithfully generated counterfactuals at test time. Other
metrics, such as validity and redundancy, are reported in the
supplementary appendix. To measure the cost, we follow the standard
proxy of distances (\(\ell_1\)-norm) between factuals and
counterfactuals. For plausibility, we assess how similar CEs are to
observed samples in the target domain,
\(\mathbf{X}^+\subset\mathcal{X}^+\). We rely on the metric used by
Altmeyer et al. (\citeproc{ref-altmeyer2024faithful}{2024}),
\begin{equation}\phantomsection\label{eq-impl-dist}{
\text{IP}(\mathbf{x}^\prime,\mathbf{X}^+) = \frac{1}{\lvert\mathbf{X}^+\rvert}\sum_{\mathbf{x} \in \mathbf{X}^+} \text{dist}(\mathbf{x}^{\prime},\mathbf{x})
}\end{equation} and introduce a novel divergence-based adaptation,
\begin{equation}\phantomsection\label{eq-impl-div}{
\text{IP}^*(\mathbf{X}^\prime,\mathbf{X}^+) = \text{MMD}(\mathbf{X}^\prime,\mathbf{X}^+)
}\end{equation} where \(\mathbf{X}^\prime\) denotes a collection of
counterfactuals and \(\text{MMD}(\cdot)\) is the unbiased estimate of
the squared population maximum mean discrepancy, proposed by Gretton et
al. (\citeproc{ref-gretton2012kernel}{2012}). The metric in
Equation~\ref{eq-impl-div} is equal to zero if and only if the two
distributions are exactly the same, \(\mathbf{X}^\prime=\mathbf{X}^+\).

To assess outcomes with respect to actionability for non-linear models,
we look at the average costs of valid counterfactuals in terms of their
distances from factual starting points. While this an imperfect proxy of
sensitivity, we hypothesize that CT can reduce these costs by teaching
models to seek plausibility with respect to mutable features, much like
we observe in Figure~\ref{fig-poc} in panel (d) compared to (c). We
supplement this analysis with qualitative findings for integrated
gradients (\citeproc{ref-sundararajan2017ig}{Sundararajan, Taly, and Yan
2017}). Finally, for predictive performance, we use standard metrics,
such as robust accuracy estimated on adversarially perturbed data using
FGSM (\citeproc{ref-goodfellow2014explaining}{Goodfellow, Shlens, and
Szegedy 2015}).

We run experiments with three gradient-based generators: \emph{Generic}
of Wachter, Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}) as a simple baseline
approach, \emph{REVISE} (\citeproc{ref-joshi2019realistic}{Joshi et al.
2019}) that aims to generate plausible counterfactuals using a surrogate
Variational Autoencoder (VAE), and \emph{ECCCo}
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}), which
targets faithfulness.

We make use of nine classification datasets common in the CE/AR
literature. Four of them are synthetic with two classes and different
characteristics: linearly separable clusters (\emph{LS}), overlapping
clusters (\emph{OL}), concentric circles (\emph{Circ}), and interlocking
moons (\emph{Moon}). Next, we have four real-world binary tabular
datasets: \emph{Adult} (Census data) of Becker and Kohavi
(\citeproc{ref-becker1996adult2}{1996}), California housing (\emph{CH})
of Pace and Barry (\citeproc{ref-pace1997sparse}{1997}), Default of
Credit Card Clients (\emph{Cred}) of Yeh
(\citeproc{ref-yeh2016default}{2016}), and Give Me Some Credit
(\emph{GMSC}) from Kaggle (\citeproc{ref-kaggle2011give}{2011}).
Finally, for the convenience of illustration, we use the 10-class
\emph{MNIST} (\citeproc{ref-lecun1998mnist}{LeCun 1998}).

To assess CT, we investigate the improvements in performance metrics
when using it on top of a weak baseline (BL): a multilayer perceptron
(\emph{MLP}). This is the best way to get a clear picture of the
effectiveness of CT, and it is consistent with evaluation practices in
the related literature
(\citeproc{ref-goodfellow2014explaining}{Goodfellow, Shlens, and Szegedy
2015}; \citeproc{ref-ross2021learning}{Ross, Lakkaraju, and Bastani
2024}; \citeproc{ref-teney2020learning}{Teney, Abbasnedjad, and Hengel
2020}).

\subsection{Experimental Results}\label{experimental-results}

Our main results for plausibility and actionability for \emph{MLP}
models are summarised in Table~\ref{tbl-main} that presents
counterfactual outcomes grouped by dataset along with standard errors
averaged across bootstrap samples. Asterisks (\(^*\)) are used when the
bootstrapped 99\%-confidence interval of differences in mean outcomes
does \emph{not} include zero, so the observed effects are statistically
significant at the 0.01 level.

The first two columns (\(\text{IP}\) and \(\text{IP}^*\)) show the
percentage reduction in implausibility for our two metrics when using CT
on top of the weak baseline. As an example, consider the first row for
\emph{LS} data: the observed positive values indicate that faithful
counterfactuals are around 30-55\% more plausible for models trained
with CT, in line with our observations in panel (b) of
Figure~\ref{fig-poc} compared to panel (a).

The third column shows the results for a scenario when mutability
constraints are imposed on the selected features. Again, we are
comparing CT to the baseline, so reductions in the positive direction
imply that valid counterfactuals are ``cheaper'' (more actionable) when
using CT with feature protection. Relating this back to
Figure~\ref{fig-poc}, the third column represents the reduction in
distances travelled by counterfactuals in panel (d) compared to panel
(c). In the following paragraphs, we summarize the results for all
datasets.

\begin{table}

\caption{\label{tbl-main}Key evaluation metrics for valid counterfactual
along with bootstrapped standard errors for all datasets.
\textbf{Plausibility} (columns 1-2): percentage reduction in
implausibility for \(\text{IP}\) and \(\text{IP}^*\), respectively;
\textbf{Cost} / \textbf{Actionability} (column 3): percentage reduction
in costs when selected features are protected. Outcomes are aggregated
across bootstrap samples (100 rounds) and varying degrees of the energy
penalty \(\lambda_{\text{egy}}\) used for \emph{ECCCo} at test time.
Asterisks (\(^*\)) indicate that the bootstrapped 99\%-confidence
interval of differences in mean outcomes does \emph{not} include zero.}

\centering{

\small
\centering
\begin{tabular}{
  l
  S[table-format=2.2(1.2)]
  S[table-format=3.2(3.2)]
  S[table-format=3.2(1.2)]
}
  \toprule
  \textbf{Data} & \textbf{$ \text{IP} $ $(-\%)$} & \textbf{$ \text{IP}^* $ $(-\%)$} & \textbf{Cost $(-\%)$} \\\midrule
  LS & 29.05\pm0.67 $^{*}$ & 55.33\pm2.03 $^{*}$ & 14.07\pm0.6 $^{*}$ \\
  Circ & 56.29\pm0.44 $^{*}$ & 89.38\pm9.3 $^{*}$ & 45.55\pm0.76 $^{*}$ \\
  Moon & 20.62\pm0.69 $^{*}$ & 19.26\pm8.12 $^{*}$ & 2.86\pm1.03 $^{*}$ \\
  OL & -1.13\pm0.88 $^{}$ & -24.52\pm14.52 $^{}$ & 38.39\pm2.21 $^{*}$ \\\midrule
  Adult & 0.77\pm1.34 $^{}$ & 32.29\pm6.87 $^{*}$ & -2.82\pm4.88 $^{}$ \\
  CH & 12.05\pm1.41 $^{*}$ & 70.27\pm3.72 $^{*}$ & 40.71\pm1.55 $^{*}$ \\
  Cred & 12.31\pm1.84 $^{*}$ & 54.89\pm11.21 $^{*}$ & -17.43\pm5.17 $^{*}$ \\
  GMSC & 23.44\pm1.99 $^{*}$ & 73.31\pm4.83 $^{*}$ & 62.64\pm2.04 $^{*}$ \\
  MNIST & 7.05\pm1.8 $^{*}$ & -25.09\pm109.05 $^{}$ & -12.34\pm6.52 $^{}$ \\\midrule
  Avg. & 17.83 & 38.35 & 19.07 \\\bottomrule
\end{tabular}

}

\end{table}%

\subsubsection{Plausibility (RQ1).}\label{sec-plaus}

\emph{CT generally produces substantial and statistically significant
improvements in plausibility.}

Average reductions in \(\text{IP}\) range from around 7\% for
\emph{MNIST} to almost 60\% for \emph{Circ}. For the real-world tabular
datasets they are around 12\% for \emph{CH} and \emph{Cred} and almost
25\% for \emph{GMSC}; for \emph{Adult} and \emph{OL} we find no
significant impact of CT on \(\text{IP}\). Reductions in \(\text{IP}^*\)
are even more substantial and generally statistically significant,
although the average degree of uncertainty is higher than for
\(\text{IP}\): reductions range from around 20\% (\emph{Moons}) to
almost 90\% (\emph{Circ}). The only negative findings are for OL and
MNIST, but they are not statistically significant. A qualitative
inspection of the counterfactuals in Figure~\ref{fig-mnist} (columns
2-5) suggests recognizable digits 1-4 for the model trained with CT
(bottom row), unlike the baseline (top row).

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{../../paper/figures/mnist_body.png}}

}

\caption{\label{fig-mnist}Visual explanations for \emph{MNIST} for BL
(top) and CT (bottom). \textbf{Plausibility}: col.~1 is a random factual
0 (blue); cols. 2-5 are corresponding \emph{ECCCo} counterfactuals in
target classes 1 to 4. \textbf{Actionability}: cols. 6-10 show
integrated gradients averaged over test images in classes 5 to 9.}

\end{figure}%

\subsubsection{Actionability (RQ2).}\label{sec-act}

\emph{CT tends to improve actionability in the presence of immutable
features, but this is not guaranteed if the assumptions in Proposition
\ref{prp-mtblty} are violated.}

For synthetic datasets, we always protect the first feature; for all
real-world tabular datasets we could identify and protect an \emph{age}
variable; for \emph{MNIST}, we protect the five upper and lower pixel
rows of the full image. Statistically significant reductions in costs
overwhelmingly point in the expected positive direction reaching up to
around 60\% for \emph{GMSC}. Only in the case of \emph{Cred}, average
costs increase, likely because any potential benefits from protecting
the \emph{age} are outweighed by the increase in costs required for
greater plausibility. The findings for \emph{Adult} and \emph{MNIST} are
not significant. A qualitative inspection of the class-conditional
integrated gradients in Figure~\ref{fig-mnist} (columns 6-10) suggests
that CT still has the expected effect: the model (bottom) is insensitive
(blue) to the protected rows of pixels; details of this experiment are
reported in the supplementary appendix.

\begin{figure*}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{../../paper/figures/acc.png}}

}

\caption{\label{fig-acc}Test accuracies on adversarially perturbed data
with varying perturbation sizes for all non-synthetic datasets.}

\end{figure*}%

\subsubsection{Predictive Performance (RQ3).}\label{sec-pred}

\emph{Models trained with CT are substantially more robust to
gradient-based adversarial attacks than conventionally-trained
baselines.}

Test accuracies on adversarially perturbed data are shown in
Figure~\ref{fig-acc}. The perturbations size, \(\varepsilon\in[0,0.1]\),
increases along the horizontal axis and includes zero, corresponding to
standard test accuracy for non-perturbed data. For all synthetic
datasets, predictive performance of CT is virtually identical to the
baseline and unaffected by perturbations. For all real-world datasets,
we find that CT substantially improves robustness: while in some cases
baseline accuracies drop to essentially zero for large enough
perturbation sizes, accuracies of CT models remain remarkably robust.

\subsubsection{Hyperparameter settings
(RQ4).}\label{sec-hyperparameters}

\emph{CT is highly sensitive to the choice of a CE generator and its
hyperparameters but (1) we observe manageable patterns, and (2) we can
usually identify settings that improve either plausibility or
actionability, and typically both of them at the same time.}

We evaluate the impacts of three types of hyperparameters on CT. In this
section we focus on the highlights and make the full results available
in the supplementary appendix.

Firstly, we find that optimal results are generally obtained when using
\emph{ECCCo} to generate counterfactuals. Conversely, using a generator
that may inhibit faithfulness (\emph{REVISE}), tends to yield poor
results. Concerning hyperparameters that guide the gradient-based
counterfactual search, we find that increasing \(T\), the maximum number
of steps, generally yields better outcomes because more CEs can mature.
Relatedly, we also find that the effectiveness and stability of CT is
positively associated with the total number of counterfactuals generated
during each training epoch. The impact of \(\tau\), the decision
threshold, is more difficult to predict. On ``harder'' datasets it may
be difficult to satisfy high \(\tau\) for any given sample (i.e., also
factuals) and so increasing this threshold does not seem to correlate
with better outcomes. In fact, \(\tau=0.5\) generally leads to optimal
results as it is associated with high proportions of mature
counterfactuals.

Secondly, the strength of the energy regularization,
\(\lambda_{\text{reg}}\) is highly impactful and should be set
sufficiently high to avoid common problems associated with exploding
gradients. The sensitivity with respect to \(\lambda_{\text{div}}\) and
\(\lambda_{\text{adv}}\) is much less evident. While high values of
\(\lambda_{\text{reg}}\) may increase the variability in outcomes when
combined with high values of \(\lambda_{\text{div}}\) or
\(\lambda_{\text{adv}}\), this effect is not particularly pronounced.

Finally, we also observe desired improvements when CT was combined with
conventional training and applied only for the final 50\% of epochs of
the complete training process. Put differently, CT can improve the
explainability of models in a post-hoc, fine-tuning manner.

\section{Discussion}\label{sec-discussion}

As our results indicate, counterfactual training produces models that
are more explainable. Nonetheless, these advantages come at the cost of
two important limitations.

\emph{Interventions on features have implications for fairness.} We
provide a method to modify the sensitivity of a model to certain
features, which can be misused by enforcing explanations based on
features that are more difficult to modify by a (group of) decision
subjects. Such abuse could result in an unfairly assigned burden of
recourse (\citeproc{ref-sharma2020certifai}{Sharma, Henderson, and Ghosh
2020}), threatening the equality of opportunity
(\citeproc{ref-bell2024fairness}{Bell et al. 2024}). Also, even if all
immutable features are protected, there may exist proxies that are
theoretically mutable, but preserve sufficient information about the
principals to hinder these protections. Indeed, deciding on the
actionability of features remains a major open challenge in the AR
literature
(\citeproc{ref-venkatasubramanian2020philosophical}{Venkatasubramanian
and Alfano 2020}).

\emph{Plausibility is costly.} As noted by Altmeyer et al.
(\citeproc{ref-altmeyer2024faithful}{2024}), more plausible
counterfactuals are inevitably more costly. CT improves plausibility and
robustness, but it can impact average costs and validity when cheap,
implausible and adversarial explanations are removed from the solution
space.

\emph{CT increases the training times.} Just like contrastive and robust
learning, CT is more resource-intensive than conventional regimes. Three
factors mitigate this effect: (1) CT yields itself to parallel
execution; (2) it amortizes the cost of CEs for the training samples;
and (3) it can be used to fine-tune conventionally-trained models.

We also highlight three key directions for future research. Firstly, it
is an interesting challenge to extend CT beyond classification settings.
Our formulation relies on the distinction between non-target class(es)
and target class(es), requiring the output space to be discrete. Thus,
it does not apply to ML tasks where the change in outcome cannot be
readily discretized. Focus on classification is a common choice in
research on CEs and AR; other settings have attracted some interest,
e.g., regression (\citeproc{ref-spooner2021counterfactual}{Spooner et
al. 2021}), but there is little consensus how to robustly extend the
notion of CEs.

Secondly, our analysis covers CE generators with different
characteristics, but it is interesting to extend it to more algorithms,
including ones that do not rely on computationally costly gradient-based
optimization. This should reduce training costs while possibly
preserving the benefits of CT.

Finally, we believe that it is possible to considerably improve
hyperparameter selection procedures, and thus performance. We have
relied exclusively on grid searches, but future work could benefit from
more sophisticated approaches.

\section{Conclusion}\label{sec-conclusion}

State-of-the-art machine learning models are prone to learning complex
representations that cannot be interpreted by humans. Existing
explainability solutions cannot guarantee that explanations agree with
these learned representation. As a step towards addressing this
challenge, we introduce counterfactual training, a novel training regime
that integrates recent advances in contrastive learning, adversarial
robustness, and counterfactual explanations to incentivize
highly-explainable models. Through extensive experiments, we demonstrate
that CT satisfies this goal while preserving the predictive performance
and promoting robustness of models. Explanations generated from CT-based
models are both more plausible (compliant with the underlying
data-generating process) and more actionable (compliant with
user-specified mutability constraints), and thus meaningful to their
recipients. In turn, our work highlights the value of simultaneously
improving models and their explanations.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-abbasnejad2020counterfactual}
Abbasnejad, Ehsan, Damien Teney, Amin Parvaneh, Javen Shi, and Anton van
den Hengel. 2020. {``{Counterfactual Vision and Language Learning}.''}
In \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)}, 10041--51.
\url{https://doi.org/10.1109/CVPR42600.2020.01006}.

\bibitem[\citeproctext]{ref-altmeyer2023explaining}
Altmeyer, Patrick, Arie van Deursen, and Cynthia C. S. Liem. 2023.
{``{Explaining Black-Box Models through Counterfactuals}.''} In
\emph{Proceedings of the JuliaCon Conferences}, 1:130.

\bibitem[\citeproctext]{ref-altmeyer2024faithful}
Altmeyer, Patrick, Mojtaba Farmanbar, Arie van Deursen, and Cynthia C.
S. Liem. 2024. {``{Faithful Model Explanations through
Energy-Constrained Conformal Counterfactuals}.''} In \emph{Proceedings
of the Thirty-Eighth AAAI Conference on Artificial Intelligence},
38:10829--37. 10. \url{https://doi.org/10.1609/aaai.v38i10.28956}.

\bibitem[\citeproctext]{ref-augustin2020adversarial}
Augustin, Maximilian, Alexander Meinke, and Matthias Hein. 2020.
{``{Adversarial Robustness on In- and Out-Distribution Improves
Explainability}.''} In \emph{Computer Vision -- ECCV 2020}, edited by
Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm,
228--45. Cham: Springer.

\bibitem[\citeproctext]{ref-balashankar2023improving}
Balashankar, Ananth, Xuezhi Wang, Yao Qin, Ben Packer, Nithum Thain, Ed
Chi, Jilin Chen, and Alex Beutel. 2023. {``{Improving Classifier
Robustness through Active Generative Counterfactual Data
Augmentation}.''} In \emph{Findings of the Association for Computational
Linguistics: EMNLP 2023}, 127--39. ACL.
\url{https://doi.org/10.18653/v1/2023.findings-emnlp.10}.

\bibitem[\citeproctext]{ref-becker1996adult2}
Becker, Barry, and Ronny Kohavi. 1996. {``{Adult}.''} UCI Machine
Learning Repository.

\bibitem[\citeproctext]{ref-bell2024fairness}
Bell, Andrew, Joao Fonseca, Carlo Abrate, Francesco Bonchi, and Julia
Stoyanovich. 2024. {``{Fairness in Algorithmic Recourse Through the Lens
of Substantive Equality of Opportunity}.''}
\url{https://arxiv.org/abs/2401.16088}.

\bibitem[\citeproctext]{ref-bezanson2017julia}
Bezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017.
{``Julia: A Fresh Approach to Numerical Computing.''} \emph{SIAM Review}
59 (1): 65--98. \url{https://doi.org/10.1137/141000671}.

\bibitem[\citeproctext]{ref-milan2023dataframes}
Bouchet-Valat, Milan, and Bogumi Kamiski. 2023. {``DataFrames.jl:
Flexible and Fast Tabular Data in Julia.''} \emph{Journal of Statistical
Software} 107 (4): 1--32. \url{https://doi.org/10.18637/jss.v107.i04}.

\bibitem[\citeproctext]{ref-byrne2021mpi}
Byrne, Simon, Lucas C. Wilcox, and Valentin Churavy. 2021. {``MPI.jl:
Julia Bindings for the Message Passing Interface.''} \emph{Proceedings
of the JuliaCon Conferences} 1 (1): 68.
\url{https://doi.org/10.21105/jcon.00068}.

\bibitem[\citeproctext]{ref-chagas2024pretty}
Chagas, Ronan Arraes Jardim, Ben Baumgold, Glen Hertz, Hendrik Ranocha,
Mark Wells, Nathan Boyer, Nicholas Ritchie, et al. 2024.
{``Ronisbr/PrettyTables.jl: V2.4.0.''} Zenodo.
\url{https://doi.org/10.5281/zenodo.13835553}.

\bibitem[\citeproctext]{ref-PlotsJL}
Christ, Simon, Daniel Schwabeneder, Christopher Rackauckas, Michael
Krabbe Borregaard, and Thomas Breloff. 2023. {``Plots.jl -- a User
Extendable Plotting API for the Julia Programming Language.''}
https://doi.org/\url{https://doi.org/10.5334/jors.431}.

\bibitem[\citeproctext]{ref-danisch2021makie}
Danisch, Simon, and Julius Krumbiegel. 2021. {``{Makie.jl}: Flexible
High-Performance Data Visualization for {Julia}.''} \emph{Journal of
Open Source Software} 6 (65): 3349.
\url{https://doi.org/10.21105/joss.03349}.

\bibitem[\citeproctext]{ref-du2019implicit}
Du, Yilun, and Igor Mordatch. 2020. {``{Implicit Generation and
Generalization in Energy-Based Models}.''}
\url{https://arxiv.org/abs/1903.08689}.

\bibitem[\citeproctext]{ref-freiesleben2022intriguing}
Freiesleben, Timo. 2022. {``{The Intriguing Relation Between
Counterfactual Explanations and Adversarial Examples}.''} \emph{Minds
and Machines} 32 (1): 77--109.

\bibitem[\citeproctext]{ref-goodfellow2016deep}
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. \emph{Deep
{Learning}}. {MIT Press}.

\bibitem[\citeproctext]{ref-goodfellow2014explaining}
Goodfellow, Ian, Jonathon Shlens, and Christian Szegedy. 2015.
{``{Explaining and Harnessing Adversarial Examples}.''}
\url{https://arxiv.org/abs/1412.6572}.

\bibitem[\citeproctext]{ref-grathwohl2020your}
Grathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud,
Mohammad Norouzi, and Kevin Swersky. 2020. {``Your Classifier Is
Secretly an Energy Based Model and You Should Treat It Like One.''} In
\emph{International Conference on Learning Representations}.

\bibitem[\citeproctext]{ref-gretton2012kernel}
Gretton, Arthur, Karsten M Borgwardt, Malte J Rasch, Bernhard Schlkopf,
and Alexander Smola. 2012. {``A Kernel Two-Sample Test.''} \emph{The
Journal of Machine Learning Research} 13 (1): 723--73.

\bibitem[\citeproctext]{ref-guo2023counternet}
Guo, Hangzhi, Thanh H. Nguyen, and Amulya Yadav. 2023. {``{CounterNet:
End-to-End Training of Prediction Aware Counterfactual Explanations}.''}
In \emph{Proceedings of the 29th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining}, 577-\/-589. KDD '23. New York, NY, USA:
Association for Computing Machinery.
\url{https://doi.org/10.1145/3580305.3599290}.

\bibitem[\citeproctext]{ref-hastie2009elements}
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. \emph{The
Elements of Statistical Learning}. Springer New York.
\url{https://doi.org/10.1007/978-0-387-84858-7}.

\bibitem[\citeproctext]{ref-innes2018fashionable}
Innes, Michael, Elliot Saba, Keno Fischer, Dhairya Gandhi, Marco
Concetto Rudilosso, Neethu Mariya Joy, Tejan Karmali, Avik Pal, and
Viral Shah. 2018. {``Fashionable Modelling with Flux.''}
\url{https://arxiv.org/abs/1811.01457}.

\bibitem[\citeproctext]{ref-innes2018flux}
Innes, Mike. 2018. {``Flux: {Elegant} Machine Learning with {Julia}.''}
\emph{Journal of Open Source Software} 3 (25): 602.
\url{https://doi.org/10.21105/joss.00602}.

\bibitem[\citeproctext]{ref-joshi2019realistic}
Joshi, Shalmali, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and
Joydeep Ghosh. 2019. {``{Towards Realistic Individual Recourse and
Actionable Explanations in Black-Box Decision Making Systems}.''}
\url{https://arxiv.org/abs/1907.09615}.

\bibitem[\citeproctext]{ref-kaggle2011give}
Kaggle. 2011. {``Give Me Some Credit, {Improve} on the State of the Art
in Credit Scoring by Predicting the Probability That Somebody Will
Experience Financial Distress in the Next Two Years.''}
https://www.kaggle.com/c/GiveMeSomeCredit; {Kaggle}.
\url{https://www.kaggle.com/c/GiveMeSomeCredit}.

\bibitem[\citeproctext]{ref-karimi2020survey}
Karimi, Amir-Hossein, Gilles Barthe, Bernhard Schlkopf, and Isabel
Valera. 2021. {``A Survey of Algorithmic Recourse: Definitions,
Formulations, Solutions, and Prospects.''}
\url{https://arxiv.org/abs/2010.04050}.

\bibitem[\citeproctext]{ref-lakshminarayanan2016simple}
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017.
{``Simple and Scalable Predictive Uncertainty Estimation Using Deep
Ensembles.''} In \emph{Proceedings of the 31st International Conference
on Neural Information Processing Systems}, 6405--16. NIPS'17. Red Hook,
NY, USA: Curran Associates Inc.

\bibitem[\citeproctext]{ref-lecun1998mnist}
LeCun, Yann. 1998. {``{The MNIST database of handwritten digits}.''}
http://yann.lecun.com/exdb/mnist/.

\bibitem[\citeproctext]{ref-lippe2024uvadlc}
Lippe, Phillip. 2024. {``{UvA Deep Learning Tutorials}.''}
\url{https://uvadlc-notebooks.readthedocs.io/en/latest/}.

\bibitem[\citeproctext]{ref-luu2023counterfactual}
Luu, Hoai Linh, and Naoya Inoue. 2023. {``{Counterfactual Adversarial
Training for Improving Robustness of Pre-trained Language Models}.''} In
\emph{Proceedings of the 37th Pacific Asia Conference on Language,
Information and Computation}, 881--88. ACL.
\url{https://aclanthology.org/2023.paclic-1.88/}.

\bibitem[\citeproctext]{ref-molnar2022interpretable}
Molnar, Christoph. 2022. \emph{Interpretable Machine Learning: A Guide
for Making Black Box Models Explainable}. 2nd ed.
\url{https://christophm.github.io/interpretable-ml-book}.

\bibitem[\citeproctext]{ref-murphy2022probabilistic}
Murphy, Kevin P. 2022. \emph{Probabilistic {Machine Learning}: {An}
Introduction}. {MIT Press}.

\bibitem[\citeproctext]{ref-pace1997sparse}
Pace, R Kelley, and Ronald Barry. 1997. {``Sparse Spatial
Autoregressions.''} \emph{Statistics \& Probability Letters} 33 (3):
291--97. \url{https://doi.org/10.1016/s0167-7152(96)00140-x}.

\bibitem[\citeproctext]{ref-pawelczyk2022exploring}
Pawelczyk, Martin, Chirag Agarwal, Shalmali Joshi, Sohini Upadhyay, and
Himabindu Lakkaraju. 2022. {``Exploring Counterfactual Explanations
Through the Lens of Adversarial Examples: A Theoretical and Empirical
Analysis.''} In \emph{Proceedings of the 25th International Conference
on Artificial Intelligence and Statistics}, edited by Gustau
Camps-Valls, Francisco J. R. Ruiz, and Isabel Valera, 151:4574--94.
Proceedings of Machine Learning Research. PMLR.
\url{https://proceedings.mlr.press/v151/pawelczyk22a.html}.

\bibitem[\citeproctext]{ref-ross2021learning}
Ross, Alexis, Himabindu Lakkaraju, and Osbert Bastani. 2024.
{``{Learning Models for Actionable Recourse}.''} In \emph{Proceedings of
the 35th International Conference on Neural Information Processing
Systems}. NIPS '21. Red Hook, NY, USA: Curran Associates Inc.

\bibitem[\citeproctext]{ref-sauer2021counterfactual}
Sauer, Axel, and Andreas Geiger. 2021. {``{Counterfactual Generative
Networks}.''} \url{https://arxiv.org/abs/2101.06046}.

\bibitem[\citeproctext]{ref-schut2021generating}
Schut, Lisa, Oscar Key, Rory McGrath, Luca Costabello, Bogdan Sacaleanu,
Yarin Gal, et al. 2021. {``Generating {Interpretable Counterfactual
Explanations By Implicit Minimisation} of {Epistemic} and {Aleatoric
Uncertainties}.''} In \emph{International {Conference} on {Artificial
Intelligence} and {Statistics}}, 1756--64. {PMLR}.

\bibitem[\citeproctext]{ref-sharma2020certifai}
Sharma, Shubham, Jette Henderson, and Joydeep Ghosh. 2020. {``{CERTIFAI:
A Common Framework to Provide Explanations and Analyse the Fairness and
Robustness of Black-box Models}.''} In \emph{Proceedings of the AAAI/ACM
Conference on AI, Ethics, and Society}, 166--72. AIES '20. New York, NY,
USA: Association for Computing Machinery.
\url{https://doi.org/10.1145/3375627.3375812}.

\bibitem[\citeproctext]{ref-spooner2021counterfactual}
Spooner, Thomas, Danial Dervovic, Jason Long, Jon Shepard, Jiahao Chen,
and Daniele Magazzeni. 2021. {``{Counterfactual Explanations for
Arbitrary Regression Models}.''} \url{https://arxiv.org/abs/2106.15212}.

\bibitem[\citeproctext]{ref-sundararajan2017ig}
Sundararajan, Mukund, Ankur Taly, and Qiqi Yan. 2017. {``Axiomatic
Attribution for Deep Networks.''}
\url{https://arxiv.org/abs/1703.01365}.

\bibitem[\citeproctext]{ref-szegedy2013intriguing}
Szegedy, Christian, Wojciech Zaremba, Ilya Sutskever, Joan Bruna,
Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2014. {``Intriguing
Properties of Neural Networks.''} \url{https://arxiv.org/abs/1312.6199}.

\bibitem[\citeproctext]{ref-teh2003energy}
Teh, Yee Whye, Max Welling, Simon Osindero, and Geoffrey E. Hinton.
2003. {``Energy-Based Models for Sparse Overcomplete Representations.''}
\emph{J. Mach. Learn. Res.} 4 (null): 1235--60.

\bibitem[\citeproctext]{ref-teney2020learning}
Teney, Damien, Ehsan Abbasnedjad, and Anton van den Hengel. 2020.
{``Learning What Makes a Difference from Counterfactual Examples and
Gradient Supervision.''} In \emph{Computer Vision - ECCV 2020}, 580--99.
Berlin, Heidelberg: Springer-Verlag.
\url{https://doi.org/10.1007/978-3-030-58607-2_34}.

\bibitem[\citeproctext]{ref-ustun2019actionable}
Ustun, Berk, Alexander Spangher, and Yang Liu. 2019. {``Actionable
Recourse in Linear Classification.''} In \emph{Proceedings of the
{Conference} on {Fairness}, {Accountability}, and {Transparency}},
10--19. \url{https://doi.org/10.1145/3287560.3287566}.

\bibitem[\citeproctext]{ref-venkatasubramanian2020philosophical}
Venkatasubramanian, Suresh, and Mark Alfano. 2020. {``The Philosophical
Basis of Algorithmic Recourse.''} In \emph{Proceedings of the 2020
Conference on Fairness, Accountability, and Transparency}, 284--93. FAT*
'20. New York, NY, USA: Association for Computing Machinery.
\url{https://doi.org/10.1145/3351095.3372876}.

\bibitem[\citeproctext]{ref-verma2020counterfactual}
Verma, Sahil, Varich Boonsanong, Minh Hoang, Keegan E. Hines, John P.
Dickerson, and Chirag Shah. 2022. {``Counterfactual Explanations and
Algorithmic Recourses for Machine Learning: A Review.''}
\url{https://arxiv.org/abs/2010.10596}.

\bibitem[\citeproctext]{ref-wachter2017counterfactual}
Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017.
{``Counterfactual Explanations Without Opening the Black Box:
{Automated} Decisions and the {GDPR}.''} \emph{Harv. JL \& Tech.} 31:
841. \url{https://doi.org/10.2139/ssrn.3063289}.

\bibitem[\citeproctext]{ref-wilson2020case}
Wilson, Andrew Gordon. 2020. {``{The Case for Bayesian Deep
Learning}.''} \url{https://arxiv.org/abs/2001.10995}.

\bibitem[\citeproctext]{ref-wu2021polyjuice}
Wu, Tongshuang, Marco Tulio Ribeiro, Jeffrey Heer, and Daniel Weld.
2021. {``Polyjuice: Generating Counterfactuals for Explaining,
Evaluating, and Improving Models.''} In \emph{Proceedings of the 59th
Annual Meeting of the Association for Computational Linguistics and the
11th International Joint Conference on Natural Language Processing
(Volume 1: Long Papers)}, edited by Chengqing Zong, Fei Xia, Wenjie Li,
and Roberto Navigli, 6707--23. Online: ACL.
\url{https://doi.org/10.18653/v1/2021.acl-long.523}.

\bibitem[\citeproctext]{ref-yeh2016default}
Yeh, I-Cheng. 2016. {``{Default of Credit Card Clients}.''} UCI Machine
Learning Repository.

\end{CSLReferences}

\newpage{}

\begin{appendices}

\section{Notation}\label{notation}

Below we provide an overview of some notation used frequently throughout
the paper:

\begin{itemize}
\tightlist
\item
  \(y^+\): The target class and also the index of the target class.
\item
  \(y^-\): The non-target class and also the index of non-the target
  class.
\item
  \(\mathbf{x}\): a single training sample.
\item
  \(\mathbf{x}^\prime\): a counterfactual.
\item
  \(\mathbf{x}^+\): a training sample in the target class
  (ground-truth).
\item
  \(\mathbf{y}^+\): The one-hot encoded output vector for the target
  class.
\item
  \(\theta\): Model parameters (unspecified).
\item
  \(\Theta\): Matrix of parameters.
\item
  \(\mathbf{M}(\cdot)\): linear predictions (logits) of the classifier.
\end{itemize}

\subsection{Other Technical Details}\label{other-technical-details}

Maximum mean discrepancy is defined as follows,

\begin{equation}\phantomsection\label{eq-mmd}{
\begin{aligned}
\text{MMD}({X}^\prime,\tilde{X}^\prime) &= \frac{1}{m(m-1)}\sum_{i=1}^m\sum_{j\neq i}^m k(x_i,x_j) \\ &+ \frac{1}{n(n-1)}\sum_{i=1}^n\sum_{j\neq i}^n k(\tilde{x}_i,\tilde{x}_j) \\ &- \frac{2}{mn}\sum_{i=1}^m\sum_{j=1}^n k(x_i,\tilde{x}_j)
\end{aligned}
}\end{equation}

where \(k(\cdot,\cdot)\) is a kernel function
(\citeproc{ref-gretton2012kernel}{Gretton et al. 2012}). We make use of
a Gaussian kernel with a constant length-scale parameter of \(0.5\). In
our implementation, Equation~\ref{eq-mmd} is by default applied to the
entire subset of the training data for which \(y=y^+\).

\section{Technical Details of Our
Approach}\label{technical-details-of-our-approach}

\subsection{Generating Counterfactuals through Gradient
Descent}\label{sec-app-ce}

In this section, we provide some background on gradient-based
counterfactual generators (Section~\ref{sec-app-ce-background}) and
discuss how we define convergence in this context
(Section~\ref{sec-app-conv}).

\subsubsection{Background}\label{sec-app-ce-background}

Gradient-based counterfactual search was originally proposed by Wachter,
Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}). It generally solves
the following unconstrained objective,

\[
\begin{aligned}
\min_{\mathbf{z}^\prime \in \mathcal{Z}^L} \left\{  {\text{yloss}(\mathbf{M}_{\theta}(g(\mathbf{z}^\prime)),\mathbf{y}^+)}+ \lambda {\text{cost}(g(\mathbf{z}^\prime)) }  \right\} 
\end{aligned} 
\]

where \(g: \mathcal{Z} \mapsto \mathcal{X}\) is an invertible function
that maps from the \(L\)-dimensional counterfactual state space to the
feature space and \(\text{cost}(\cdot)\) denotes one or more penalties
that are used to induce certain properties of the counterfactual
outcome. As above, \(\mathbf{y}^+\) denotes the target output and
\(\mathbf{M}_{\theta}(\mathbf{x})\) returns the logit predictions of the
underlying classifier for \(\mathbf{x}=g(\mathbf{z})\).

For all generators used in this work we use standard logit crossentropy
loss for \(\text{yloss}(\cdot)\). All generators also penalize the
distance (\(\ell_1\)-norm) of counterfactuals from their original
factual state. For \emph{Generic} and \emph{ECCo}, we have
\(\mathcal{Z}:=\mathcal{X}\) and
\(g(\mathbf{z})=g(\mathbf{z})^{-1}=\mathbf{z}\), that is counterfactual
are searched directly in the feature space. Conversely, \emph{REVISE}
traverses the latent space of a variational autoencoder (VAE) fitted to
the training data, where \(g(\cdot)\) corresponds to the decoder
(\citeproc{ref-joshi2019realistic}{Joshi et al. 2019}). In addition to
the distance penalty, \emph{ECCo} uses an additional penalty component
that regularizes the energy associated with the counterfactual,
\(\mathbf{x}^\prime\) (\citeproc{ref-altmeyer2024faithful}{Altmeyer et
al. 2024}).

\subsubsection{Convergence}\label{sec-app-conv}

An important consideration when generating counterfactual explanations
using gradient-based methods is how to define convergence. Two common
choices are to 1) perform gradient descent over a fixed number of
iterations \(T\), or 2) conclude the search as soon as the predicted
probability for the target class has reached a pre-determined threshold,
\(\tau\):
\(\mathcal{S}(\mathbf{M}_\theta(\mathbf{x}^\prime))[y^+] \geq \tau\). We
prefer the latter for our purposes, because it explicitly defines
convergence in terms of the black-box model, \(\mathbf{M}(\mathbf{x})\).

Defining convergence in this way allows for a more intuitive
interpretation of the resulting counterfactual outcomes than with fixed
\(T\). Specifically, it allows us to think of counterfactuals as
explaining `high-confidence' predictions by the model for the target
class \(y^+\). Depending on the context and application, different
choices of \(\tau\) can be considered as representing `high-confidence'
predictions.

\subsection{Protecting Mutability Constraints with Linear
Classifiers}\label{sec-app-constraints}

In Section~\ref{sec-constraints} we explain that to avoid penalizing
implausibility that arises due to mutability constraints, we impose a
point mass prior on \(p(\mathbf{x})\) for the corresponding feature. We
argue in Section~\ref{sec-constraints} that this approach induces models
to be less sensitive to immutable features and demonstrate this
empirically in Section~\ref{sec-experiments}. Below we derive the
analytical results in Prp.\textasciitilde{}\ref{prp-mtblty}.

\begin{proof}
Let \(d_{\text{mtbl}}\) and \(d_{\text{immtbl}}\) denote some mutable
and immutable feature, respectively. Suppose that
\(\mu_{y^-,d_{\text{immtbl}}} < \mu_{y^+,d_{\text{immtbl}}}\) and
\(\mu_{y^-,d_{\text{mtbl}}} > \mu_{y^+,d_{\text{mtbl}}}\), where
\(\mu_{k,d}\) denotes the conditional sample mean of feature \(d\) in
class \(k\). In words, we assume that the immutable feature tends to
take lower values for samples in the non-target class \(y^-\) than in
the target class \(y^+\). We assume the opposite to hold for the mutable
feature.

Assuming multivariate Gaussian class densities with common diagonal
covariance matrix \(\Sigma_k=\Sigma\) for all \(k \in \mathcal{K}\), we
have for the log likelihood ratio between any two classes
\(k,m \in \mathcal{K}\) (\citeproc{ref-hastie2009elements}{Hastie,
Tibshirani, and Friedman 2009}):

\begin{equation}\phantomsection\label{eq-loglike}{
\log \frac{p(k|\mathbf{x})}{p(m|\mathbf{x})}=\mathbf{x}^\intercal \Sigma^{-1}(\mu_{k}-\mu_{m})  + \text{const}
}\end{equation}

By independence of \(x_1,...,x_D\), the full log-likelihood ratio
decomposes into:

\begin{equation}\phantomsection\label{eq-loglike-decomp}{
\log \frac{p(k|\mathbf{x})}{p(m|\mathbf{x})} = \sum_{d=1}^D \frac{\mu_{k,d}-\mu_{m,d}}{\sigma_{d}^2} x_{d} + \text{const}
}\end{equation}

By the properties of our classifier (\emph{multinomial logistic
regression}), we have:

\begin{equation}\phantomsection\label{eq-multi}{
\log \frac{p(k|\mathbf{x})}{p(m|\mathbf{x})} = \sum_{d=1}^D \left( \theta_{k,d} - \theta_{m,d} \right)x_d + \text{const}
}\end{equation}

where \(\theta_{k,d}=\Theta[k,d]\) denotes the coefficient on feature
\(d\) for class \(k\).

Based on Equation~\ref{eq-loglike-decomp} and Equation~\ref{eq-multi} we
can identify that
\((\mu_{k,d}-\mu_{m,d}) \propto (\theta_{k,d} - \theta_{m,d})\) under
the assumptions we made above. Hence, we have that
\((\theta_{y^-,d_{\text{immtbl}}} - \theta_{y^+,d_{\text{immtbl}}}) < 0\)
and
\((\theta_{y^-,d_{\text{mtbl}}} - \theta_{y^+,d_{\text{mtbl}}}) > 0\)

Let \(\mathbf{x}^\prime\) denote some randomly chosen individual from
class \(y^-\) and let \(y^+ \sim p(y)\) denote the randomly chosen
target class. Then the partial derivative of the contrastive divergence
penalty Equation~\ref{eq-div} with respect to coefficient
\(\theta_{y^+,d}\) is equal to

\begin{equation}\phantomsection\label{eq-grad}{
\frac{\partial}{\partial\theta_{y^+,d}} \left(\text{div}(\mathbf{x}^+,\mathbf{x^\prime},\mathbf{y};\theta)\right) = \frac{\partial}{\partial\theta_{y^+,d}} \left( \left(-\mathbf{M}_\theta(\mathbf{x}^+)[y^+]\right) - \left(-\mathbf{M}_\theta(\mathbf{x}^\prime)[y^+]\right) \right) = x_{d}^\prime - x^+_{d}
}\end{equation}

and equal to zero everywhere else.

Since \((\mu_{y^-,d_{\text{immtbl}}} < \mu_{y^+,d_{\text{immtbl}}})\) we
are more likely to have
\((x_{d_{\text{immtbl}}}^\prime - x^+_{d_{\text{immtbl}}}) < 0\) than
vice versa at initialization. Similarly, we are more likely to have
\((x_{d_{\text{mtbl}}}^\prime - x^+_{d_{\text{mtbl}}}) > 0\) since
\((\mu_{y^-,d_{\text{mtbl}}} > \mu_{y^+,d_{\text{mtbl}}})\).

This implies that if we do not protect feature \(d_{\text{immtbl}}\),
the contrastive divergence penalty will decrease
\(\theta_{y^-,d_{\text{immtbl}}}\) thereby exacerbating the existing
effect
\((\theta_{y^-,d_{\text{immtbl}}} - \theta_{y^+,d_{\text{immtbl}}}) < 0\).
In words, not protecting the immutable feature would have the
undesirable effect of making the classifier more sensitive to this
feature, in that it would be more likely to predict class \(y^-\) as
opposed to \(y^+\) for lower values of \(d_{\text{immtbl}}\).

By the same rationale, the contrastive divergence penalty can generally
be expected to increase \(\theta_{y^-,d_{\text{mtbl}}}\) exacerbating
\((\theta_{y^-,d_{\text{mtbl}}} - \theta_{y^+,d_{\text{mtbl}}}) > 0\).
In words, this has the effect of making the classifier more sensitive to
the mutable feature, in that it would be more likely to predict class
\(y^-\) as opposed to \(y^+\) for higher values of \(d_{\text{mtbl}}\).

Thus, our proposed approach of protecting feature \(d_{\text{immtbl}}\)
has the net affect of decreasing the classifier's sensitivity to the
immutable feature relative to the mutable feature (i.e.~no change in
sensitivity for \(d_{\text{immtbl}}\) relative to increased sensitivity
for \(d_{\text{mtbl}}\)).
\end{proof}

\subsection{Domain Constraints}\label{domain-constraints}

We apply domain constraints on counterfactuals during training and
evaluation. There are at least two good reasons for doing so. Firstly,
within the context of explainability and algorithmic recourse,
real-world attributes are often domain constrained: the \emph{age}
feature, for example, is lower bounded by zero and upper bounded by the
maximum human lifespan. Secondly, domain constraints help mitigate
training instabilities commonly associated with energy-based modelling
(\citeproc{ref-grathwohl2020your}{Grathwohl et al. 2020};
\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}).

For our image datasets, features are pixel values and hence the domain
is constrained by the lower and upper bound of values that pixels can
take depending on how they are scaled (in our case \([-1,1]\)). For all
other features \(d\) in our synthetic and tabular datasets, we
automatically infer domain constraints
\([x_d^{\text{LB}},x_d^{\text{UB}}]\) as follows,

\begin{equation}\phantomsection\label{eq-domain}{
\begin{aligned}
x_d^{\text{LB}} &= \arg\min_{x_d} \{\mu_d - n_{\sigma_d}\sigma_d, \arg \min_{x_d} x_d\} \\
x_d^{\text{UB}} &= \arg\max_{x_d} \{\mu_d + n_{\sigma_d}\sigma_d, \arg \max_{x_d} x_d\} 
\end{aligned}
}\end{equation}

where \(\mu_d\) and \(\sigma_d\) denote the sample mean and standard
deviation of feature \(d\). We set \(n_{\sigma_d}=3\) across the board
but higher values and hence wider bounds may be appropriate depending on
the application.

\subsection{Training Hyperparameters}\label{sec-app-training}

Note~\ref{nte-train-default} presents the default hyperparameters used
during training.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-train-default}: Training Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-train-default} 

\begin{itemize}
\tightlist
\item
  Meta Parameters:

  \begin{itemize}
  \tightlist
  \item
    Generator: \texttt{ecco}
  \item
    Model: \texttt{mlp}
  \end{itemize}
\item
  Model:

  \begin{itemize}
  \tightlist
  \item
    Activation: \texttt{relu}
  \item
    No.~Hidden: \texttt{32}
  \item
    No.~Layers: \texttt{1}
  \end{itemize}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    Burnin: \texttt{0.0}
  \item
    Class Loss: \texttt{logitcrossentropy}
  \item
    Convergence: \texttt{threshold}
  \item
    Generator Parameters:

    \begin{itemize}
    \tightlist
    \item
      Decision Threshold: \texttt{0.75}
    \item
      \(\lambda_{\text{cst}}\): \texttt{0.001}
    \item
      \(\lambda_{\text{egy}}\): \texttt{5.0}
    \item
      Learning Rate: \texttt{0.25}
    \item
      Maximum Iterations: \texttt{30}
    \item
      Optimizer: \texttt{sgd}
    \item
      Type: \texttt{ECCo}
    \end{itemize}
  \item
    \(\lambda_{\text{adv}}\): \texttt{0.25}
  \item
    \(\lambda_{\text{clf}}\): \texttt{1.0}
  \item
    \(\lambda_{\text{div}}\): \texttt{0.5}
  \item
    \(\lambda_{\text{reg}}\): \texttt{0.1}
  \item
    Learning Rate: \texttt{0.001}
  \item
    No.~Counterfactuals: \texttt{1000}
  \item
    No.~Epochs: \texttt{100}
  \item
    Objective: \texttt{full}
  \item
    Optimizer: \texttt{adam}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsection{Evaluation Details}\label{sec-app-eval}

For all of our evaluations, we proceed as follows: for each experiment
setting we generate multiple counterfactuals (``No.~Counterfactuals''),
randomly choosing the factual and target class each time
(Note~\ref{nte-eval-default}). We do this across multiple rounds
(``No.~Runs'') with different random seeds to account for stochasticity
(Note~\ref{nte-eval-default}). This is in line with standard practice in
the related literature on CE. Note~\ref{nte-eval-default} presents the
default hyperparameters used during evaluation. For our final results
presented in the main paper, we rely on held out test sets to sample
factuals (and outputs for our performance metrics). For tuning purposes
we rely on training or validation sets.

\subsubsection{Robust Accuracy}\label{robust-accuracy}

To evaluate robust accuracy (Acc.\(^*\)), we use the Fast Gradient Sign
Method (FGSM) to perturb test samples
(\citeproc{ref-goodfellow2014explaining}{Goodfellow, Shlens, and Szegedy
2015}). For the main results, we have set the perturbation size to
\(\epsilon=0.03\). We have also tested other perturbation sizes, as well
as randomly perturbed data. Although not reported here, we have
consistently found strong outperformance of CT compared to the weak
baseline.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-eval-default}: Evaluation Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-eval-default} 

\begin{itemize}
\tightlist
\item
  Counterfactual Parameters:

  \begin{itemize}
  \tightlist
  \item
    Convergence: \texttt{threshold}
  \item
    Decision Threshold: \texttt{0.95}
  \item
    Generator Parameters:

    \begin{itemize}
    \tightlist
    \item
      Decision Threshold: \texttt{0.75}
    \item
      \(\lambda_{\text{cst}}\): \texttt{0.001}
    \item
      \(\lambda_{\text{egy}}\): \texttt{5.0}
    \item
      Learning Rate: \texttt{0.25}
    \item
      Maximum Iterations: \texttt{30}
    \item
      Optimizer: \texttt{sgd}
    \item
      Type: \texttt{ECCo}
    \end{itemize}
  \item
    Maximum Iterations: \texttt{50}
  \item
    No.~Individuals: \texttt{100}
  \item
    No.~Runs: \texttt{5}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\FloatBarrier

\section{Details on Main Experiments}\label{sec-app-main}

\subsection{Final Hyperparameters}\label{final-hyperparameters}

As discussed Section~\ref{sec-experiments}, CT is sensitive to certain
hyperparameter choices. We study the effect of many hyperparameters
extensively in Section~\ref{sec-app-grid}. For the main results, we tune
a small set of key hyperparameters (Section~\ref{sec-app-tune}). The
final choices for the main results are presented for each data set in
Table~\ref{tbl-final-params} along with training, test and batch sizes.

\begin{table}

\caption{\label{tbl-final-params}Final hyperparameters used for the main
results presented in Section~\ref{sec-experiments}. Any hyperparameter
not shown here is set to its default value
(Note~\ref{nte-train-default}).}

\centering{

\begin{tabular}{cccccccc}
  \toprule
  \textbf{Data} & \textbf{No. Train} & \textbf{No. Test} & \textbf{Batchsize} & \textbf{Domain} & \textbf{Decision Threshold} & \textbf{No. Counterfactuals} & \textbf{$\lambda_{\text{reg}}$} \\\midrule
  LS & 3600 & 600 & 30 & none & 0.5 & 1000 & 0.01 \\
  Circ & 3600 & 600 & 30 & none & 0.5 & 1000 & 0.5 \\
  Moon & 3600 & 600 & 30 & none & 0.9 & 1000 & 0.25 \\
  OL & 3600 & 600 & 30 & none & 0.5 & 1000 & 0.25 \\\midrule
  Adult & 26049 & 5010 & 1000 & none & 0.75 & 5000 & 0.25 \\
  CH & 16504 & 3101 & 1000 & none & 0.5 & 5000 & 0.25 \\
  Cred & 10617 & 1923 & 1000 & none & 0.5 & 5000 & 0.25 \\
  GMSC & 13371 & 2474 & 1000 & none & 0.5 & 5000 & 0.5 \\
  MNIST & 11000 & 2000 & 1000 & (-1.0, 1.0) & 0.5 & 5000 & 0.01 \\
\end{tabular}

}

\end{table}%

\subsection{Final Results}\label{sec-app-final-results}

Plus/minus two standard deviations of bootstrap estimates.

\subsubsection{Robust Performance Plots}\label{robust-performance-plots}

\subsubsection{Confidence Intervals}\label{confidence-intervals}

\begin{table}

\caption{\label{tbl-ci}Mean outcomes for \textbf{CT} and \textbf{BL}
along with bootstrapped confidence intervals (99\%) for difference in
mean outcomes grouped by dataset and evaluation metric. Column
\textbf{LB} and \textbf{UB} show the lower and upper bound of the
intervals, respectively, and computed using the percentile method. The
underlying counterfactual evaluations are the same as the ones used to
produce Table~\ref{tbl-main}.}

\centering{

\begin{tabular}{lccccc}
  \toprule
  \textbf{Variable} & \textbf{Data} & \textbf{CT} & \textbf{BL} & \textbf{LB} & \textbf{UB} \\\midrule
  Cost & Adult & 2.26 & 2.2 & -0.22 & 0.28 \\
  Cost & CH & 1.46 & 2.46 & -1.1 & -0.89 \\
  Cost & Circ & 0.67 & 1.23 & -0.58 & -0.53 \\
  Cost & Cred & 2.68 & 2.29 & 0.16 & 0.63 \\
  Cost & GMSC & 1.14 & 3.05 & -2.45 & -1.77 \\
  Cost & LS & 3.82 & 4.44 & -0.7 & -0.56 \\
  Cost & MNIST & 77.04 & 68.67 & -3.47 & 18.34 \\
  Cost & Moon & 1.55 & 1.6 & -0.08 & -0.01 \\
  Cost & OL & 1.62 & 2.63 & -1.15 & -0.81 \\
  $ \text{IP}^* $ & Adult & 0.07 & 0.11 & -0.06 & -0.01 \\
  $ \text{IP}^* $ & CH & 0.02 & 0.06 & -0.06 & -0.04 \\
  $ \text{IP}^* $ & Circ & 0.0 & 0.0 & -0.01 & -0.0 \\
  $ \text{IP}^* $ & Cred & 0.03 & 0.06 & -0.05 & -0.01 \\
  $ \text{IP}^* $ & GMSC & 0.02 & 0.07 & -0.06 & -0.04 \\
  $ \text{IP}^* $ & LS & 0.1 & 0.23 & -0.14 & -0.12 \\
  $ \text{IP}^* $ & MNIST & 0.04 & 0.04 & -0.1 & 0.09 \\
  $ \text{IP}^* $ & Moon & 0.02 & 0.02 & -0.01 & -0.0 \\
  $ \text{IP}^* $ & OL & 0.12 & 0.09 & -0.01 & 0.05 \\
  $ \text{IP} $ & Adult & 15.03 & 15.15 & -0.68 & 0.26 \\
  $ \text{IP} $ & CH & 6.61 & 7.52 & -1.17 & -0.63 \\
  $ \text{IP} $ & Circ & 1.03 & 2.36 & -1.37 & -1.29 \\
  $ \text{IP} $ & Cred & 19.31 & 22.03 & -3.69 & -1.74 \\
  $ \text{IP} $ & GMSC & 6.19 & 8.09 & -2.4 & -1.49 \\
  $ \text{IP} $ & LS & 2.41 & 3.4 & -1.04 & -0.94 \\
  $ \text{IP} $ & MNIST & 258.83 & 278.54 & -30.49 & -7.64 \\
  $ \text{IP} $ & Moon & 1.36 & 1.71 & -0.38 & -0.32 \\
  $ \text{IP} $ & OL & 4.49 & 4.44 & -0.03 & 0.13 \\\bottomrule
\end{tabular}

}

\end{table}%

\subsubsection{Qualitative Findings for Image
Data}\label{qualitative-findings-for-image-data}

Figure~\ref{fig-mnist} shows much more plausible (faithful)
counterfactuals for a model with CT than the model with conventional
training (Figure~\ref{fig-mnist-vanilla}).

\begin{figure}

\begin{minipage}{0.46\linewidth}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{../../paper/figures/mnist_mlp.png}}

}

\caption{\label{fig-mnist}Counterfactual images for \emph{MLP} with
counterfactual training. Factual images are shown on the diagonal, with
the corresponding counterfactual for each target class (columns) in that
same row. The underlying generator, \emph{ECCo}, aims to generate
counterfactuals that are faithful to the model
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}).}

\end{figure}%

\end{minipage}%
%
\begin{minipage}{0.09\linewidth}
~\end{minipage}%
%
\begin{minipage}{0.46\linewidth}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{../../paper/figures/mnist_mlp_vanilla.png}}

}

\caption{\label{fig-mnist-vanilla}The same setup, factuals, model
architecture and generator as in Figure~\ref{fig-mnist}, but the model
was trained conventionally.}

\end{figure}%

\end{minipage}%

\end{figure}%

\begin{figure}

\begin{minipage}{0.50\linewidth}

\subsubsection{Integrated Gradients}\label{integrated-gradients}

\begin{table}[H]

\caption{\label{tbl-ig}Integrated gradients.}

\centering{

\begin{tabular}{
l
S[table-format=2.2(3.2)]
S[table-format=2.2(2.2)]
}
  \toprule
  \textbf{Data} & \textbf{CT} & \textbf{BL} \\\midrule
  LS & 0.03 \pm 0.0 & 10.24 \pm 2.4 \\
  Circ & 3.2 \pm 0.67 & 149.76 \pm 842.75 \\
  Moon & 60.84 \pm 128.51 & 0.55 \pm 0.06 \\
  OL & 0.78 \pm 0.12 & 4.81 \pm 1.08 \\\midrule
  Adult & 0.43 \pm 0.01 & 1.0 \pm 0.0 \\
  CH & 0.08 \pm 0.01 & 0.23 \pm 0.01 \\
  Cred & 0.0 \pm 0.0 & 0.43 \pm 0.01 \\
  GMSC & 1.0 \pm 0.0 & 0.21 \pm 0.03 \\
  MNIST & 0.18 \pm 0.01 & 0.41 \pm 0.01 \\
\end{tabular}

}

\end{table}%

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{../../paper/figures/mnist_ig.png}}

}

\caption{\label{fig-mnist-ig}Class-conditional integrated gradients.}

\end{figure}%

\end{minipage}%

\end{figure}%

\subsubsection{Costs and Validity}\label{costs-and-validity}

\begin{table}

\caption{\label{tbl-panel}Costs and validity.}

\begin{minipage}{0.33\linewidth}

\subcaption{\label{tbl-costs}Costs}

\centering{

\begin{tabular}{
l
S[table-format=2.2(1.2)]
}
  \toprule
  \textbf{Data} & \textbf{Cost $(-\%)$} \\\midrule
  LS & -26.82\pm0.86 $^{*}$ \\
  Circ & 40.97\pm0.82 $^{*}$ \\
  Moon & 33.83\pm0.98 $^{*}$ \\
  OL & 10.35\pm1.28 $^{*}$ \\\midrule
  Adult & 1.16\pm3.53 $^{}$ \\
  CH & -34.89\pm2.31 $^{*}$ \\
  Cred & 28.24\pm1.08 $^{*}$ \\
  GMSC & 3.54\pm5.78 $^{}$ \\
  MNIST & -31.67\pm7.72 $^{*}$ \\\midrule
  Avg. & 2.75 \\\bottomrule
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\subcaption{\label{tbl-val}Validity}

\centering{

\begin{tabular}{lcc}
  \toprule
  \textbf{Data} & \textbf{CT} & \textbf{BL} \\\midrule
  LS & 1.0 & 1.0 \\
  Circ & 0.97 & 0.52 \\
  Moon & 1.0 & 1.0 \\
  OL & 0.87 & 0.98 \\\midrule
  Adult & 0.61 & 0.99 \\
  CH & 0.96 & 1.0 \\
  Cred & 0.7 & 1.0 \\
  GMSC & 0.63 & 1.0 \\
  MNIST & 1.0 & 1.0 \\
\end{tabular}

}

\end{minipage}%
%
\begin{minipage}{0.33\linewidth}

\subcaption{\label{tbl-val-mtbl}Validity}

\centering{

\begin{tabular}{lcc}
  \toprule
  \textbf{Data} & \textbf{CT} & \textbf{BL} \\\midrule
  LS & 1.0 & 1.0 \\
  Circ & 0.67 & 0.49 \\
  Moon & 0.99 & 0.98 \\
  OL & 0.37 & 0.57 \\\midrule
  Adult & 0.56 & 0.99 \\
  CH & 0.96 & 1.0 \\
  Cred & 0.67 & 1.0 \\
  GMSC & 0.38 & 1.0 \\
  MNIST & 1.0 & 1.0 \\
\end{tabular}

}

\end{minipage}%

\end{table}%

\FloatBarrier

\section{Grid Searches}\label{sec-app-grid}

To assess the hyperparameter sensitivity of our proposed training regime
we ran multiple large grid searches for all of our synthetic datasets.
We have grouped these grid searches into multiple categories:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Generator Parameters} (Section~\ref{sec-app-grid-gen}):
  Investigates the effect of changing hyperparameters that affect the
  counterfactual outcomes during the training phase.
\item
  \textbf{Penalty Strengths} (Section~\ref{sec-app-grid-pen}):
  Investigates the effect of changing the penalty strengths in out
  proposed objective (Equation~\ref{eq-obj}).
\item
  \textbf{Other Parameters} (Section~\ref{sec-app-grid-train}):
  Investigates the effect of changing other training parameters,
  including the total number of generated counterfactuals in each epoch.
\end{enumerate}

We begin by summarizing the high-level findings in
Section~\ref{sec-app-grid-hl}. For each of the categories,
Section~\ref{sec-app-grid-gen} to Section~\ref{sec-app-grid-train} then
present all details including the exact parameter grids, average
predictive performance outcomes and key evaluation metrics for the
generated counterfactuals.

\subsection{Evaluation Details}\label{evaluation-details}

To measure predictive performance, we compute the accuracy and F1-score
for all models on test data (Table~\ref{tbl-acc-gen},
Table~\ref{tbl-acc-pen}, Table~\ref{tbl-acc-train}). With respect to
explanatory performance, we report here our findings for the
(im)plausibility and cost of counterfactuals at test time. Since the
computation of our proposed divergence metric
(Equation~\ref{eq-impl-div}) is memory-intensive, we rely on the
distance-based metric for the grid searches. For the counterfactual
evaluation, we draw factual samples from the training data for the grid
searches to avoid data leakage with respect to our final results
reported in the body of the paper. Specifically, we want to avoid
choosing our default hyperparameters based on results on the test data.
Since we are optimizing for explainability, not predictive performance,
we still present test accuracy and F1-scores.

\subsubsection{Predictive Performance}\label{predictive-performance}

We find that CT is associated with little to no decrease in average
predictive performance for our synthetic datasets: test accuracy and
F1-scores decrease by at most \textasciitilde1 percentage point, but
generally much less (Table~\ref{tbl-acc-gen}, Table~\ref{tbl-acc-pen},
Table~\ref{tbl-acc-train}). Variation across hyperparameters is
negligible as indicated by small standard deviations for these metrics
across the board.

\subsubsection{Counterfactual Outcomes}\label{sec-app-grid-hl}

Overall, we find that counterfactual training achieves it key objectives
consistently across all hyperparameter settings and also broadly across
datasets: plausibility is improved by up to 60 percent (\%) for the
\emph{Circles} data (e.g.
Figure~\ref{fig-grid-gen_params-plaus-circles}), 25-30\% for the
\emph{Moons} data (e.g. Figure~\ref{fig-grid-gen_params-plaus-moons})
and 10-20\% for the \emph{Linearly Separable} data (e.g.
Figure~\ref{fig-grid-gen_params-plaus-lin_sep}). At the same time, the
average costs of faithful counterfactuals are reduced in many cases by
around 20-25\% for \emph{Circles} (e.g.
Figure~\ref{fig-grid-gen_params-cost-circles}) and up to 50\% for
\emph{Moons} (e.g. Figure~\ref{fig-grid-gen_params-cost-moons}). For the
\emph{Linearly Separable} data, costs are generally increased although
typically by less than 10\% (e.g.
Figure~\ref{fig-grid-gen_params-cost-lin_sep}), which reflects a common
tradeoff between costs and plausibility
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}).

We do observe strong sensitivity to certain hyperparameters, with clear
an manageable patterns. Concerning generator parameters, we firstly find
that using \emph{REVISE} to generate counterfactuals during training
typically yields the worst outcomes out of all generators, often leading
to a substantial decrease in plausibility. This finding can be
attributed to the fact that \emph{REVISE} effectively assigns the task
of learning plausible explanations from the model itself to a surrogate
VAE. In other words, counterfactuals generated by \emph{REVISE} are less
faithful to the model that \emph{ECCo} and \emph{Generic}, and hence we
would expect them to be a less effective and, in fact, potentially
detrimental role in our training regime. Secondly, we observe that
allowing for a higher number of maximum steps \(T\) for the
counterfactual search generally yields better outcomes. This is
intuitive, because it allows more counterfactuals to reach maturity in
any given iteration. Looking in particular at the results for
\emph{Linearly Separable}, it seems that higher values for \(T\) in
combination with higher decision thresholds (\(\tau\)) yields the best
results when using \emph{ECCo}. But depending on the degree of class
separability of the underlying data, a high decision-threshold can also
affect results adversely, as evident from the results for the
\emph{Overlapping} data (Figure~\ref{fig-grid-gen_params-plaus-over}):
here we find that CT generally fails to achieve its objective because
only a tiny proportion of counterfactuals ever reaches maturity.

Regarding penalty strengths, we find that the strength of the energy
regularization, \(\lambda_{\text{reg}}\) is a key hyperparameter, while
sensitivity with respect to \(\lambda_{\text{div}}\) and
\(\lambda_{\text{adv}}\) is much less evident. In particular, we observe
that not regularizing energy enough or at all typically leads to poor
performance in terms of decreased plausibility and increased costs, in
particular for \emph{Circles} (Figure~\ref{fig-grid-pen-plaus-circles}),
\emph{Linearly Separable} (Figure~\ref{fig-grid-pen-plaus-lin_sep}) and
\emph{Overlapping} (Figure~\ref{fig-grid-pen-plaus-over}). High values
of \(\lambda_{\text{reg}}\) can increase the variability in outcomes, in
particular when combined with high values for \(\lambda_{\text{div}}\)
and \(\lambda_{\text{adv}}\), but this effect is less pronounced.

Finally, concerning other hyperparameters we observe that the
effectiveness and stability of CT is positively associated with the
number of counterfactuals generated during each training epoch, in
particular for \emph{Circles}
(Figure~\ref{fig-grid-train-plaus-circles}) and \emph{Moons}
(Figure~\ref{fig-grid-train-plaus-moons}). We further find that a higher
number of training epochs is beneficial as expected, where we tested
training models for 50 and 100 epochs. Interestingly, we find that it is
not necessary to employ CT during the entire training phase to achieve
the desired improvements in explainability: specifically, we have tested
training models conventionally during the first half of training before
switching to CT after this initial burn-in period.

\subsection{Generator Parameters}\label{sec-app-grid-gen}

The hyperparameter grid with varying generator parameters during
training is shown in Note~\ref{nte-gen-params-final-run-train}. The
corresponding evaluation grid used for these experiments is shown in
Note~\ref{nte-gen-params-final-run-eval}.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-gen-params-final-run-train}: Training Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-gen-params-final-run-train} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    Decision Threshold: \texttt{0.75,\ 0.9,\ 0.95}
  \item
    \(\lambda_{\text{egy}}\): \texttt{0.1,\ 0.5,\ 5.0,\ 10.0,\ 20.0}
  \item
    Maximum Iterations: \texttt{5,\ 25,\ 50}
  \end{itemize}
\item
  Generator: \texttt{ecco,\ generic,\ revise}
\item
  Model: \texttt{mlp}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    Objective: \texttt{full,\ vanilla}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-gen-params-final-run-eval}: Evaluation Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-gen-params-final-run-eval} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{egy}}\): \texttt{0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsubsection{Predictive Performance}\label{predictive-performance-1}

Predictive performance measures for this grid search are shown in
Table~\ref{tbl-acc-gen}.

\begin{longtable}{ccccc}

\caption{\label{tbl-acc-gen}Predictive performance measures by dataset
and objective averaged across training-phase parameters
(Note~\ref{nte-gen-params-final-run-train}) and evaluation-phase
parameters (Note~\ref{nte-gen-params-final-run-eval}).}

\tabularnewline

  \toprule
  \textbf{Dataset} & \textbf{Variable} & \textbf{Objective} & \textbf{Mean} & \textbf{Se} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Dataset} & \textbf{Variable} & \textbf{Objective} & \textbf{Mean} & \textbf{Se} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  Circ & Accuracy & Full & 1.0 & 0.0 \\
  Circ & Accuracy & Vanilla & 1.0 & 0.0 \\
  Circ & F1-score & Full & 1.0 & 0.0 \\
  Circ & F1-score & Vanilla & 1.0 & 0.0 \\
  LS & Accuracy & Full & 1.0 & 0.0 \\
  LS & Accuracy & Vanilla & 1.0 & 0.0 \\
  LS & F1-score & Full & 1.0 & 0.0 \\
  LS & F1-score & Vanilla & 1.0 & 0.0 \\
  Moon & Accuracy & Full & 1.0 & 0.0 \\
  Moon & Accuracy & Vanilla & 1.0 & 0.0 \\
  Moon & F1-score & Full & 1.0 & 0.0 \\
  Moon & F1-score & Vanilla & 1.0 & 0.0 \\
  OL & Accuracy & Full & 0.91 & 0.0 \\
  OL & Accuracy & Vanilla & 0.92 & 0.0 \\
  OL & F1-score & Full & 0.91 & 0.0 \\
  OL & F1-score & Vanilla & 0.92 & 0.0 \\\bottomrule

\end{longtable}

\subsubsection{Plausibility}\label{plausibility}

The results with respect to the plausibility measure are shown in
Figure~\ref{fig-grid-gen_params-plaus-circles} to
Figure~\ref{fig-grid-gen_params-plaus-over}.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/circles/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-gen_params-plaus-circles}Average outcomes for
the plausibility measure across hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/lin_sep/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-gen_params-plaus-lin_sep}Average outcomes for
the plausibility measure across hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/moons/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-gen_params-plaus-moons}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/over/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-gen_params-plaus-over}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Overlapping.}

\end{figure}%

\subsubsection{Cost}\label{cost}

The results with respect to the cost measure are shown in
Figure~\ref{fig-grid-gen_params-cost-circles} to
Figure~\ref{fig-grid-gen_params-cost-over}.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/circles/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png}

}

\caption{\label{fig-grid-gen_params-cost-circles}Average outcomes for
the cost measure across hyperparameters. This shows the \% change from
the baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/lin_sep/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png}

}

\caption{\label{fig-grid-gen_params-cost-lin_sep}Average outcomes for
the cost measure across hyperparameters. This shows the \% change from
the baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Linearly
Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/moons/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png}

}

\caption{\label{fig-grid-gen_params-cost-moons}Average outcomes for the
cost measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/gen_params/mlp/over/evaluation/results/ce/decision_threshold_exper---lambda_energy_exper---maxiter_exper---maxiter---decision_threshold_exper/distance.png}

}

\caption{\label{fig-grid-gen_params-cost-over}Average outcomes for the
cost measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data:
Overlapping.}

\end{figure}%

\subsection{Penalty Strengths}\label{sec-app-grid-pen}

The hyperparameter grid with varying penalty strengths during training
is shown in Note~\ref{nte-pen-final-run-train}. The corresponding
evaluation grid used for these experiments is shown in
Note~\ref{nte-pen-final-run-eval}.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-pen-final-run-train}: Training Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-pen-final-run-train} 

\begin{itemize}
\tightlist
\item
  Generator: \texttt{ecco,\ generic,\ revise}
\item
  Model: \texttt{mlp}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{adv}}\): \texttt{0.1,\ 0.25,\ 1.0}
  \item
    \(\lambda_{\text{div}}\): \texttt{0.01,\ 0.1,\ 1.0}
  \item
    \(\lambda_{\text{reg}}\): \texttt{0.0,\ 0.01,\ 0.1,\ 0.25,\ 0.5}
  \item
    Objective: \texttt{full,\ vanilla}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-pen-final-run-eval}: Evaluation Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-pen-final-run-eval} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{egy}}\): \texttt{0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsubsection{Predictive Performance}\label{predictive-performance-2}

Predictive performance measures for this grid search are shown in
Table~\ref{tbl-acc-pen}.

\begin{longtable}{ccccc}

\caption{\label{tbl-acc-pen}Predictive performance measures by dataset
and objective averaged across training-phase parameters
(Note~\ref{nte-pen-final-run-train}) and evaluation-phase parameters
(Note~\ref{nte-pen-final-run-eval}).}

\tabularnewline

  \toprule
  \textbf{Dataset} & \textbf{Variable} & \textbf{Objective} & \textbf{Mean} & \textbf{Se} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Dataset} & \textbf{Variable} & \textbf{Objective} & \textbf{Mean} & \textbf{Se} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  Circ & Accuracy & Full & 0.99 & 0.01 \\
  Circ & Accuracy & Vanilla & 1.0 & 0.0 \\
  Circ & F1-score & Full & 0.99 & 0.01 \\
  Circ & F1-score & Vanilla & 1.0 & 0.0 \\
  LS & Accuracy & Full & 1.0 & 0.01 \\
  LS & Accuracy & Vanilla & 1.0 & 0.0 \\
  LS & F1-score & Full & 1.0 & 0.01 \\
  LS & F1-score & Vanilla & 1.0 & 0.0 \\
  Moon & Accuracy & Full & 0.99 & 0.04 \\
  Moon & Accuracy & Vanilla & 1.0 & 0.01 \\
  Moon & F1-score & Full & 0.99 & 0.04 \\
  Moon & F1-score & Vanilla & 1.0 & 0.01 \\
  OL & Accuracy & Full & 0.91 & 0.02 \\
  OL & Accuracy & Vanilla & 0.92 & 0.0 \\
  OL & F1-score & Full & 0.91 & 0.02 \\
  OL & F1-score & Vanilla & 0.92 & 0.0 \\\bottomrule

\end{longtable}

\subsubsection{Plausibility}\label{plausibility-1}

The results with respect to the plausibility measure are shown in
Figure~\ref{fig-grid-pen-plaus-circles} to
Figure~\ref{fig-grid-pen-plaus-over}.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/circles/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-pen-plaus-circles}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/lin_sep/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-pen-plaus-lin_sep}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/moons/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-pen-plaus-moons}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/over/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-pen-plaus-over}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Overlapping.}

\end{figure}%

\subsubsection{Cost}\label{cost-1}

The results with respect to the cost measure are shown in
Figure~\ref{fig-grid-pen-cost-circles} to
Figure~\ref{fig-grid-pen-cost-over}.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/circles/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png}

}

\caption{\label{fig-grid-pen-cost-circles}Average outcomes for the cost
measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/lin_sep/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png}

}

\caption{\label{fig-grid-pen-cost-lin_sep}Average outcomes for the cost
measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Linearly
Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/moons/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png}

}

\caption{\label{fig-grid-pen-cost-moons}Average outcomes for the cost
measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/penalties/mlp/over/evaluation/results/ce/lambda_adversarial---lambda_energy_reg---lambda_energy_diff---lambda_adversarial---lambda_adversarial/distance.png}

}

\caption{\label{fig-grid-pen-cost-over}Average outcomes for the cost
measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data:
Overlapping.}

\end{figure}%

\subsection{Other Parameters}\label{sec-app-grid-train}

The hyperparameter grid with other varying training parameters is shown
in Note~\ref{nte-train-final-run-train}. The corresponding evaluation
grid used for these experiments is shown in
Note~\ref{nte-train-final-run-eval}.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-train-final-run-train}: Training Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-train-final-run-train} 

\begin{itemize}
\tightlist
\item
  Generator: \texttt{ecco,\ generic,\ revise}
\item
  Model: \texttt{mlp}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    Burnin: \texttt{0.0,\ 0.5}
  \item
    No.~Counterfactuals: \texttt{100,\ 1000}
  \item
    No.~Epochs: \texttt{50,\ 100}
  \item
    Objective: \texttt{full,\ vanilla}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-train-final-run-eval}: Evaluation Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-train-final-run-eval} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{egy}}\): \texttt{0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsubsection{Predictive Performance}\label{predictive-performance-3}

Predictive performance measures for this grid search are shown in
Table~\ref{tbl-acc-train}.

\begin{longtable}{ccccc}

\caption{\label{tbl-acc-train}Predictive performance measures by dataset
and objective averaged across training-phase parameters
(Note~\ref{nte-train-final-run-train}) and evaluation-phase parameters
(Note~\ref{nte-train-final-run-eval}).}

\tabularnewline

  \toprule
  \textbf{Dataset} & \textbf{Variable} & \textbf{Objective} & \textbf{Mean} & \textbf{Se} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Dataset} & \textbf{Variable} & \textbf{Objective} & \textbf{Mean} & \textbf{Se} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  Circ & Accuracy & Full & 0.99 & 0.0 \\
  Circ & Accuracy & Vanilla & 1.0 & 0.0 \\
  Circ & F1-score & Full & 0.99 & 0.0 \\
  Circ & F1-score & Vanilla & 1.0 & 0.0 \\
  LS & Accuracy & Full & 1.0 & 0.0 \\
  LS & Accuracy & Vanilla & 1.0 & 0.0 \\
  LS & F1-score & Full & 1.0 & 0.0 \\
  LS & F1-score & Vanilla & 1.0 & 0.0 \\
  Moon & Accuracy & Full & 1.0 & 0.01 \\
  Moon & Accuracy & Vanilla & 0.99 & 0.02 \\
  Moon & F1-score & Full & 1.0 & 0.01 \\
  Moon & F1-score & Vanilla & 0.99 & 0.02 \\
  OL & Accuracy & Full & 0.91 & 0.01 \\
  OL & Accuracy & Vanilla & 0.92 & 0.0 \\
  OL & F1-score & Full & 0.91 & 0.01 \\
  OL & F1-score & Vanilla & 0.92 & 0.0 \\\bottomrule

\end{longtable}

\subsubsection{Plausibility}\label{plausibility-2}

The results with respect to the plausibility measure are shown in
Figure~\ref{fig-grid-train-plaus-circles} to
Figure~\ref{fig-grid-train-plaus-over}.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/circles/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-train-plaus-circles}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/lin_sep/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-train-plaus-lin_sep}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/moons/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-train-plaus-moons}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/over/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/plausibility_distance_from_target.png}

}

\caption{\label{fig-grid-train-plaus-over}Average outcomes for the
plausibility measure across hyperparameters. This shows the \% change
from the baseline model for the distance-based implausibility metric
(Equation~\ref{eq-impl-dist}). Boxplots indicate the variation across
evaluation runs and test settings (varying parameters for \emph{ECCo}).
Data: Overlapping.}

\end{figure}%

\subsubsection{Cost}\label{cost-2}

The results with respect to the cost measure are shown in
Figure~\ref{fig-grid-train-cost-circles} to
Figure~\ref{fig-grid-train-cost-over}.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/circles/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png}

}

\caption{\label{fig-grid-train-cost-circles}Average outcomes for the
cost measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/lin_sep/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png}

}

\caption{\label{fig-grid-train-cost-lin_sep}Average outcomes for the
cost measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Linearly
Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/moons/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png}

}

\caption{\label{fig-grid-train-cost-moons}Average outcomes for the cost
measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/training_params/mlp/over/evaluation/results/ce/burnin---nce---nepochs---burnin---burnin/distance.png}

}

\caption{\label{fig-grid-train-cost-over}Average outcomes for the cost
measure across hyperparameters. This shows the \% change from the
baseline model for the distance-based cost metric
(\citeproc{ref-wachter2017counterfactual}{Wachter, Mittelstadt, and
Russell 2017}). Boxplots indicate the variation across evaluation runs
and test settings (varying parameters for \emph{ECCo}). Data:
Overlapping.}

\end{figure}%

\FloatBarrier

\section{Tuning Key Parameters}\label{sec-app-tune}

Based on the findings from our initial large grid searches
(Section~\ref{sec-app-grid}), we tune selected hyperparameters for all
datasets: namely, the decision threshold \(\tau\) and the strength of
the energy regularization \(\lambda_{\text{reg}}\). The final
hyperparameter choices for each dataset are presented in
Table~\ref{tbl-final-params} in Section~\ref{sec-app-main}. Detailed
results for each data set are shown in Figure~\ref{fig-tune-plaus-adult}
to Figure~\ref{fig-tune-mat-over}. From Table~\ref{tbl-final-params}, we
notice that the same decision threshold of \(\tau=0.5\) is optimal for
all but on dataset. We attribute this to the fact that a low decision
threshold results in a higher share of mature counterfactuals and hence
more opportunities for the model to learn from examples
(Figure~\ref{fig-tune-mat-adult} to Figure~\ref{fig-tune-mat-over}).
This has played a role in particular for our real-world tabular datasets
and MNIST, which suffered from low levels of maturity for higher
decision thresholds. In cases where maturity is not an issue, as for
\emph{Moons}, higher decision thresholds lead to better outcomes, which
may have to do with the fact that the resulting counterfactuals are more
faithful to the model. Concerning the regularization strength, we find
somewhat high variation across datasets. Most notably, we find that
relatively low levels of regularization are optimal for MNIST. We
hypothesize that this finding may be attributed to the uniform scaling
of all input features (digits).

Finally, to increase the proportion of mature counterfactuals for some
datasets, we have also investigated the effect on the learning rate
\(\eta\) for the counterfactual search and even smaller regularization
strengths for a fixed decision threshold of 0.5
(Figure~\ref{fig-tune_lr-plaus-adult} to
Figure~\ref{fig-tune_lr-plaus-over}). For the given low decision
threshold, we find that the learning rate has no discernable impact on
the proportion of mature counterfactuals
(Figure~\ref{fig-tune_lr-mat-adult} to
Figure~\ref{fig-tune_lr-mat-over}). We do notice, however, that the
results for MNIST are much improved when using a low value
\(\lambda_{\text{reg}}\), the strength for the engery regularization:
plausibility is increased by up to \textasciitilde10\%
(Figure~\ref{fig-tune_lr-plaus-mnist}) and the proportion of mature
counterfactuals reaches 100\%.

One consideration worth exploring is to combine high decision thresholds
with high learning rates, which we have not investigated here.

\subsection{Key Parameters}\label{sec-app-tune-key}

The hyperparameter grid for tuning key parameters is shown in
Note~\ref{nte-tune-train}. The corresponding evaluation grid used for
these experiments is shown in Note~\ref{nte-tune-eval}.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-tune-train}: Training Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-tune-train} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    Decision Threshold: \texttt{0.5,\ 0.75,\ 0.9}
  \end{itemize}
\item
  Model: \texttt{mlp}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{reg}}\): \texttt{0.1,\ 0.25,\ 0.5}
  \item
    Objective: \texttt{full,\ vanilla}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-tune-eval}: Evaluation Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-tune-eval} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{egy}}\): \texttt{0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsubsection{Plausibility}\label{plausibility-3}

The results with respect to the plausibility measure are shown in
Figure~\ref{fig-tune-plaus-adult} to Figure~\ref{fig-tune-plaus-over}.

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/adult/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-adult}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Adult.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/cali/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-cali}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: California Housing.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/circles/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-circles}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/credit/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-credit}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Credit.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/gmsc/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-gmsc}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: GMSC.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/lin_sep/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-lin_sep}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/mnist/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-mnist}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: MNIST.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/moons/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-moons}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/over/evaluation/results/ce/lambda_energy_reg---decision_threshold_exper---lambda_energy_eval---lambda_energy_reg---decision_threshold_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune-plaus-over}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Overlapping.}

\end{figure}%

\subsubsection{Proportion of Mature CE}\label{proportion-of-mature-ce}

The results with respect to the proportion of mature counterfactuals in
each epoch are shown in Figure~\ref{fig-tune-mat-adult} to
Figure~\ref{fig-tune-mat-over}.

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/adult/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-adult}Proportion of mature counterfactuals
in each epoch. Data: Adult.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/cali/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-cali}Proportion of mature counterfactuals
in each epoch. Data: California Housing.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/circles/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-circles}Proportion of mature
counterfactuals in each epoch. Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/credit/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-credit}Proportion of mature counterfactuals
in each epoch. Data: Credit.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/gmsc/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-gmsc}Proportion of mature counterfactuals
in each epoch. Data: GMSC.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/lin_sep/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-lin_sep}Proportion of mature
counterfactuals in each epoch. Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/mnist/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-mnist}Proportion of mature counterfactuals
in each epoch. Data: MNIST.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/moons/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-moons}Proportion of mature counterfactuals
in each epoch. Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune/mlp/over/evaluation/results/logs/objective---decision_threshold---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune-mat-over}Proportion of mature counterfactuals
in each epoch. Data: Overlapping.}

\end{figure}%

\subsection{Learning Rate}\label{sec-app-tune-lr}

The hyperparameter grid for tuning the learning rate is shown in
Note~\ref{nte-tune_lr-train}. The corresponding evaluation grid used for
these experiments is shown in Note~\ref{nte-tune_lr-eval}.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-tune_lr-train}: Training Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-tune_lr-train} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    Learning Rate: \texttt{0.1,\ 0.5,\ 1.0}
  \end{itemize}
\item
  Model: \texttt{mlp}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{reg}}\): \texttt{0.01,\ 0.1,\ 0.5}
  \item
    Objective: \texttt{full,\ vanilla}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, toprule=.15mm, colback=white, colbacktitle=quarto-callout-note-color!10!white, leftrule=.75mm, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note \ref*{nte-tune_lr-eval}: Evaluation Phase}, coltitle=black, titlerule=0mm, rightrule=.15mm, bottomtitle=1mm, breakable, bottomrule=.15mm, left=2mm, opacityback=0]

\quartocalloutnte{nte-tune_lr-eval} 

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{egy}}\): \texttt{0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0}
  \end{itemize}
\end{itemize}

\end{tcolorbox}

\subsubsection{Plausibility}\label{plausibility-4}

The results with respect to the plausibility measure are shown in
Figure~\ref{fig-tune_lr-plaus-adult} to
Figure~\ref{fig-tune_lr-plaus-over}.

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/adult/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-adult}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Adult.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/cali/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-cali}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: California Housing.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/circles/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-circles}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/credit/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-credit}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Credit.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/gmsc/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-gmsc}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: GMSC.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/lin_sep/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-lin_sep}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/mnist/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-mnist}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: MNIST.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/moons/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-moons}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/over/evaluation/results/ce/lambda_energy_reg---lr_exper---lambda_energy_eval---lambda_energy_reg---lr_exper/plausibility_distance_from_target.png}

}

\caption{\label{fig-tune_lr-plaus-over}Average outcomes for the
plausibility measure across key hyperparameters. This shows the \%
change from the baseline model for the distance-based implausibility
metric (Equation~\ref{eq-impl-dist}). Boxplots indicate the variation
across evaluation runs and test settings (varying parameters for
\emph{ECCo}). Data: Overlapping.}

\end{figure}%

\subsubsection{Proportion of Mature CE}\label{proportion-of-mature-ce-1}

The results with respect to the proportion of mature counterfactuals in
each epoch are shown in Figure~\ref{fig-tune_lr-mat-adult} to
Figure~\ref{fig-tune_lr-mat-over}.

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/adult/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-adult}Proportion of mature
counterfactuals in each epoch. Data: Adult.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/cali/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-cali}Proportion of mature
counterfactuals in each epoch. Data: California Housing.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/circles/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-circles}Proportion of mature
counterfactuals in each epoch. Data: Circles.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/credit/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-credit}Proportion of mature
counterfactuals in each epoch. Data: Credit.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/gmsc/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-gmsc}Proportion of mature
counterfactuals in each epoch. Data: GMSC.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/lin_sep/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-lin_sep}Proportion of mature
counterfactuals in each epoch. Data: Linearly Separable.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/mnist/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-mnist}Proportion of mature
counterfactuals in each epoch. Data: MNIST.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/moons/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-moons}Proportion of mature
counterfactuals in each epoch. Data: Moons.}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{../../paper/experiments/output/final_run/tune_lr/mlp/over/evaluation/results/logs/objective---lr---lambda_energy_reg/percent_valid.png}

}

\caption{\label{fig-tune_lr-mat-over}Proportion of mature
counterfactuals in each epoch. Data: Overlapping.}

\end{figure}%

\FloatBarrier

\section{Computation Details}\label{computation-details}

\subsection{Hardware}\label{sec-app-hardware}

We performed our experiments on a high-performance cluster. Details
about the cluster will be disclosed upon publication to avoid revealing
information that might interfere with the double-blind review process.
Since our experiments involve highly parallel tasks and rather small
models by today's standard, we have relied on distributed computing
across multiple central processing units (CPU). Graphical processing
units (GPU) were not required.

\subsubsection{Grid Searches}\label{grid-searches}

Model training for the largest grid searches with 270 unique parameter
combinations was parallelized across 34 CPUs with 2GB memory each. The
time to completion varied by dataset for reasons discussed in
Section~\ref{sec-discussion}: 0h49m (\emph{Moons}), 1h4m (\emph{Linearly
Separable}), 1h49m (\emph{Circles}), 3h52m (\emph{Overlapping}). Model
evaluations for large grid searches were parallelized across 20 CPUs
with 3GB memory each. Evaluations for all data sets took less than one
hour (\textless1h) to complete.

\subsubsection{Tuning}\label{tuning}

For tuning of selected hyperparameters, we distributed the task of
generating counterfactuals during training across 40 CPUs with 2GB
memory each for all tabular datasets. Except for the \emph{Adult}
dataset, all training runs were completed in less that half an hour
(\textless0h30m). The \emph{Adult} dataset took around 0h35m to
complete. Evaluations across 20 CPUs with 3GB memory each generally took
less than 0h30m to complete. For \emph{MNIST}, we relied on 100 CPUs
with 2GB memory each. For the \emph{MLP}, training of all models could
be completed in 1h30m, while the evaluation across 20 CPUs (6GB memory)
took 4h12m. For the \emph{CNN}, training of all models took
\textasciitilde8h, with conventionally trained models taking
\textasciitilde0h15m each and model with CT taking
\textasciitilde0h30m-0h45m each.

\subsection{Software}\label{software}

All computations were performed in the Julia Programming Language
(\citeproc{ref-bezanson2017julia}{Bezanson et al. 2017}). We have
developed a package for counterfactual training that leverages and
extends the functionality provided by several existing packages, most
notably
\href{https://github.com/JuliaTrustworthyAI/CounterfactualExplanations.jl}{CounterfactualExplanations.jl}
(\citeproc{ref-altmeyer2023explaining}{Altmeyer, Deursen, and Liem
2023}) and the \href{https://fluxml.ai/Flux.jl/v0.16/}{Flux.jl} library
for deep learning (\citeproc{ref-innes2018fashionable}{Michael Innes et
al. 2018}; \citeproc{ref-innes2018flux}{Mike Innes 2018}). For
data-wrangling and presentation-ready tables we relied on
\href{https://dataframes.juliadata.org/v1.7/}{DataFrames.jl}
(\citeproc{ref-milan2023dataframes}{Bouchet-Valat and Kamiski 2023})
and
\href{https://ronisbr.github.io/PrettyTables.jl/v2.4/}{PrettyTables.jl}
(\citeproc{ref-chagas2024pretty}{Chagas et al. 2024}), respectively. For
plots and visualizations we used both
\href{https://docs.juliaplots.org/v1.40/}{Plots.jl}
(\citeproc{ref-PlotsJL}{Christ et al. 2023}) and
\href{https://docs.makie.org/v0.22/}{Makie.jl}
(\citeproc{ref-danisch2021makie}{Danisch and Krumbiegel 2021}), in
particular \href{https://aog.makie.org/v0.9.3/}{AlgebraOfGraphics.jl}.
To distribute computational tasks across multiple processors, we have
relied on \href{https://juliaparallel.org/MPI.jl/v0.20/}{MPI.jl}
(\citeproc{ref-byrne2021mpi}{Byrne, Wilcox, and Churavy 2021}).

\end{appendices}




\end{document}
