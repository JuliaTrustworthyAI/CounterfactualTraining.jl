# Conclusions {#sec-discussion}

As our results indicate, counterfactual training produces models that are more explainable. Nonetheless, these advantages come at the cost of two important limitations.  

*CT increases the training time of models.* CT can be more time-consuming than conventional training regimes. While higher numbers of CEs per iteration positively impact the quality of solutions, they also increase the amount of computations. In our experiments, grids with 270 settings took up to four hours for more demanding datasets on a high-performance computing cluster with 34 2GB CPUs.^[See supplementary appendix for computational details.] Three factors attenuate this effect: (1) CT yields itself to parallel execution, which we have leveraged for our own experiments; (2) it amortizes the cost of CEs for the training samples; (3) as demonstrated, it retains its value when used as a "fine-tuning" technique for conventionally-trained models.  

*Interventions on features have implications for fairness.* We provide a tool that allows practitioners to modify the sensitivity of a model with respect to certain features. Model owners can use our solution to support the fair and equitable treatment of decision subjects, but they could also misuse it by enforcing explanations based on features that are more difficult to modify by some (group of) individuals. When applied irresponsibly, CT could result in an unfairly assigned burden of recourse [@sharma2020certifai], threatening the equality of opportunity in the system [@bell2024fairness]. Additionally, CT requires that model owners define the mutability constraints for the features considered by the model. Even if all immutable features are protected, there may exist proxies that are mutable --- and hence should not be protected --- but preserve sufficient information about the principals to hinder the protections. Deciding on actionability is still a major open challenge in the AR literature [@venkatasubramanian2020philosophical] impacting the capacity of CT to fulfill its intended goal. As such, neither of these phenomena is ultimately specific to CT.

We also highlight several important directions for future research. Firstly, it is an interesting challenge to extend CT beyond classification settings. Our formulation relies on the distinction between non-target class(es) $y^{-}$ and target class(es) $y^{+}$ to generate counterfactuals through @eq-obj. While $y^{-}$ and $y^{+}$ can be arbitrarily defined, CT requires the output space $\mathcal{Y}$ to be discrete. Thus, it does not apply to ML tasks where the change in outcome cannot be readily discretized. Focus on classification is a common choice in research on CEs and AR. Other settings have attracted some interest, e.g., regression [@spooner2021counterfactual], but there is little consensus how to robustly extend the notion of CEs.  
Secondly, CT is susceptible to instabilities in training. This problem has been recognized for JEMs [@grathwohl2020your] and even though we depart from the SGLD-based sampling, we still encounter variability in outcomes. CT is exposed to two potential sources of training instabilities: (1) the energy-based contrastive divergence term in @eq-div, and (2) the underlying counterfactual explainers. We find several promising ways to mitigate this problem: regularizing energy ($\lambda_{\text{reg}}$), generating sufficiently many counterfactuals during each epoch, and including only mature counterfactuals for contrastive divergence.  
Finally, we believe that it is possible to substantially improve hyperparameter selection procedures, and thus performance. In this work, we have relied exclusively on grid searches for this task. Future work on CT could benefit from investigating more sophisticated approaches. Notably, our method is iterative which makes methods such as Bayesian or gradient-based optimization applicable [@bischl2023hyperparameter].