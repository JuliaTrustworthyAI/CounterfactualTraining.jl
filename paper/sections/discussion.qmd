# Conclusions {#sec-discussion}

As our results indicate, counterfactual training produces models that are more explainable. Nonetheless, these advantages come at the cost of two important limitations.  

*Interventions on features have implications for fairness.* We provide a tool that allows practitioners to modify the sensitivity of a model with respect to certain features. Model owners can use our solution to support the fair and equitable treatment of decision subjects, but they could also misuse it by enforcing explanations based on features that are more difficult to modify by some (group of) individuals. When used irresponsibly, CT could result in an unfairly assigned burden of recourse [@sharma2020certifai], threatening the equality of opportunity [@bell2024fairness]. Additionally, CT requires mutability constraints for the features considered by the model. Even if all immutable features are protected, there may exist proxies that are mutable, and hence should not be protected, but preserve sufficient information about the principals to hinder these protections. Deciding on actionability is still a major open challenge in the AR literature [@venkatasubramanian2020philosophical] impacting the capacity of CT to fulfill its intended goal.

*CT increases the training time of models.* Just like adversarial training, CT is more resource-intensive than conventional training regimes. Higher numbers of CEs per iteration improve the quality of learned representations, but they also increase the number of computations. As our codebase is not performance optimized, grids of 270 settings took up to four hours for more demanding datasets in our experiments, when ran on 34 2GB CPUs (see supplementary appendix). Other than optimization, three factors mitigate this effect: (1) CT yields itself to parallel execution; (2) it amortizes the cost of CEs for the training samples; (3) it can be used to fine-tune conventionally-trained models.  

We also highlight several important directions for future research. Firstly, it is an interesting challenge to extend CT beyond classification settings. Our formulation relies on the distinction between non-target class(es) $y^{-}$ and target class(es) $y^{+}$ to generate counterfactuals through @eq-obj. While $y^{-}$ and $y^{+}$ can be arbitrarily defined, CT requires the output space $\mathcal{Y}$ to be discrete. Thus, it does not apply to ML tasks where the change in outcome cannot be readily discretized. Focus on classification is a common choice in research on CEs and AR. Other settings have attracted some interest, e.g., regression [@spooner2021counterfactual], but there is little consensus how to robustly extend the notion of CEs.  
Secondly, CT is susceptible to training instabilities. This problem has been recognized for JEMs [@grathwohl2020your] and even though we depart from the SGLD sampling, we still encounter variability in outcomes. CT is exposed to two potential sources of instabilities: (1) the energy-based contrastive divergence term, $\text{div}(\cdot)$, in @eq-div, and (2) the underlying explainers. We find several promising ways to mitigate this problem: regularizing energy ($\lambda_{\text{reg}}$), generating sufficiently many counterfactuals during each epoch, and including only mature counterfactuals in $\text{div}(\cdot)$.  
Finally, we believe that it is possible to substantially improve hyperparameter selection procedures, and thus performance. In this work, we have relied exclusively on grid searches for this task. Future work on CT could benefit from investigating more sophisticated approaches. Notably, our method is iterative which makes methods such as Bayesian or gradient-based optimization applicable [@bischl2023hyperparameter].