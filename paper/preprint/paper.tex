% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
    \setmainfont[]{Latin Modern Roman}
  \setmathfont[]{Latin Modern Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{arxiv}
\usepackage{orcidlink}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{placeins}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{definition}
\newtheorem{exercise}{Parameters}[section]
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[section]
\newtheorem{refsolution}{Solution}[section]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Counterfactual Training: Teaching Models Plausible and Actionable Explanations},
  pdfauthor={Patrick Altmeyer; Arie van Deursen; Cynthia C. S. Liem},
  pdfkeywords={Counterfactual Explanations, Explainable
AI, Representation Learning},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\usepackage{lineno}
\linenumbers
\newcommand{\runninghead}{A Preprint }
\renewcommand{\runninghead}{Counterfactual Training (A Preprint) }
\title{Counterfactual Training: Teaching Models Plausible and Actionable
Explanations}
\def\asep{\\\\\\ } % default: all authors on same column
\def\asep{\And }
\author{\textbf{Patrick
Altmeyer}~\orcidlink{0000-0003-4726-8613}\\Faculty of Electrical
Engineering, Mathematics and Computer Science\\Delft University of
Technology\\\\\href{mailto:p.altmeyer@tudelft.nl}{p.altmeyer@tudelft.nl}\asep\textbf{Arie
van Deursen}\\Faculty of Electrical Engineering, Mathematics and
Computer Science\\Delft University of Technology\\\\\asep\textbf{Cynthia
C. S. Liem}\\Faculty of Electrical Engineering, Mathematics and Computer
Science\\Delft University of Technology\\\\}
\date{}
\begin{document}
\maketitle
\begin{abstract}
Counterfactual Explanations have emerged as a popular tool to explain
predictions made by opaque machine learning models: they explain how
factual inputs need to change in order for some fitted model to produce
some desired output. Much existing research has focused on identifying
explanations that are not only valid but also deemed desirable with
respect to the underlying data and stakeholder requirements. Recent work
has shown that under this premise, the task of learning desirable
explanations is effectively reassigned from the model itself to the
(post-hoc) counterfactual explainer. Building on that work, we propose a
novel model objective that leverages counterfactuals during the training
phase (ad-hoc) in order to minimize the divergence between learned
representations and desirable explanations. Through extensive
experiments, we demonstrate that our proposed methodology facilitates
training models that inherently deliver desirable explanations while
maintaining high predictive performance.
\end{abstract}
{\bfseries \emph Keywords}
\def\sep{\textbullet\ }
Counterfactual Explanations \sep Explainable AI \sep 
Representation Learning



\section{Introduction}\label{introduction}

Today's prominence of artificial intelligence (AI) has largely been
driven by advances in \textbf{representation learning}: instead of
relying on features and rules that are carefully hand-crafted by humans,
modern AIs are tasked with learning these representations from scratch,
guided by narrow objectives such as predictive accuracy
(\citeproc{ref-goodfellow2016deep}{I. Goodfellow, Bengio, and Courville
2016}). Modern advances in computing have made it possible to provide
such AIs with ever greater degrees of freedom to achieve that task,
which has often led them to outperform traditionally more parsimonious
models. Unfortunately, in doing so they also learn increasingly complex
and highly sensitive representations that we can no longer easily
interpret.

This trend towards complexity for the sake of performance has come under
serious scrutiny in recent years. At the very cusp of the deep learning
revolution, Szegedy et al. (\citeproc{ref-szegedy2013intriguing}{2013})
showed that artificial neural networks (ANN) are sensitive to
adversarial examples: counterfactuals of model inputs that yield vastly
different model predictions despite being ``imperceptible'' in that they
are semantically indifferent from their factual counterparts. Despite
partially effective mitigation strategies such as \textbf{adversarial
training} (\citeproc{ref-goodfellow2014explaining}{I. J. Goodfellow,
Shlens, and Szegedy 2014}), truly robust deep learning (DL) remains
unattainable even for models that are considered shallow by today's
standards (\citeproc{ref-kolter2023keynote}{Kolter 2023}).

Part of the problem is that high degrees of freedom provide room for
many solutions that are locally optimal with respect to narrow
objectives (\citeproc{ref-wilson2020case}{Wilson 2020}). Based purely on
predictive performance, these solutions may seem to provide compelling
explanations for the data, when in fact they are based on purely
associative, semantically meaningless patterns. This poses two related
challenges: firstly, it makes these models inherently opaque, since
humans cannot simply interpret what type of explanation the complex
learned representations correspond to; secondly, even if we could
resolve the first challenge, it is not obvious how to mitigate models
from learning representations that correspond to meaningless and
undesirable explanations.

The first challenge has attracted an abundance of research on
\textbf{explainable AI} (XAI) which aims to develop tools to derive
explanations from complex model representations. This can mitigate a
scenario in which we deploy opaque models and blindly rely on their
predictions. On countless occasions, this scenario has already occurred
in practice and caused real harm to people who were affected adversely
and often unfairly by automated decision-making systems (ADMS) involving
opaque models (\citeproc{ref-oneil2016weapons}{O'Neil 2016}). Effective
XAI tools can aide us in monitoring models and providing recourse to
individuals to turn adverse outcomes (e.g.~``loan application
rejected'') into positive ones (``application accepted''). Wachter,
Mittelstadt, and Russell
(\citeproc{ref-wachter2017counterfactual}{2017}) propose
\textbf{counterfactual explanations} as an effective approach to achieve
this: they explain how factual inputs need to change in order for some
fitted model to produce some desired output, typically involving minimal
perturbations.

To our surprise, the second challenge has not yet attracted any
consolidated research effort. Specifically, there has been no concerted
effort towards improving model \textbf{explainability}, which we define
here as the degree to which learned representations correspond to
explanations that are interpretable and deemed desirable by humans.
Instead, the choice has typically been to improve the capacity of XAI
tools to identify the subset explanations that are both desirable and
valid for any given model, independent of whether the learned
representations are also compatible with undesirable explanations
(\citeproc{ref-altmeyer2024faithful}{Altmeyer et al. 2024}).
Fortunately, recent findings indicate that explainability can arise as
byproduct of regularization techniques aimed at other objectives such as
robustness, generalization and generative capacity Altmeyer et al.
(\citeproc{ref-altmeyer2024faithful}{2024}).

Building on these findings, we introduce \textbf{counterfactual
training}: a novel regularization technique geared explicitly towards
aligning model representations with desirable explanations. Our
contributions are as follows:

\begin{itemize}
\tightlist
\item
  We discuss existing related work on improving models and consolidate
  it through the lens of counterfactual explanations
  (Section~\ref{sec-lit}).
\item
  We present our proposed methodological framework that leverages
  faithful counterfactual explanations during the training phase of
  models to achieve the explainability objective
  (Section~\ref{sec-method}).
\item
  Through extensive experiments we demonstrate the counterfactual
  training improve model explainability while maintaining high
  predictive performance. We run ablation studies and grid searches to
  understand how the underlying model components and hyperparameters
  affect outcomes. (Section~\ref{sec-experiments}).
\end{itemize}

Despite limitations of our approach discussed in
Section~\ref{sec-discussion}, we conclude that counterfactual training
provides a practical framework for researchers and practitioners
interested in making opaque models more trustworthy
Section~\ref{sec-conclusion}. We also believe that this work serves as
an opportunity for XAI researchers to reevaluate the premise of
improving XAI tools without improving models.

\section{Related Literature}\label{sec-lit}

To the best of our knowledge, our proposed framework for counterfactual
training represents the first attempt to use counterfactual explanations
during training to improve model explainability. In high-level terms, we
define model explainability as the extent to which valid explanations
derived for an opaque model are also deemed desirable with respect to
the underlying data and stakeholder requirements. To make this more
concrete, we follow Augustin, Meinke, and Hein
(\citeproc{ref-augustin2020adversarial}{2020}) in tieing the concept of
explainability to the quality of counterfactual explanations that we can
generate for a given model. The authors show that counterfactual
explanations---understood here as minimal input perturbations that yield
some desired model prediction---are generally more meaningful if the
underlying model is more robust to adversarial examples. We can make
intuitive sense of this finding when looking at adversarial training
(AT) through the lens of representation learning with high degrees of
freedom: by inducing models to ``unlearn'' representations that are
susceptible to worst-case counterfactuals (i.e.~adversarial examples),
AT effectively removes some undesirable explanations from the solution
space.

\subsection{Adversarial Examples are Counterfactual
Explanations}\label{adversarial-examples-are-counterfactual-explanations}

This interpretation of the link between explainability through
counterfactuals on one side, and robustness to adversarial examples on
the other, is backed by empirical evidence. Sauer and Geiger
(\citeproc{ref-sauer2021counterfactual}{2021}) demonstrate that using
counterfactual images during classifier training improves model
robustness. Similarly, Abbasnejad et al.
(\citeproc{ref-abbasnejad2020counterfactual}{2020}) argue that
counterfactuals represent potentially useful training data in machine
learning, especially in supervised settings where inputs may be
reasonably mapped to multiple outputs. They, too, demonstrate the
augmenting the training data of image classifiers can improve
generalization. Teney, Abbasnedjad, and Hengel
(\citeproc{ref-teney2020learning}{2020}) propose an approach using
counterfactuals in training that does not rely on data augmentation:
they argue that counterfactual pairs typically already exist in training
datasets. Specifically, their approach relies on, firstly, identifying
similar input samples with different annotations and, secondly, ensuring
that the gradient of the classifier aligns with the vector between pairs
of counterfactual inputs using the cosine distance as a loss function.
In the natural language processing (NLP) domain, counterfactuals have
similarly been used to improve models through data augmentation: Wu et
al. (\citeproc{ref-wu2021polyjuice}{2021}), propose \emph{POLYJUICE}, a
general-purpose counterfactual generator for language models. They
demonstrate empirically that augmenting training data through
\emph{POLYJUICE} counterfactuals improves robustness in a number of NLP
tasks. Luu and Inoue (\citeproc{ref-luu2023counterfactual}{2023})
introduce Counterfactual Adversarial Training (CAT), which also aims at
improving generalization and robustness of language models.
Specifically, they propose to proceed as follows: firstly, they identify
training samples that are subject to high predictive uncertainty;
secondly, they generate counterfactual explanations for those samples;
and, finally, they fine-tune the given language model on the augmented
dataset that includes the generated counterfactuals.

There have also been several attempts at formalizing the relationship
between counterfactual explanations (CE) and adversarial examples (AE).
Pointing to clear similarities in how CE and AE are generated,
Freiesleben (\citeproc{ref-freiesleben2022intriguing}{2022}) makes the
case for jointly studying the opaqueness and robustness problem in
representation learning. Formally, AE can be seen as the subset of CE,
for which misclassification is achieved
(\citeproc{ref-freiesleben2022intriguing}{Freiesleben 2022}). Similarly,
Pawelczyk et al. (\citeproc{ref-pawelczyk2022exploring}{2022}) show that
CE and AE are equivalent under certain conditions and derive theoretical
upper bounds on the distances between them.

Two recent works are closely related to ours in that they use
counterfactuals during training with the explicit goal of affecting
certain properties of post-hoc counterfactual explanations. Firstly,
Ross, Lakkaraju, and Bastani (\citeproc{ref-ross2021learning}{2024})
propose a way to train models that are guaranteed to provide recourse
for individuals to move from an adverse outcome to some positive target
class with high probability. The approach proposed by Ross, Lakkaraju,
and Bastani (\citeproc{ref-ross2021learning}{2024}) builds on
adversarial training, where in this context susceptibility to targeted
adversarial examples for the positive class is explicitly induced. The
proposed method allows for imposing a set of actionability constraints
ex-ante: for example, users can specify that certain features
(e.g.~\emph{age}, \emph{gender}, \ldots) are immutable. Secondly, Guo,
Nguyen, and Yadav (\citeproc{ref-guo2023counternet}{2023}) are the first
to propose an end-to-end training pipeline that includes counterfactual
explanations as part of the training procedure. In particular, they
propose a specific network architecture that includes a predictor and CE
generator network, where the parameters of the CE generator network are
learnable. Counterfactuals are generated during each training iteration
and fed back to the predictor network. In contrast to Guo, Nguyen, and
Yadav (\citeproc{ref-guo2023counternet}{2023}), we impose no
restrictions on the neural network architecture at all.

\subsection{Beyond Robustness}\label{beyond-robustness}

Improving the adversarial robustness of models is not the only path
towards aligning representations with desirable explanations. In a work
closely related to this one, Altmeyer et al.
(\citeproc{ref-altmeyer2024faithful}{2024}) show that explainability can
be improved through model averaging and refined model objectives. The
authors propose a way to generate counterfactuals that are maximally
\textbf{faithful} to the model in that they are consistent with what the
model has learned about the underlying data. Formally, they rely on
tools from energy-based modelling to minimize the divergence between the
distribution of counterfactuals and the conditional posterior over
inputs learned by the model. Their proposed counterfactual explainer,
\emph{ECCCo}, yields desirable (or \textbf{plausible}) explanations if
and only if the underlying model has learned representations that align
with them. They find that both deep ensembles
(\citeproc{ref-lakshminarayanan2016simple}{Lakshminarayanan, Pritzel,
and Blundell 2017}) and joint energy-based models (JEMs)
(\citeproc{ref-grathwohl2020your}{Grathwohl et al. 2020}) tend to do
well in this regard.

Once again it helps to look at these findings through the lens of
representation learning with high degrees of freedom. Deep ensembles are
approximate Bayesian model averages, which are most called for when
models are underspecified by the available data
(\citeproc{ref-wilson2020case}{Wilson 2020}). Averaging across solutions
mitigates the aforementioned risk of relying on a single locally optimal
representations that corresponds to semantically meaningless
explanations for the data. Previous work by Schut et al.
(\citeproc{ref-schut2021generating}{2021}) similarly found that
generating desirable (``interpretable'') counterfactual explanations is
almost trivial for deep ensembles that have also undergone adversarial
training. The case for JEMs is even clearer: they involve a hybrid
objective that induces both high predictive performance and generative
capacity (\citeproc{ref-grathwohl2020your}{Grathwohl et al. 2020}). This
is closely related to the idea of aligning models with desirable
explanations and has inspired our proposed counterfactual training
objective, as we explain in Section~\ref{sec-method}.

\section{Counterfactual Training}\label{sec-method}

\begin{definition}[Model
Explainability]\protect\hypertarget{def-explainability}{}\label{def-explainability}

~

\end{definition}

\section{Experiments}\label{sec-experiments}

\subsection{Experimental Setup}\label{experimental-setup}

\subsection{Experimental Results}\label{experimental-results}

\section{Discussion}\label{sec-discussion}

\section{Conclusion}\label{sec-conclusion}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-abbasnejad2020counterfactual}
Abbasnejad, Ehsan, Damien Teney, Amin Parvaneh, Javen Shi, and Anton van
den Hengel. 2020. {``Counterfactual Vision and Language Learning.''} In
\emph{2020 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)}, 10041--51.
\url{https://doi.org/10.1109/CVPR42600.2020.01006}.

\bibitem[\citeproctext]{ref-altmeyer2024faithful}
Altmeyer, Patrick, Mojtaba Farmanbar, Arie van Deursen, and Cynthia CS
Liem. 2024. {``Faithful Model Explanations Through Energy-Constrained
Conformal Counterfactuals.''} In \emph{Proceedings of the AAAI
Conference on Artificial Intelligence}, 38:10829--37. 10.

\bibitem[\citeproctext]{ref-augustin2020adversarial}
Augustin, Maximilian, Alexander Meinke, and Matthias Hein. 2020.
{``Adversarial Robustness on in-and Out-Distribution Improves
Explainability.''} In \emph{European Conference on Computer Vision},
228--45. Springer.

\bibitem[\citeproctext]{ref-freiesleben2022intriguing}
Freiesleben, Timo. 2022. {``The Intriguing Relation Between
Counterfactual Explanations and Adversarial Examples.''} \emph{Minds and
Machines} 32 (1): 77--109.

\bibitem[\citeproctext]{ref-goodfellow2014explaining}
Goodfellow, Ian J, Jonathon Shlens, and Christian Szegedy. 2014.
{``Explaining and Harnessing Adversarial Examples.''}
\url{https://arxiv.org/abs/1412.6572}.

\bibitem[\citeproctext]{ref-goodfellow2016deep}
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. \emph{Deep
{Learning}}. {MIT Press}.

\bibitem[\citeproctext]{ref-grathwohl2020your}
Grathwohl, Will, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud,
Mohammad Norouzi, and Kevin Swersky. 2020. {``Your Classifier Is
Secretly an Energy Based Model and You Should Treat It Like One.''} In
\emph{International Conference on Learning Representations}.

\bibitem[\citeproctext]{ref-guo2023counternet}
Guo, Hangzhi, Thanh H. Nguyen, and Amulya Yadav. 2023. {``CounterNet:
End-to-End Training of Prediction Aware Counterfactual Explanations.''}
In \emph{Proceedings of the 29th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining}, 577--89. KDD '23. New York, NY, USA:
Association for Computing Machinery.
\url{https://doi.org/10.1145/3580305.3599290}.

\bibitem[\citeproctext]{ref-kolter2023keynote}
Kolter, Zico. 2023.{``{Keynote Addresses: SaTML 2023 }.''} In \emph{2023
IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
xvi--. Los Alamitos, CA, USA: IEEE Computer Society.
\url{https://doi.org/10.1109/SaTML54575.2023.00009}.

\bibitem[\citeproctext]{ref-lakshminarayanan2016simple}
Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. 2017.
{``Simple and Scalable Predictive Uncertainty Estimation Using Deep
Ensembles.''} \emph{Advances in Neural Information Processing Systems}
30.

\bibitem[\citeproctext]{ref-luu2023counterfactual}
Luu, Hoai Linh, and Naoya Inoue. 2023. {``Counterfactual Adversarial
Training for Improving Robustness of Pre-Trained Language Models.''} In
\emph{Proceedings of the 37th Pacific Asia Conference on Language,
Information and Computation}, 881--88.

\bibitem[\citeproctext]{ref-oneil2016weapons}
O'Neil, Cathy. 2016. \emph{Weapons of Math Destruction: {How} Big Data
Increases Inequality and Threatens Democracy}. {Crown}.

\bibitem[\citeproctext]{ref-pawelczyk2022exploring}
Pawelczyk, Martin, Chirag Agarwal, Shalmali Joshi, Sohini Upadhyay, and
Himabindu Lakkaraju. 2022. {``Exploring Counterfactual Explanations
Through the Lens of Adversarial Examples: A Theoretical and Empirical
Analysis.''} In \emph{Proceedings of the 25th International Conference
on Artificial Intelligence and Statistics}, edited by Gustau
Camps-Valls, Francisco J. R. Ruiz, and Isabel Valera, 151:4574--94.
Proceedings of Machine Learning Research. PMLR.
\url{https://proceedings.mlr.press/v151/pawelczyk22a.html}.

\bibitem[\citeproctext]{ref-ross2021learning}
Ross, Alexis, Himabindu Lakkaraju, and Osbert Bastani. 2024. {``Learning
Models for Actionable Recourse.''} In \emph{Proceedings of the 35th
International Conference on Neural Information Processing Systems}. NIPS
'21. Red Hook, NY, USA: Curran Associates Inc.

\bibitem[\citeproctext]{ref-sauer2021counterfactual}
Sauer, Axel, and Andreas Geiger. 2021. {``Counterfactual Generative
Networks.''} \url{https://arxiv.org/abs/2101.06046}.

\bibitem[\citeproctext]{ref-schut2021generating}
Schut, Lisa, Oscar Key, Rory Mc Grath, Luca Costabello, Bogdan
Sacaleanu, Yarin Gal, et al. 2021. {``Generating {Interpretable
Counterfactual Explanations By Implicit Minimisation} of {Epistemic} and
{Aleatoric Uncertainties}.''} In \emph{International {Conference} on
{Artificial Intelligence} and {Statistics}}, 1756--64. {PMLR}.

\bibitem[\citeproctext]{ref-szegedy2013intriguing}
Szegedy, Christian, Wojciech Zaremba, Ilya Sutskever, Joan Bruna,
Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. {``Intriguing
Properties of Neural Networks.''} \url{https://arxiv.org/abs/1312.6199}.

\bibitem[\citeproctext]{ref-teney2020learning}
Teney, Damien, Ehsan Abbasnedjad, and Anton van den Hengel. 2020.
{``Learning What Makes a Difference from Counterfactual Examples and
Gradient Supervision.''} In \emph{Computer Vision--ECCV 2020: 16th
European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part
x 16}, 580--99. Springer.

\bibitem[\citeproctext]{ref-wachter2017counterfactual}
Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2017.
{``Counterfactual Explanations Without Opening the Black Box:
{Automated} Decisions and the {GDPR}.''} \emph{Harv. JL \& Tech.} 31:
841. \url{https://doi.org/10.2139/ssrn.3063289}.

\bibitem[\citeproctext]{ref-wilson2020case}
Wilson, Andrew Gordon. 2020. {``The Case for Bayesian Deep Learning.''}
\url{https://arxiv.org/abs/2001.10995}.

\bibitem[\citeproctext]{ref-wu2021polyjuice}
Wu, Tongshuang, Marco Tulio Ribeiro, Jeffrey Heer, and Daniel Weld.
2021. {``Polyjuice: Generating Counterfactuals for Explaining,
Evaluating, and Improving Models.''} In \emph{Proceedings of the 59th
Annual Meeting of the Association for Computational Linguistics and the
11th International Joint Conference on Natural Language Processing
(Volume 1: Long Papers)}, edited by Chengqing Zong, Fei Xia, Wenjie Li,
and Roberto Navigli, 6707--23. Online: Association for Computational
Linguistics. \url{https://doi.org/10.18653/v1/2021.acl-long.523}.

\end{CSLReferences}

\newpage{}

\FloatBarrier

\setcounter{section}{0}
\renewcommand{\thesection}{\Alph{section}}

\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\section{Training Details}\label{training-details}

\subsection{Initial Grid Search}\label{initial-grid-search}

For the initial round of experiments we

\subsubsection{Generator Parameters}\label{generator-parameters}

The hyperparameter grids for the first investigation of the effect of
generator parameters are shown in
Parameters~\ref{exr-gen-params-first-run-train} and
Parameters~\ref{exr-gen-params-first-run-eval}.

\begin{exercise}[Training
Phase]\protect\hypertarget{exr-gen-params-first-run-train}{}\label{exr-gen-params-first-run-train}

~

\begin{itemize}
\tightlist
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{cost}}\): \texttt{0.0,\ 0.001,\ 0.1}
  \item
    \(\lambda_{\text{div}}\):
    \texttt{0.01,\ 0.05,\ 0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0,\ 15.0}
  \item
    Learning Rate: \texttt{1.0}
  \item
    Maximum Iterations: \texttt{20,\ 50,\ 100}
  \item
    Optimizerimizer: \texttt{sgd}
  \end{itemize}
\item
  Generator: \texttt{ecco,\ generic,\ omni,\ revise}
\item
  Training Parameters:

  \begin{itemize}
  \tightlist
  \item
    Objective: \texttt{full,\ vanilla}
  \end{itemize}
\end{itemize}

\end{exercise}

\begin{exercise}[Evaluation
Phase]\protect\hypertarget{exr-gen-params-first-run-eval}{}\label{exr-gen-params-first-run-eval}

~

\begin{itemize}
\tightlist
\item
  Counterfactual Parameters:

  \begin{itemize}
  \tightlist
  \item
    Convergence: \texttt{max\_iter}
  \item
    Maximum Iterations: \texttt{100}
  \item
    No.~Individuals: \texttt{100}
  \item
    No.~Runs: \texttt{5}
  \end{itemize}
\item
  Generator Parameters:

  \begin{itemize}
  \tightlist
  \item
    \(\lambda_{\text{cost}}\): \texttt{0.0}
  \item
    \(\lambda_{\text{div}}\):
    \texttt{0.1,\ 0.5,\ 1.0,\ 5.0,\ 10.0,\ 20.0}
  \item
    Learning Rate: \texttt{1.0}
  \item
    Maximum Iterations: \texttt{50}
  \item
    Optimizerimizer: \texttt{sgd}
  \end{itemize}
\end{itemize}

\end{exercise}

\paragraph{Linearly Separable}\label{linearly-separable}

\begin{itemize}
\tightlist
\item
  \textbf{Energy Penalty} (Table~\ref{tbl-lin_sep-lambda_energy_exper}):
  \emph{ECCo} generally does yield better results than \emph{Vanilla}
  for higher choices of the energy penalty (10,15) during training.
  \emph{Generic} performs poorly accross the board. \emph{Omni} seems to
  have an anchoring effect, in that it never performs terribly but also
  never as good as the best \emph{ECCo} results. \emph{REVISE} performs
  poorly across the board.
\item
  \textbf{Cost} (Table~\ref{tbl-lin_sep-lambda_cost_exper}): Results for
  all generators (except \emph{Omni}) are quite bad, which can likely be
  attributed to extremely bad results for some choices of the
  \textbf{Energy Penalty} (results here are averaged). For \emph{ECCo}
  and \emph{Generic}, higher cost values generally lead to worse
  results.
\item
  \textbf{Maximum Iterations}: No clear patterns recognizable, so it
  seems that smaller choices are ok.
\item
  \textbf{Validity}: \emph{ECCo} almost always valid except for very low
  values during training and high values at evaluation time.
  \emph{Generic} often has poor validity.
\item
  \textbf{Accuracy}: Seems largely unaffected.
\end{itemize}

\begin{longtable}{ccccc}

\caption{\label{tbl-lin_sep-lambda_energy_exper}Results for Linearly
Separable data by energy penalty.}

\tabularnewline

  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{div}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{div}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  full & 0.01 & \textit{ECCo} & $-9.91 \cdot 10^{11}$ & $2.25 \cdot 10^{12}$ \\
  full & 0.01 & \textit{Generic} & $-5.71 \cdot 10^{17}$ & $1.3 \cdot 10^{18}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.01}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.54}} & \color{blue}{\textbf{0.116}} \\
  full & 0.01 & \textit{REVISE} & -15.6 & 13.2 \\
  vanilla & 0.01 & \textit{ECCo} & -4.28 & 3.52 \\
  vanilla & 0.01 & \textit{Generic} & -4.45 & 3.47 \\
  vanilla & 0.01 & \textit{Omniscient} & -5.12 & 4.46 \\
  vanilla & 0.01 & \textit{REVISE} & -4.91 & 4.24 \\
  full & 0.05 & \textit{ECCo} & $-5.63 \cdot 10^{5}$ & $1.28 \cdot 10^{6}$ \\
  full & 0.05 & \textit{Generic} & $-8.35 \cdot 10^{17}$ & $1.9 \cdot 10^{18}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.05}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.53}} & \color{blue}{\textbf{0.114}} \\
  full & 0.05 & \textit{REVISE} & -15 & 12.6 \\
  vanilla & 0.05 & \textit{ECCo} & -4.4 & 3.66 \\
  vanilla & 0.05 & \textit{Generic} & -4.38 & 3.48 \\
  vanilla & 0.05 & \textit{Omniscient} & -5.25 & 4.62 \\
  vanilla & 0.05 & \textit{REVISE} & -4.94 & 4.22 \\
  full & 0.1 & \textit{ECCo} & $-6.74 \cdot 10^{5}$ & $1.53 \cdot 10^{6}$ \\
  full & 0.1 & \textit{Generic} & $-1.72 \cdot 10^{11}$ & $3.9 \cdot 10^{11}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.1}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.56}} & \color{blue}{\textbf{0.124}} \\
  full & 0.1 & \textit{REVISE} & -15.6 & 13.2 \\
  vanilla & 0.1 & \textit{ECCo} & -4.28 & 3.52 \\
  vanilla & 0.1 & \textit{Generic} & -4.45 & 3.48 \\
  vanilla & 0.1 & \textit{Omniscient} & -5.12 & 4.46 \\
  vanilla & 0.1 & \textit{REVISE} & -4.91 & 4.25 \\
  full & 0.5 & \textit{ECCo} & -11.8 & 9.83 \\
  full & 0.5 & \textit{Generic} & $-1.06 \cdot 10^{18}$ & $2.42 \cdot 10^{18}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.5}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.54}} & \color{blue}{\textbf{0.123}} \\
  full & 0.5 & \textit{REVISE} & -15 & 12.6 \\
  vanilla & 0.5 & \textit{ECCo} & -4.4 & 3.65 \\
  vanilla & 0.5 & \textit{Generic} & -4.38 & 3.48 \\
  vanilla & 0.5 & \textit{Omniscient} & -5.25 & 4.61 \\
  vanilla & 0.5 & \textit{REVISE} & -4.95 & 4.22 \\
  full & 1 & \textit{ECCo} & -11.5 & 11.1 \\
  full & 1 & \textit{Generic} & $-1.71 \cdot 10^{11}$ & $3.88 \cdot 10^{11}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{1}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.59}} & \color{blue}{\textbf{0.117}} \\
  full & 1 & \textit{REVISE} & -15.7 & 13.3 \\
  vanilla & 1 & \textit{ECCo} & -4.28 & 3.51 \\
  vanilla & 1 & \textit{Generic} & -4.44 & 3.47 \\
  vanilla & 1 & \textit{Omniscient} & -5.11 & 4.46 \\
  vanilla & 1 & \textit{REVISE} & -4.91 & 4.25 \\
  full & 5 & \textit{ECCo} & -3.99 & 3.12 \\
  full & 5 & \textit{Generic} & $-4.88 \cdot 10^{17}$ & $1.11 \cdot 10^{18}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{5}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.53}} & \color{blue}{\textbf{0.117}} \\
  full & 5 & \textit{REVISE} & -14.6 & 12.1 \\
  vanilla & 5 & \textit{ECCo} & -4.4 & 3.65 \\
  vanilla & 5 & \textit{Generic} & -4.38 & 3.48 \\
  vanilla & 5 & \textit{Omniscient} & -5.25 & 4.61 \\
  vanilla & 5 & \textit{REVISE} & -4.95 & 4.22 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{10}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-2.31}} & \color{blue}{\textbf{0.735}} \\
  full & 10 & \textit{Generic} & $-1.7 \cdot 10^{11}$ & $3.86 \cdot 10^{11}$ \\
  full & 10 & \textit{Omniscient} & -2.53 & 0.117 \\
  full & 10 & \textit{REVISE} & -15.5 & 13 \\
  vanilla & 10 & \textit{ECCo} & -4.28 & 3.51 \\
  vanilla & 10 & \textit{Generic} & -4.44 & 3.47 \\
  vanilla & 10 & \textit{Omniscient} & -5.12 & 4.46 \\
  vanilla & 10 & \textit{REVISE} & -4.91 & 4.24 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{15}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-2.01}} & \color{blue}{\textbf{0.488}} \\
  full & 15 & \textit{Generic} & $-4.91 \cdot 10^{17}$ & $1.12 \cdot 10^{18}$ \\
  full & 15 & \textit{Omniscient} & -2.53 & 0.116 \\
  full & 15 & \textit{REVISE} & -14.4 & 11.7 \\
  vanilla & 15 & \textit{ECCo} & -4.4 & 3.65 \\
  vanilla & 15 & \textit{Generic} & -4.38 & 3.48 \\
  vanilla & 15 & \textit{Omniscient} & -5.25 & 4.6 \\
  vanilla & 15 & \textit{REVISE} & -4.95 & 4.23 \\\bottomrule

\end{longtable}

\begin{longtable}{ccccc}

\caption{\label{tbl-lin_sep-lambda_cost_exper}Results for Linearly
Separable data by cost penalty.}

\tabularnewline

  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{cost}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{cost}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  full & 0 & \textit{ECCo} & $-5.32 \cdot 10^{3}$ & $1.21 \cdot 10^{4}$ \\
  full & 0 & \textit{Generic} & $-1.03 \cdot 10^{18}$ & $2.34 \cdot 10^{18}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.64}} & \color{blue}{\textbf{0.125}} \\
  full & 0 & \textit{REVISE} & -15.4 & 12.9 \\
  vanilla & 0 & \textit{ECCo} & -4.34 & 3.58 \\
  vanilla & 0 & \textit{Generic} & -4.41 & 3.48 \\
  vanilla & 0 & \textit{Omniscient} & -5.18 & 4.54 \\
  vanilla & 0 & \textit{REVISE} & -4.93 & 4.23 \\
  full & 0.001 & \textit{ECCo} & -362 & 811 \\
  full & 0.001 & \textit{Generic} & $-2.65 \cdot 10^{17}$ & $6.03 \cdot 10^{17}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.001}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.49}} & \color{blue}{\textbf{0.115}} \\
  full & 0.001 & \textit{REVISE} & -15.5 & 13 \\
  vanilla & 0.001 & \textit{ECCo} & -4.34 & 3.58 \\
  vanilla & 0.001 & \textit{Generic} & -4.41 & 3.48 \\
  vanilla & 0.001 & \textit{Omniscient} & -5.18 & 4.53 \\
  vanilla & 0.001 & \textit{REVISE} & -4.93 & 4.23 \\
  full & 0.1 & \textit{ECCo} & $-3.72 \cdot 10^{11}$ & $8.46 \cdot 10^{11}$ \\
  full & 0.1 & \textit{Generic} & $-4.49 \cdot 10^{14}$ & $1.02 \cdot 10^{15}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.1}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-2.5}} & \color{blue}{\textbf{0.112}} \\
  full & 0.1 & \textit{REVISE} & -14.6 & 12.2 \\
  vanilla & 0.1 & \textit{ECCo} & -4.34 & 3.58 \\
  vanilla & 0.1 & \textit{Generic} & -4.41 & 3.48 \\
  vanilla & 0.1 & \textit{Omniscient} & -5.18 & 4.54 \\
  vanilla & 0.1 & \textit{REVISE} & -4.93 & 4.24 \\\bottomrule

\end{longtable}

\paragraph{Moons}\label{moons}

\begin{itemize}
\tightlist
\item
  \textbf{Energy Penalty} (Table~\ref{tbl-moons-lambda_energy_exper}):
  \emph{ECCo} consistently yields better results than \emph{Vanilla},
  except for very low choices of the energy penalty during training for
  which it performs abismal. \emph{Generic} performs quite badly across
  the board for high enough choices of the energy penalty at evaluation
  time. \emph{Omni} has small positive effect. \emph{REVISE} performs
  poorly across the board.
\item
  \textbf{Cost (distance penalty)}: \emph{Generic} generally does better
  for higher values, while \emph{ECCo} does better for lower values.
\item
  \textbf{Maximum Iterations}: No clear patterns recognizable, so it
  seems that smaller choices are ok.
\item
  \textbf{Validity}: \emph{ECCo} generally achieves full validity except
  for very low choices the energy penalty during training and high
  choices at evaluation time. \emph{Generic} performs poorly for high
  choices of the energy penalty during evaluation.
\item
  \textbf{Accuracy}: Largely unaffected although \emph{ECCo} suffers a
  bit for very low choices the energy penalty during training.
  \emph{REVISE} suffers a lot in general (around 10 percentage points).
\end{itemize}

\begin{longtable}{ccccc}

\caption{\label{tbl-moons-lambda_energy_exper}Results for Moons data by
energy penalty.}

\tabularnewline

  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{div}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{div}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  full & 0.01 & \textit{ECCo} & $-2.8 \cdot 10^{22}$ & $6.39 \cdot 10^{22}$ \\
  full & 0.01 & \textit{Generic} & $-4.89 \cdot 10^{30}$ & $1.11 \cdot 10^{31}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.01}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-4.74}} & \color{blue}{\textbf{5.08}} \\
  full & 0.01 & \textit{REVISE} & -572 & $1.25 \cdot 10^{3}$ \\
  vanilla & 0.01 & \textit{ECCo} & -15.5 & 17.3 \\
  vanilla & 0.01 & \textit{Generic} & -10.9 & 11.9 \\
  vanilla & 0.01 & \textit{Omniscient} & -12.7 & 14.4 \\
  vanilla & 0.01 & \textit{REVISE} & -11.2 & 13 \\
  full & 0.05 & \textit{ECCo} & $-1.55 \cdot 10^{16}$ & $3.52 \cdot 10^{16}$ \\
  full & 0.05 & \textit{Generic} & $-2.22 \cdot 10^{20}$ & $5 \cdot 10^{20}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.05}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-4.41}} & \color{blue}{\textbf{4.48}} \\
  full & 0.05 & \textit{REVISE} & $-1.04 \cdot 10^{3}$ & $2.3 \cdot 10^{3}$ \\
  vanilla & 0.05 & \textit{ECCo} & -15.5 & 17.2 \\
  vanilla & 0.05 & \textit{Generic} & -11.7 & 12.8 \\
  vanilla & 0.05 & \textit{Omniscient} & -12.4 & 14.1 \\
  vanilla & 0.05 & \textit{REVISE} & -11.3 & 13.1 \\
  full & 0.1 & \textit{ECCo} & $-3.41 \cdot 10^{3}$ & $7.73 \cdot 10^{3}$ \\
  full & 0.1 & \textit{Generic} & $-5.22 \cdot 10^{30}$ & $1.19 \cdot 10^{31}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.1}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-4.78}} & \color{blue}{\textbf{5.12}} \\
  full & 0.1 & \textit{REVISE} & -288 & 594 \\
  vanilla & 0.1 & \textit{ECCo} & -15.5 & 17.2 \\
  vanilla & 0.1 & \textit{Generic} & -10.9 & 11.9 \\
  vanilla & 0.1 & \textit{Omniscient} & -12.7 & 14.4 \\
  vanilla & 0.1 & \textit{REVISE} & -11.3 & 13.1 \\
  full & 0.5 & \textit{ECCo} & -7.09 & 7.51 \\
  full & 0.5 & \textit{Generic} & $-1.11 \cdot 10^{31}$ & $2.53 \cdot 10^{31}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.5}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-4.58}} & \color{blue}{\textbf{4.83}} \\
  full & 0.5 & \textit{REVISE} & $-1.19 \cdot 10^{3}$ & $2.64 \cdot 10^{3}$ \\
  vanilla & 0.5 & \textit{ECCo} & -15.5 & 17.2 \\
  vanilla & 0.5 & \textit{Generic} & -11.7 & 12.8 \\
  vanilla & 0.5 & \textit{Omniscient} & -12.4 & 14.1 \\
  vanilla & 0.5 & \textit{REVISE} & -11.3 & 13.1 \\
  full & 1 & \textit{ECCo} & -6.06 & 6.33 \\
  full & 1 & \textit{Generic} & $-1.58 \cdot 10^{33}$ & $3.59 \cdot 10^{33}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{1}} & \color{blue}{\textbf{Omniscient}} & \color{blue}{\textbf{-4.66}} & \color{blue}{\textbf{4.89}} \\
  full & 1 & \textit{REVISE} & $-1.16 \cdot 10^{3}$ & $2.59 \cdot 10^{3}$ \\
  vanilla & 1 & \textit{ECCo} & -15.5 & 17.3 \\
  vanilla & 1 & \textit{Generic} & -10.9 & 11.9 \\
  vanilla & 1 & \textit{Omniscient} & -12.7 & 14.4 \\
  vanilla & 1 & \textit{REVISE} & -11.3 & 13.1 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{5}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-2.57}} & \color{blue}{\textbf{2.07}} \\
  full & 5 & \textit{Generic} & $-1.17 \cdot 10^{28}$ & $2.66 \cdot 10^{28}$ \\
  full & 5 & \textit{Omniscient} & -4.29 & 4.31 \\
  full & 5 & \textit{REVISE} & -530 & $1.16 \cdot 10^{3}$ \\
  vanilla & 5 & \textit{ECCo} & -15.5 & 17.2 \\
  vanilla & 5 & \textit{Generic} & -11.7 & 12.7 \\
  vanilla & 5 & \textit{Omniscient} & -12.4 & 14.1 \\
  vanilla & 5 & \textit{REVISE} & -11.3 & 13.1 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{10}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-1.76}} & \color{blue}{\textbf{0.974}} \\
  full & 10 & \textit{Generic} & $-1.54 \cdot 10^{33}$ & $3.51 \cdot 10^{33}$ \\
  full & 10 & \textit{Omniscient} & -4.44 & 4.56 \\
  full & 10 & \textit{REVISE} & $-1.52 \cdot 10^{3}$ & $3.4 \cdot 10^{3}$ \\
  vanilla & 10 & \textit{ECCo} & -15.5 & 17.3 \\
  vanilla & 10 & \textit{Generic} & -10.9 & 11.9 \\
  vanilla & 10 & \textit{Omniscient} & -12.7 & 14.4 \\
  vanilla & 10 & \textit{REVISE} & -11.3 & 13.1 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{15}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-1.37}} & \color{blue}{\textbf{0.365}} \\
  full & 15 & \textit{Generic} & $-5.32 \cdot 10^{28}$ & $1.21 \cdot 10^{29}$ \\
  full & 15 & \textit{Omniscient} & -4.34 & 4.38 \\
  full & 15 & \textit{REVISE} & -473 & $1.03 \cdot 10^{3}$ \\
  vanilla & 15 & \textit{ECCo} & -15.5 & 17.2 \\
  vanilla & 15 & \textit{Generic} & -11.7 & 12.8 \\
  vanilla & 15 & \textit{Omniscient} & -12.4 & 14.1 \\
  vanilla & 15 & \textit{REVISE} & -11.3 & 13.1 \\\bottomrule

\end{longtable}

\paragraph{Circles}\label{circles}

\begin{itemize}
\tightlist
\item
  \textbf{Energy Penalty} (Table~\ref{tbl-circles-lambda_energy_exper}):
  \emph{ECCo} consistently yields better results than \emph{Vanilla},
  though primarily for low to medium choices of the energy penalty
  (\textless=5) during training. The same goes for \emph{Generic}, which
  sometimes outperforms \emph{ECCo} (for small energy penalty at
  evaluation time). \emph{Omni} does alright for lower energy penalty at
  evaluation time, but loses out for higher choices. \emph{REVISE}
  performs poorly across the board (except very low choices at
  evaluation time).
\item
  \textbf{Cost (distance penalty)}: \emph{ECCo} and \emph{Generic}
  generally achieve the best results when no cost penalty is used during
  training. Both \emph{Omni} and \emph{REVISE} are largely unaffected.
\item
  \textbf{Maximum Iterations}: \emph{ECCo} consistently yields better
  results for higher numbers of iterations. \emph{Generic} generally
  does best for a medium number (50). \emph{Omni} is sometimes invalid
  (\textbf{???}).
\item
  \textbf{Validity}: \emph{ECCo} tends to outperform its \emph{Vanilla}
  counterpart, though primarily for low to medium choices of the energy
  penalty (\textless=5) during training and evaluation. \emph{Vanilla}
  typically worse across the board.
\item
  \textbf{Accuracy}: Mostly unaffected, but \emph{REVISE} again
  consistently some deterioration and \emph{ECCo} deteriorates for high
  choices of energy penalty during training, reflecting other outcomes
  above.
\end{itemize}

\begin{longtable}{ccccc}

\caption{\label{tbl-circles-lambda_energy_exper}Results for Circles data
by energy penalty.}

\tabularnewline

  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{div}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endfirsthead
  \toprule
  \textbf{Objective} & \textbf{$\lambda_{\text{div}} (\text{train})$} & \textbf{Generator} & \textbf{Value} & \textbf{Std} \\\midrule
  \endhead
  \bottomrule
  \multicolumn{5}{r}{Continuing table below.}\\
  \bottomrule
  \endfoot
  \endlastfoot
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.01}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-1.26}} & \color{blue}{\textbf{0.423}} \\
  full & 0.01 & \textit{Generic} & -1.49 & 0.71 \\
  full & 0.01 & \textit{Omniscient} & -5.21 & 5.25 \\
  full & 0.01 & \textit{REVISE} & $-2.71 \cdot 10^{26}$ & $6.37 \cdot 10^{26}$ \\
  vanilla & 0.01 & \textit{ECCo} & -9.33 & 7.34 \\
  vanilla & 0.01 & \textit{Generic} & -8.89 & 6.88 \\
  vanilla & 0.01 & \textit{Omniscient} & -8.67 & 6.87 \\
  vanilla & 0.01 & \textit{REVISE} & -8.65 & 6.8 \\
  full & 0.05 & \textit{ECCo} & -1.29 & 0.397 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.05}} & \color{blue}{\textbf{Generic}} & \color{blue}{\textbf{-1.21}} & \color{blue}{\textbf{0.356}} \\
  full & 0.05 & \textit{Omniscient} & -5.08 & 5.09 \\
  full & 0.05 & \textit{REVISE} & $-5.91 \cdot 10^{27}$ & $1.36 \cdot 10^{28}$ \\
  vanilla & 0.05 & \textit{ECCo} & -9.35 & 7.32 \\
  vanilla & 0.05 & \textit{Generic} & -8.85 & 6.87 \\
  vanilla & 0.05 & \textit{Omniscient} & -8.7 & 6.96 \\
  vanilla & 0.05 & \textit{REVISE} & -8.52 & 6.76 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.1}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-1.2}} & \color{blue}{\textbf{0.383}} \\
  full & 0.1 & \textit{Generic} & -1.5 & 0.735 \\
  full & 0.1 & \textit{Omniscient} & -5.17 & 5.23 \\
  full & 0.1 & \textit{REVISE} & $-3.06 \cdot 10^{26}$ & $7.7 \cdot 10^{26}$ \\
  vanilla & 0.1 & \textit{ECCo} & -9.33 & 7.32 \\
  vanilla & 0.1 & \textit{Generic} & -8.88 & 6.86 \\
  vanilla & 0.1 & \textit{Omniscient} & -8.69 & 6.9 \\
  vanilla & 0.1 & \textit{REVISE} & -8.68 & 6.81 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{0.5}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-1.12}} & \color{blue}{\textbf{0.217}} \\
  full & 0.5 & \textit{Generic} & -1.21 & 0.352 \\
  full & 0.5 & \textit{Omniscient} & -5.09 & 5.12 \\
  full & 0.5 & \textit{REVISE} & $-5.97 \cdot 10^{27}$ & $1.37 \cdot 10^{28}$ \\
  vanilla & 0.5 & \textit{ECCo} & -9.35 & 7.3 \\
  vanilla & 0.5 & \textit{Generic} & -8.89 & 6.92 \\
  vanilla & 0.5 & \textit{Omniscient} & -8.68 & 6.93 \\
  vanilla & 0.5 & \textit{REVISE} & -8.53 & 6.75 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{1}} & \color{blue}{\textbf{ECCo}} & \color{blue}{\textbf{-1.1}} & \color{blue}{\textbf{0.163}} \\
  full & 1 & \textit{Generic} & -1.49 & 0.726 \\
  full & 1 & \textit{Omniscient} & -5.16 & 5.2 \\
  full & 1 & \textit{REVISE} & $-3.09 \cdot 10^{26}$ & $7.22 \cdot 10^{26}$ \\
  vanilla & 1 & \textit{ECCo} & -9.34 & 7.36 \\
  vanilla & 1 & \textit{Generic} & -8.86 & 6.85 \\
  vanilla & 1 & \textit{Omniscient} & -8.7 & 6.9 \\
  vanilla & 1 & \textit{REVISE} & -8.69 & 6.85 \\
  full & 5 & \textit{ECCo} & -1.75 & 0.154 \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{5}} & \color{blue}{\textbf{Generic}} & \color{blue}{\textbf{-1.21}} & \color{blue}{\textbf{0.363}} \\
  full & 5 & \textit{Omniscient} & -5.14 & 5.16 \\
  full & 5 & \textit{REVISE} & $-1.1 \cdot 10^{28}$ & $2.5 \cdot 10^{28}$ \\
  vanilla & 5 & \textit{ECCo} & -9.36 & 7.32 \\
  vanilla & 5 & \textit{Generic} & -8.88 & 6.91 \\
  vanilla & 5 & \textit{Omniscient} & -8.7 & 6.93 \\
  vanilla & 5 & \textit{REVISE} & -8.52 & 6.73 \\
  full & 10 & \textit{ECCo} & $-1.02 \cdot 10^{6}$ & $2.32 \cdot 10^{6}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{10}} & \color{blue}{\textbf{Generic}} & \color{blue}{\textbf{-1.49}} & \color{blue}{\textbf{0.702}} \\
  full & 10 & \textit{Omniscient} & -5.13 & 5.16 \\
  full & 10 & \textit{REVISE} & $-3.74 \cdot 10^{26}$ & $9.09 \cdot 10^{26}$ \\
  vanilla & 10 & \textit{ECCo} & -9.31 & 7.33 \\
  vanilla & 10 & \textit{Generic} & -8.87 & 6.86 \\
  vanilla & 10 & \textit{Omniscient} & -8.7 & 6.89 \\
  vanilla & 10 & \textit{REVISE} & -8.69 & 6.83 \\
  full & 15 & \textit{ECCo} & $-3.31 \cdot 10^{13}$ & $7.54 \cdot 10^{13}$ \\
  \color{blue}{\textbf{full}} & \color{blue}{\textbf{15}} & \color{blue}{\textbf{Generic}} & \color{blue}{\textbf{-1.22}} & \color{blue}{\textbf{0.37}} \\
  full & 15 & \textit{Omniscient} & -5.2 & 5.23 \\
  full & 15 & \textit{REVISE} & $-9.01 \cdot 10^{27}$ & $2.06 \cdot 10^{28}$ \\
  vanilla & 15 & \textit{ECCo} & -9.38 & 7.34 \\
  vanilla & 15 & \textit{Generic} & -8.86 & 6.87 \\
  vanilla & 15 & \textit{Omniscient} & -8.69 & 6.96 \\
  vanilla & 15 & \textit{REVISE} & -8.51 & 6.73 \\\bottomrule

\end{longtable}




\end{document}
