var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = CounterfactualTraining","category":"page"},{"location":"#CounterfactualTraining","page":"Home","title":"CounterfactualTraining","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for CounterfactualTraining.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [CounterfactualTraining]","category":"page"},{"location":"#CounterfactualTraining.AbstractObjective","page":"Home","title":"CounterfactualTraining.AbstractObjective","text":"Base type of training objectives.\n\n\n\n\n\n","category":"type"},{"location":"#CounterfactualTraining.AdversarialObjective","page":"Home","title":"CounterfactualTraining.AdversarialObjective","text":"AdversarialObjective <: AbstractObjective\n\nThe AdversarialObjective is a concrete implementation of the AbstractObjective abstract type that optimizes for:\n\nStandard classification objective (the discriminative task).\nAdversarial classification objective on the counterfactuals (the explainability task).\n\n\n\n\n\n","category":"type"},{"location":"#CounterfactualTraining.AdversarialObjective-Tuple{Any, Any}","page":"Home","title":"CounterfactualTraining.AdversarialObjective","text":"(obj::AdversarialObjective)(\n    yhat,\n    y;\n    energy_differential::Vector{<:AbstractFloat},\n    regularization::Vector{<:AbstractFloat}=[0.0f0],\n    adversarial_loss::Union{AbstractFloat,Vector{<:AbstractFloat}},\n    kwrgs...,\n)\n\nIf the adversarial_loss has been computed already, obj::AdversarialObjective can be called directly on predictions yhat and labels y. The different loss components are then added together with a weighting vector lambda.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.AdversarialObjective-Tuple{}","page":"Home","title":"CounterfactualTraining.AdversarialObjective","text":"AdversarialObjective(;\n    class_loss::Function=Flux.Losses.logitcrossentropy,\n    lambda::Vector{<:AbstractFloat}=[1.0, 1.0]\n)\n\nOuter constructor for the AdversarialObjective type.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.EnergyDifferentialObjective","page":"Home","title":"CounterfactualTraining.EnergyDifferentialObjective","text":"EnergyDifferentialObjective <: AbstractObjective\n\nThe EnergyDifferentialObjective is a concrete implementation of the AbstractObjective abstract type that optimizes for:\n\nStandard classification objective (the discriminative task)\nEnergy differential between counterfactuals and observed data (the explainability task).\n\n\n\n\n\n","category":"type"},{"location":"#CounterfactualTraining.EnergyDifferentialObjective-Tuple{Any, Any}","page":"Home","title":"CounterfactualTraining.EnergyDifferentialObjective","text":"(obj::EnergyDifferentialObjective)(\n    yhat,\n    y;\n    energy_differential::Vector{<:AbstractFloat},\n    regularization::Vector{<:AbstractFloat}=[0.0f0],\n    adversarial_loss::Union{AbstractFloat,Vector{<:AbstractFloat}},\n    regularization::Vector{<:AbstractFloat}=[0.0f0],\n    kwrgs...,\n)\n\nIf the energy_differential and regularization have been computed already, obj::EnergyDifferentialObjective can be called directly on predictions yhat and labels y. The different loss components are then added together with a weighting vector lambda.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.EnergyDifferentialObjective-Tuple{}","page":"Home","title":"CounterfactualTraining.EnergyDifferentialObjective","text":"EnergyDifferentialObjective(;\n    class_loss::Function=Flux.Losses.logitcrossentropy, \n    lambda::Vector{<:AbstractFloat}=[1.0, 0.5, 0.0001]\n)\n\nOuter constructor for the EnergyDifferentialObjective type.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.FullObjective","page":"Home","title":"CounterfactualTraining.FullObjective","text":"FullObjective <: AbstractObjective\n\nThe FullObjective is a concrete implementation of the AbstractObjective abstract type that optimizes for all three tasks:\n\nStandard classification objective (the discriminative task)\nEnergy differential between counterfactuals and observed data (the explainability task).\nAdversarial classification objective on the counterfactuals (the explainability task).\n\n\n\n\n\n","category":"type"},{"location":"#CounterfactualTraining.FullObjective-Tuple{Any, Any}","page":"Home","title":"CounterfactualTraining.FullObjective","text":"(obj::FullObjective)(\n    yhat,\n    y;\n    energy_differential::Vector{<:AbstractFloat},\n    regularization::Vector{<:AbstractFloat}=[0.0f0],\n    adversarial_loss::Union{AbstractFloat,Vector{<:AbstractFloat}},\n    kwrgs...,\n)\n\nIf the adversarial_loss has been computed already, obj::FullObjective can be called directly on predictions yhat and labels y. The different loss components are then added together with a weighting vector lambda.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.FullObjective-Tuple{}","page":"Home","title":"CounterfactualTraining.FullObjective","text":"FullObjective(;\n    class_loss::Function=Flux.Losses.logitcrossentropy,\n    energy_differential::PenaltyOrFun=EnergyDifferential(),\n    lambda::Vector{<:AbstractFloat}=[1.0, 0.5, 0.0001, 1.0]\n)\n\nOuter constructor for the FullObjective type.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.generate!-NTuple{4, Any}","page":"Home","title":"CounterfactualTraining.generate!","text":"generate!(\n    input,\n    model,\n    data,\n    generator;\n    convergence=Convergence.MaxIterConvergence(),\n    parallelizer=nothing,\n    input_encoder=nothing,\n    verbose=1,\n    domain=nothing,\n)\n\nThis function generates counterfactual explanations for a given array of inputs input. It is supposed to be used inside of the mini-batch training loop. The model model is expected to be a Flux model that takes an input and returns a vector of predictions. The data data is expected to a training dataset compatible with Flux training. The generator generator is expected to be a function that generates new inputs. It is used to generate counterfactuals.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.generate!-Tuple{Any, Any, Any}","page":"Home","title":"CounterfactualTraining.generate!","text":"generate!(\n    model,\n    data,\n    generator;\n    nsamples::Union{Int,Nothing}=nothing,\n    convergence=Convergence.MaxIterConvergence(),\n    parallelizer=nothing,\n    input_encoder=nothing,\n    verbose=1,\n    domain=nothing,\n)\n\nThis function generates counterfactual explanations for the whole dataset data or a subset thereof (nsamples). It is supposed to be used outside of the mini-batch training loop.\n\n\n\n\n\n","category":"method"},{"location":"#CounterfactualTraining.unwrap-Tuple{Any}","page":"Home","title":"CounterfactualTraining.unwrap","text":"unwrap(train_set; labels=nothing)\n\nUnwraps the data from a Flux.DataLoader or zip iterator. The output variables is assumed to be categorical. If no labels are provided, then 1 to n is used where n is the number of classes.\n\n\n\n\n\n","category":"method"}]
}
