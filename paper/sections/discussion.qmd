# Discussion {#sec-discussion}

As our results indicate, counterfactual training produces models that are more explainable. However, our approach is not without limitations.  
***CT increases the training time of models.*** CT can be more time-consuming than conventional training regimes. While higher numbers of CEs per iteration positively impact the quality of solutions, they also increase the amount of computations. Relatively small grids with 270 settings can take almost four hours for more demanding datasets on a high-performance computing cluster with 34 2GB CPUs.^[See supplementary appendix for computational details.] Three factors attenuate this effect. First, CT amortizes the cost of CEs for the training samples. Second, we find that it can retain its value when used as a "fine-tuning" technique for conventionally-trained models. Third, it yields itself to parallel execution, which we have leveraged for our own experiments.  
***Immutable features may have proxies.*** We propose an approach to protect immutable features and thus increase the actionability of the generated CEs. However, it requires that model owners define the mutability constraints for (all) features considered by the model. Even if all immutable features are protected, there may exist proxies that are mutable (and hence should not be protected) but preserve enough information about the principals to hinder the protections. Delineating actionability is a major undecided challenge in the AR literature [see, e.g., @venkatasubramanian2020philosophical] impacting the capacity of CT to fulfill its intended goal.  
***Interventions on features may impact fairness.***  We provide a tool that allows practitioners to modify the sensitivity of a model with respect to certain features, which may have implication for the fair and equitable treatment of decision subjects. As protecting a set of features leads the model to assign higher relative importance to unprotected features, model owners could misuse our solution by enforcing explanations based on features that are more difficult to modify by some (group of) individuals. For example, consider the Adult dataset used in our experiments, where *workclass* or *education* may be more difficult to change for underpriviledged groups. When applied irresponsibly, CT could result in an unfairly assigned burden of recourse [e.g., @sharma2020certifai], threatening the equality of opportunity in the system [@bell2024fairness]. Still, these phenomena are not specific to CT.  
  
We also highlight several interesting directions for future research.  
***Extending CT beyond classification settings.*** Our formulation relies on the distinction between non-target class(es) $y^{-}$ and target class(es) $y^{+}$ to generate counterfactuals through @eq-obj. While $y^{-}$ and $y^{+}$ can be arbitrarily defined, CT requires the output space $\mathcal{Y}$ to be discrete. Thus, it does not apply to ML tasks where the change in outcome cannot be readily quantified. Focus on classification models is a common restriction in research on CEs and AR. Other settings have attracted some interest (e.g., regression in [@spooner2021counterfactual; @zhao2023counterfactual]), but there is little consensus how to robustly extend the notion of CEs.  
***Addressing the training instabilities.*** JEMs are susceptible to instabilities during training [@grathwohl2020your] and even though we depart from the SGLD-based sampling, we still encounter major variability in the outcomes. CT is exposed to two potential sources of instabilities: (1) the energy-based contrastive divergence term in @eq-div, and (2) the underlying counterfactual explainers. Still, we find that training instabilities can be successfully mitigated by regularizing energy ($\lambda_{\text{reg}}$), generating sufficiently many counterfactuals during each training epoch, and including only mature counterfactuals for contrastive divergence.  
***Improving hyperparameter selection procedures.*** Our method benefits from the tuning of certain key hyperparameters (see @sec-hyperparameters). In this work, we have relied exclusively on grid search for this task. Future work on CT could benefit from investigating more sophisticated approaches towards hyperparameter tuning. Notably, CT is iterative which makes a variety of methods applicable, including Bayesian [e.g., @snoek2012practical] or gradient-based [e.g., @franceschi2017forward] optimization.